\documentclass[english,gradu]{tktltiki2018}
\usepackage{epsfig}
%\usepackage[pdftex]{graphicx}
\usepackage{subfigure}
\usepackage{url}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{amsfonts,amsmath,amssymb,amsthm,booktabs,color,enumitem,graphicx,mathabx}
\usepackage{subfigure,xspace}
\usepackage{algpseudocode}
\begin{document}
\onehalfspacing

\newtheorem{theo}{Theorem}
\newtheorem{lem}{Lemma}
\newtheorem{cor}[lem]{Corollary}

\theoremstyle{definition}
%\newtheorem{def}[theo]{Definition}
\newtheorem{prob}{Problem}
\newtheorem{alg}{Algorithm}
\newtheorem{ex}{Example}

\theoremstyle{remark}
\newtheorem*{note}{Remark}

\newcommand\range[2]{\ensuremath{\left [ #1 , #2 \right )}\xspace}
\newcommand\orange[2]{\ensuremath{\left ( #1 , #2 \right )}\xspace}
\newcommand\crange[2]{\ensuremath{\left [ #1 , #2 \right ]}\xspace}
\newcommand\set[1]{\ensuremath{\left\{#1\right\}}\xspace}
\newcommand\size[1]{\ensuremath{\left |#1\right |}\xspace}
\newcommand\ceil[1]{\ensuremath{\left\lceil #1\right\rceil}\xspace}
\newcommand\reals{\ensuremath{\mathbb{R}}\xspace}

\newcommand\spt{\ensuremath{\dot{s}}\xspace}
\newcommand\ept{\ensuremath{\dot{t}}\xspace}
\newcommand\fspace{\ensuremath{\mathcal{A}}\xspace}
\newcommand\dirs{\ensuremath{\mathcal{C}}\xspace}

\newcommand\epts{\ensuremath{P}\xspace}
\newcommand\segsize{\ensuremath{m}\xspace}
\newcommand\inter[1]{\ensuremath{\textsc{intr}(#1)}\xspace}
\newcommand\leftc[1]{\ensuremath{\textsc{left}(#1)}\xspace}
\newcommand\rightc[1]{\ensuremath{\textsc{right}(#1)}\xspace}
\newcommand\leftu[2]{\ensuremath{\textsc{fst}_{#2}(#1)}\xspace}
\newcommand\rightu[2]{\ensuremath{\textsc{snd}_{#2}(#1)}\xspace}
\newcommand\reach[1]{\ensuremath{\textsc{light}(#1)}\xspace}
\newcommand\reachd[2]{\ensuremath{\textsc{light}_{#2}(#1)}\xspace}
\newcommand\canon[1]{\ensuremath{\textsc{c}(#1)}\xspace}
%\newcommand\canonp[1]{\ensuremath{\dot{\textsc{c}}(#1)}\xspace}
%\newcommand\canont[2]{\ensuremath{\textsc{c}(#1,#2)}\xspace}
\newcommand\canoni[2]{\ensuremath{\textsc{c}_{#2}(#1)}\xspace}
\newcommand\canonpar[1]{\ensuremath{\textsc{p}_{\textsc{c}}(#1)}\xspace}
\newcommand\canonpari[2]{\ensuremath{\textsc{p}_{\textsc{c},#2}(#1)}\xspace}
\newcommand\epar[1]{\ensuremath{\textsc{p}(#1)}\xspace}
\newcommand\visitp{\ensuremath{\textsc{VisitParent}}\xspace}
\newcommand\visitc{\ensuremath{\textsc{VisitCanonical}}\xspace}
\newcommand\adddt{\ensuremath{\textsc{InsertToTree}}\xspace}
\newcommand\checkdt{\ensuremath{\textsc{QueryTree}}\xspace}
\newcommand\maskof[1]{\ensuremath{\textsc{NodeMask}(#1)}\xspace}

\newcommand\nodecs[1]{\ensuremath{\textsc{ivc}(#1)}\xspace}
\newcommand\nodeps[1]{\ensuremath{\textsc{ivp}(#1)}\xspace}
\newcommand\subtree[1]{\ensuremath{\texttt{subtree}(#1)}\xspace}
\newcommand\subtreep[1]{\ensuremath{\texttt{subtreeP}(#1)}\xspace}
\newcommand\hasrect[1]{\ensuremath{\texttt{hasrect}(#1)}\xspace}
\newcommand\hasbits[2]{\ensuremath{\texttt{hasbits}(#1)[#2]}\xspace}

\newcommand\rect[1]{\ensuremath{\textsc{rect}(#1)}\xspace}

\newcommand\pop[1]{\ensuremath{\textsc{pop}(#1)}\xspace}

\newcommand\y[1]{\ensuremath{{#1}_y}\xspace}
\newcommand\x[1]{\ensuremath{{#1}_x}\xspace}
\newcommand\xrange[1]{\ensuremath{x(#1)}\xspace}
\newcommand\yrange[1]{\ensuremath{y(#1)}\xspace}
\newcommand\zrange[1]{\ensuremath{z(#1)}\xspace}
\newcommand\xranget[2]{\ensuremath{x(#1)_{#2}}\xspace}
\newcommand\yranget[2]{\ensuremath{y(#1)_{#2}}\xspace}
\newcommand\nbs[1]{\ensuremath{\textsc{nbs}{(#1)}}\xspace}
\newcommand\nbsd[2]{\ensuremath{\textsc{nbs}_{#2}{(#1)}}\xspace}
\newcommand\obsd[2]{\ensuremath{\textsc{obs}_{#2}{(#1)}}\xspace}

\newcommand\decomp[1]{\ensuremath{\textsc{dec}_{#1}}\xspace}
%\newcommand\decompc[1]{\ensuremath{\textsc{dec}({#1})}\xspace}
\newcommand\sweep[2]{\ensuremath{\textsc{sweep}_{#2}{(#1)}}\xspace}
\newcommand\stepof[1]{\ensuremath{\textsc{step}{(#1)}}\xspace}
\newcommand\proj[2]{\ensuremath{\text{proj}_{#1}(#2)}\xspace}

\newcommand\rotr[1]{\ensuremath{\top #1}\xspace}
\newcommand\vecof[1]{\ensuremath{\left [#1\right ]}\xspace}
\newcommand\sline[1]{\ensuremath{S_{#1}}\xspace}
\newcommand\intert[2]{\ensuremath{\textsc{interval}_{#1}(#2)}\xspace}
\newcommand\point[1]{\ensuremath{\left ({#1}\right )}\xspace}

\newcommand\cellE{\ensuremath{\mathsf{CellEvent}}\xspace}
\newcommand\cellEs{\ensuremath{\mathsf{CellEvent}}s\xspace}
\newcommand\obsE{\ensuremath{\mathsf{ObstacleEvent}}\xspace}
\newcommand\obsEs{\ensuremath{\mathsf{ObstacleEvent}}s\xspace}
\newcommand\addE{\ensuremath{\mathsf{AddRangeEvent}}\xspace}
\newcommand\addEs{\ensuremath{\mathsf{AddRangeEvent}}s\xspace}
\newcommand\cellof[1]{\ensuremath{\text{cell}(#1)}\xspace}
\newcommand\rectof[1]{\ensuremath{\text{rect}(#1)}\xspace}
\newcommand\hrectof[1]{\ensuremath{\text{hyperrect}(#1)}\xspace}


\title{Rectilinear minimum link paths in high dimensions}
\author{Mikko Sysikaski}
\date{\today}
\level{Master's thesis}

% For new study programmes (2017->) to appear on title page
%\department{Master's Programme in Computer Science}
%\department{Master's Programme in Data Science}
%\department{Bachelor's Programme in Computer Science}

\maketitle

\numberofpagesinformation{\numberofpages\ pages + \numberofappendixpages\ appendices}

\classification{\protect{\ \\
%\  General and reference $\rightarrow$ Document types  $\rightarrow$ Surveys and overviews\  \\
%\  Applied computing  $\rightarrow$ Document management and text processing  $\rightarrow$ Document management $\rightarrow$ Text editing\\
F.2.2 [Nonnumerical Algorithms and Problems]}}

\keywords{algorithms, computational geometry}

\supervisors{Antti Laaksonen and Jyrki Kivinen}

%default (40 cr thesis)
%\program{Computer Science}

%Computer Science Master's Programme thesis, 30 cr
%\program{Study Programme in Computer Science} 

%Data Science thesis, 30 cr
%\program{Master's Programme in Data Science}

%Bachelor's thesis 
%\level{Bachelor's thesis}
%Computer Science Bachelor's Programme (2017->) thesis
%\program{Bachelor's Programme in Computer Science}

% For CS Master's Programme thesis 2017->
%\additionalinformation{Thesis for the Algorithms study track }
%\additionalinformation{Thesis for the Networking and Services study track}
%\additionalinformation{Thesis for the Software Systems study track}

% For CS Master's thesis if you follow CS degree requirements prior 2017
%\additionalinformation{Thesis for the Algorithmic Bioinformatics subprogramme}
\additionalinformation{Thesis for the Algorithms, Data Analytics and Machine Learning subprogramme}
%\additionalinformation{Thesis for the Networking and Services subprogramme}
%\additionalinformation{Thesis for the Software Systems subprogramme}

%\level{Seminar essay}
%\additionalinformation{Essay for Seminar on ...}

\begin{abstract}
The thesis subject are algorithms for minimum link path computation.
Minimum link path is a geometric path that consists of straight line segments and does a minimal number of turns.
We present new algorithms to several variations of the minimum link path problem.
\end{abstract}

\mytableofcontents


\setcounter{section}{-1}
\section{Preface}

"If it was hard to write, it should be hard to read." -- anonymous

\section{Introduction}

Path finding problems are a widely studied subject in algorithmics.\cite{survey}
A typical task is finding the shortest path between two nodes in a graph.
Geometric version of the problem asks for the shortest path in a continuous space, such as plane with polygonal obstacles.
The typical task is to minimize the Euclidean length of the path, but there are other relevant metrics as well.
For example a robot might move forward fast, but be slow at corners, so a long simple route is sometimes preferable to a shorter but more complex route.

The topic of this thesis is finding geometric path the do minimum amount of turns.
Consider a path consisting of a finite number of straight line segments.
The \emph{link distance} of the path is the number of segments.
A \emph{minimum link path} between two points is a path that minimizes the link distance.

Finding minimum link paths is a well studied algorithmic problem.
The basic idea employed by most known algorithms is a simple extension of bredth-first search:
First find points that have link distance~1 to the starting point, then points with link distance~2, and similarly iterate until the desired endpoint is encountered.
Since the search happens in continuous space, the hard part of the algorithms is defining the appropriate data structures to store and update the discovered area.

In this thesis we focus on variants of the problem where the possible directions of the edges of the path are limited.
In $C$-oriented problem we are given a set $C$ of possible directions that the edges can take.
For the $C$-oriented problem, we present a new algorithm that works in time $O(C^2n\log n)$~\cite{revisited}.
We also study 3D version of the problem for a case where the only allowed directions are the coordinate axes.
For this problem we present a new algorithm that works in time $O(n^2\log^2n)$, which is a significant improvement over the earlier best known result $O(n^{2.5}\log n)$.\cite{restricted}
Finally, we extend the 3D solution to work in $D$-dimensional domains in time $O(n^D\log^Dn)$.

\subsection{Problem description}

The definition of the minimum link path problem is the following.
\begin{prob}\label{prob:path}
We are given a description of free space \fspace and two points $\spt\in\fspace$ and $\ept\in\fspace$.
The task is to find a path from \spt to \ept in \fspace with minimum link distance.
\end{prob}

Typically the algorithms for pathfinding start from one of the points, and search the area until the other point is found.
Often this approach allows us to create a data structure that can be used to efficiently find a path between \spt and any other point.
Thus the same algorithms can be applied to solve a problem where \ept is given only afterwards.

\begin{prob}\label{prob:map}
We are given a description of free space \fspace and a point $\spt\in\fspace$.
Construct a data structure that allows finding the minimum link path between \spt and any given point.
\end{prob}

\subsection{Overview of algorithms}\label{sec:overview}

All the known algorithms for the minimum link path problem use the same basic idea:
The tasks is to find a minimum link path from point \spt to point \ept.
Let \reach{k} be the set of points reachable by at most $k$ links from \spt.
Start by defining $\reach{0}=\set{\spt}$, and iteratively compute \reach{k+1} from \reach{k}.
The iteration continues until we find $k$ such that $\ept\in\reach{k}$.
This iteration is often called \emph{staged illumination}, because the computation of \reach{k+1} can be illustrated by setting a light source in all points of \reach{k}, and selecting all the lit points.

This process closely resembles the bredth-first search, but a key difference is that the search is done in continuous space rather than in a graph.
A nontrivial part in any minimum link path algorithm is maintaining the illuminated area in a data structure that allows efficient computation of \reach{k+1} from \reach{k}.

Representing the illuminated area can be simplified by first splitting the free space into simple primitives.
A common approach in computational geometry is to start by triangulating the input, which allows working with simple forms.
In case of minimum link paths with restricted orientations, rectangles or trapezoids are the most comfortable representations.
In Section~\ref{sec:decomposition} we present algorithms for construction decompositions suitable for minimum link path computation.

With restricted orientations that the paths can take, we can use \emph{sweep line algorithms} to efficiently compute \reach{k+1} from \reach{k}.
The idea is to "sweep" over the search space by a line, and use the sweep to calculate how the path can advance into the direction of the sweep line.
This generic technique allows us to transform the 2-dimensional illumination problem into a series of easier 1-dimensional problems on the sweep line.
The sweep line technique is discussed in Section~\ref{sec:sweep}.

During the sweeps we need to maintain the relationship between the sweep line and the obstacles as well as the region \reach{k}.
Maintaining this kind of information requires efficient handling of 1-dimensional intervals.
\emph{Segment tree} is a generic data structure for working with intervals.
It can be used to efficiently implement all the operations required by the staged illumination.
Segment trees are described in Section~\ref{sec:segtree}.

We combine the aforementioned concepts into an algorithm for finding minimum link paths in Section~\ref{sec:minlink2d}.
The ideas of the two-dimensional solution can also be generalized to work in higher dimensions.
Many details need to be taken care of, but the basic ideas are relatively straightforward to transfer to more than two dimensions.
The space is decomposed into cuboids instead of rectangles, and the sweep line is replaced by a sweep plane.
The segment tree can also be generalized into a higher dimensional structure.
These elements are combined into an algorithm for finding minimum link paths in higher dimensional domains in Section~\ref{sec:minlink3d}.



\section{Space decomposition}\label{sec:decomposition}

The domain of the minimum link path problem is a polygon with smaller polygons as obstacles.
The input is given as a list of polygons, and each polygon is described by a list of vertices.
This form is inconvenient for path planning algorithms, as many simple operations, such as checking whether we can move from a given point to given direction, require scanning through all the polygons.

In the rectilinear minimum link path problem the obstacle edges are oriented according to the coordinate axis.
This allows us to decomposition the free space into rectangles, which is a convenient form for rectilinear path computation.
For each cell of the decomposition we also construct links to neighboring cells and obstacles.
In other words, the decomposition is a graph with rectangles as vertices and an edge between each pair of adjacent rectangles.
If the total number of edges in all the obstacles is $n$, we can decompose the space into $O(n)$ cells such the total number of links between cells is also $O(n)$.

A similar structure can also be used for computing minimum link paths in 3-dimensional domains.
In 3D rectilinear case each obstacle face is a polygon with axis-aligned edges in 3D space.
In this case the free space can be decomposed into a graph with $O(n^2)$ cuboid as vertices and $O(n^2)$ edges.


\subsection{Sweep line algorithms}\label{sec:sweep}

Sweep line algorithms are a generic technique used for a wide range of computational geometry problems.
The idea is to image a line that crosses over the domain.
As the sweep line progresses, we gradually update the solution to take into account the parts of the domain that the line has crossed.
Conceptually the sweep line moves continuously in space, but in practice we only process a discrete set of \emph{events} where some structural change to the solution happens.


\subsection{Planar decomposition}\label{sec:decomp2d}

A rectilinear domain can be decomposed into rectangles by extending each horizontal obstacle edge in both directions until the sides hit a vertical obstacle edge.
This defines the \emph{horizontal decomposition} of the domain, denoted \decomp{x}.
The vertical decomposition \decomp{y} is defined correspondingly by extending all the vertical edges until they hit a horizontal obstacle.

It is easy to see that each cell of \decomp{x} touches at least one obstacle vertex.
Since each vertex can be touched by at most two rectangles, the size of the decomposition is $O(n)$.
Each pair of touching rectangles also shares a common obstacle corner, so the number of links is also $O(n)$.

\decomp{x} can be constructed with a line sweep algorithm.
We sweep over the domain by a horizontal line moving from $y$ coordinate $-\infty$ (down) to $\infty$ (up).
During the sweep we maintain the intersection of the free space \fspace and the sweep line.
The intersection consists of non-overlapping intervals, which we store in a binary search tree.

Each element added to the binary tree is a partially constructed rectangle $a$ with the following fields.
\begin{itemize}
\item Interval $\xrange{a}=\range{\xranget{a}{1}}{\xranget{a}{2}}$.
\item Interval $\yrange{a}=\range{\yranget{a}{1}}{\yranget{a}{2}}$.
\item List of neighbor links $\nbs{a}$.
\end{itemize}

The sweep stops at each horizontal obstacle edge.
When moving from down to up, each edge starts either starts or ends an obstacle.
If the edge starts an obstacle, the $x$-range of the edge is fully contained in one of the intervals in the search tree.
If the edge ends an obstacle, the $x$-range does not intersect any intervals in the tree, but the left and right endpoints may touch some intervals.
In both cases the intervals touching the encountered edge are removed from the search tree, and $O(1)$ new intervals are inserted to maintain the sweep line state.
A more exact description of the algorithm follows below.

\begin{alg}\label{alg:split2d}
Decomposition of \fspace into a group of rectangular cells \decomp{x}.
\begin{algorithmic}
\State $T\gets \text{Empty binary search tree}$.
\State $E\gets\text{All horizontal obstacle edges}$.
\State Sort $E$ by the $y$ coordinates of the edges.
\ForAll{$e\in E$}
	\If{$e$ starts an obstacle}
		\Comment Exactly one interval in $T$ intersects \xrange{e}.
		\State $v\gets\text{Lookup $T$ for interval touching \xrange{e}}$.
		\State Remove $v$ from $T$.
		\State $\yranget{v}{2}\gets\y{e}$.
		\ForAll{$u\gets v\setminus s$}
			\State $\yranget{u}{1}\gets\y{e}$.
			\State Insert $v$ to list $\nbs{u}$.
			\State $a\gets\text{New rectangle}$.
			\State $\xrange{a}\gets u$.
			\State $\yranget{a}{1}\gets\y{e}$.
			\State Insert $a$ to tree $T$.
		\EndFor
	\Else\Comment $e$ starts free space.
		\State $a\gets\text{New rectangle}$
		\State $\xrange{a}\gets\xrange{e}$.
		\State $\yranget{a}{1}\gets\y{e}$.
		\ForAll{$v\in$ lookup $T$ for intervals touching \xrange{e}}
			\State Remove $v$ from $T$.
			\State Insert $v$ to list \nbs{a}.
			\State $\xrange{a}\gets\xrange{a}\cup\xrange{v}$.
		\EndFor
		\State Insert $a$ to $T$.
	\EndIf
\EndFor
\end{algorithmic}
\end{alg}

The complexity of the algorithm can be easily bounded.

\begin{lem}\label{lem:split2dtime}Algorithm~\ref{alg:split2d} works in time $O(n\log n)$ and space $O(n)$.\end{lem}
\begin{proof}
The algorithm sorts all the horizontal edges in time $O(n\log n)$, and iterates over them in $O(n)$ steps.
On each step we emit $O(1)$ cells and neighbor links, and perform $O(1)$ operations to the binary search tree.
The search tree is a balanced binary tree, so each operation to it is carried out in time $O(\log n)$.
Thus the total complexity of the algorithm is $O(n\log n)$, and we only need $O(n)$ storage for the edge list and the binary search tree.
\end{proof}

\subsection{3D cuboid decomposition}\label{sec:split3d}

Similarly as a 2D domain can be decomposed into rectangles, a 3D rectilinear domain can be decomposed into cuboids.
Decomposition into cuboids is used in the algorithm for 3D minimum link paths in Section~\ref{sec:minlink3d}.
The running time of the path finding algorithm is heavily depent on the size of the decomposition, so it is desirable to find as small decomposition as possible.

The input is given as a list of 2-dimensional obstacle faces in 3-dimensional space.
Each obstacle face is a polygon defined by a list of vertices.
Denote the total number of vertices by $n$.

We present a simple algorithm that uses the Algorithm~\ref{alg:split2d} as a subroutine.
This algorithm produces a decomposition with $O(n^2)$ cells and $O(n^2)$ links.
There also exists algorithms for finding decompositions with even small number of cells, but the worst case for number of links is superquadratic for all the known solutions.

The solution is a sweep plane algorithm, whichi sweeps through the domain with a plane perpendicular to $z$-axis.
During the sweep we maintain the intersection of the sweep plane and the domain~\fspace.
The intersection of the domain and a plane is called a \emph{cross section} of the domain.

In each cross section we form a 2D decomposition of the domain with Algorithm~\ref{alg:split2d}, and extend the $xy$-rectangles in $z$-direction so that they fill the whole free space.
Any common rectangles shared by consecutive cross sections are merged into a single larger cuboid.
The merging is done by by maintaining a binary search tree of the cells of the previous decomposition.

The description below only calculates the cells, but not the links between them.
We discuss the computation of links below.

\begin{alg}\label{alg:split3d}
Decompose the free space defined by a set $E$ of obstacle faces into cuboids.
\begin{algorithmic}
\State $Z\gets$ All $z$-coordinates of obstacle vertices.
\State Sort $Z$ in increasing order.
\State $R\gets$ Empty list of result cells.
\State $M\gets$ Empty binary search tree mapping 2D rectangles to indices in $R$.
\ForAll{$z\in Z$}
	\State $E_z\gets\set{e \mid e\in E, \zrange{e}\ni z}$.
	\State $T\gets$ 2D decomposition for $E_z$ using Algorithm~\ref{alg:split2d}.
	\ForAll{$m\in M\setminus T$}
		\State $c\gets R[M[m]]$.
		\State Upper $z$-coordinate of $c\gets z$.
		\State Remove $m$ from $M$.
	\EndFor
	\ForAll{$t\in T\setminus M$}
		\State $c\gets$ New cell with $xy$-bounds $t$ and starting $z$-coordinate $z$.
		\State Insert $c$ into $R$.
		\State $M[t]\gets$ index of $c$ in $R$.
	\EndFor
\EndFor
\State Return list $R$.
\end{algorithmic}
\end{alg}

The running time of the algorithm is easy to determine using Lemma~\ref{lem:split2dtime}.

\begin{lem}\label{lem:split3dtime}Algorithm~\ref{alg:split3d} has running time $O(n^2\log n)$.\end{lem}
\begin{proof}
We loop through $O(n)$ unique $z$-coordinates.
For each $z$ we construct a set of obstacles in time $O(n)$ and a 2D decomposition in time $O(n\log n)$.
The map $M$ is implemented as a binary search tree, so each update and lookup can be performed in time $O(\log n)$.
For each $z$ we perform $O(n)$ such updates, so the total time bound is $O(n^2\log n)$.
\end{proof}

Algorithm~\ref{alg:split3d} divides the space into cuboids, but does not generate any links between them.
First we bound the number of links.
The following lemma helps in the analysis.

\begin{lem}\label{lem:decomp2dch}
Consider two obstacle sets $A$ and $B$ on 2D plane.
Let $n$ be the total number of obstacle edges in $A$ and $B$, and $k$ be the number of edges that are present in exactly one of the sets.
The number of overlapping rectangles in \decomp{x}(A) and \decomp{x}(B) is $O(nk)$.
\end{lem}
\begin{proof}
Consider how the sweep line of Algorithm~\ref{alg:split2d} advances in domains $A$ and $B$.
Recall that the sweep line is a horizontal line moving in $y$-direction.

The intersection of the sweep line and the free space is a sequence of disjoint intervals for both $A$ and $B$.
Since there are $O(k)$ changes to the set of obstacles, the edit distance between the interval sets is $O(k)$.
Thus each $y$ coordinate contributes $O(k)$ pairs to the overlap.
Since the number of $y$ coordinates where the domain changes is $O(n)$, the total number of overlapping pairs is $O(nk)$.
\end{proof}

\begin{lem}\label{lem:split3dcount}The number of pairs of adjacent cells in the decomposition produced by Algorithm~\ref{alg:split3d} is $O(n^2)$.\end{lem}
\begin{proof}
Since the number of links produced by Algorithm~\ref{alg:split2d} is $O(n)$, any cross section has $O(n)$ links in $x$ and $y$ directions.
Thus the total number of $x$ and $y$ links is $O(n^2)$.

Let $k_z$ be the number of different obstacles on the cross sections on planes $z=z_k-\varepsilon$ and $z=z_k+\varepsilon$.
Since the total number of obstacles is $n$, the sum of different $k_z$ values is $n$.
The number of links between two adjacent layers is $O(nk_z)$ by Lemma~\ref{lem:decomp2dch}.
Summing up all the changes gives the desired bound $\sum_z O(nk_z) = O(n^2)$.
\end{proof}

Since we know how to compute links for 2D decomposition, the links in $x$ and $y$ directions can easily be obtained from the cross sections.
What remains is computing the links in $z$ direction.
We compute the links between each pair of adjacent cross sections separately.

Let $A$ and $B$ be the sets of rectangles that are different on the horizontal decompositions of two adjacent cross sections.
Finding the $z$-links in the 3D decomposition is equivalent to finding the set of overlapping pairs between $A$ and $B$.
The pairs are found by running \emph{another} line sweep algorithm after both $A$ and $B$ have been created by Algorithm~\ref{alg:split2d}.

We sweep through the domain again by a horizontal line.
During the sweep we maintain two binary search tree $T_A$ and $T_B$, containing the rectangles of $A$ and $B$ touching the sweep line respectively.
The binary search tree is ordered by the $x$-coordinate of the rectangle.
Note that the rectangles in each of the sets $A$ and $B$ are disjoint, so the $x$-ranges are disjoint as well.

Each time the sweep line arrives into a new rectangle $a\in A$, the tree $T_B$ is queries to find all the rectangles touched by the bottom line of $a$.
Similarly for each new rectangle $b\in B$, we query the tree $T_A$ for rectangles touching the bottom line of $b$.
A more exact description of the algorithm is below.

\begin{alg}\label{alg:overlap2d}
Find all overlapping pairs of two sets of rectangles $A$ and $B$.
\begin{algorithmic}
\State $E\gets$ All bottom and top edges of rectangles in $A$ and $B$.
\State Sort $E$ by $y$-coordinate.
\State $T_A\gets$ Empty binary search tree.
\State $T_B\gets$ Empty binary search tree.
\ForAll{$e\in E$}
	\State $s\in\set{A,B}\gets$ Group to which $e$ belongs to.
	\State $t\in\set{A,B}\gets$ Group to which $e$ does not belong to.
	\If{$e$ starts a rectangle}
		\State Find all elements from $T_t$ with $x$-range intersection the $x$-range of $e$.
		\State Add the rectangle to $T_x$.
	\Else
		\State Remove the rectangle from $T_x$.
	\EndIf
\EndFor
\end{algorithmic}
\end{alg}

\begin{lem}\label{lem:overlap2dtime}Algorithm~\ref{alg:overlap2d} runs in time $O(n\log n + k)$, where $n$ is the total size of $A$ and $B$, and $k$ is the number of overlapping pairs.\end{lem}
\begin{proof}
First we sort all the top and bottom edges in the input in time $O(n\log n)$.
We then iterate over all the edges, performing 3 kinds of tree operations: add, remove and lookup.

Each add and lookup operation takes $O(\log n)$ time in a balanced binary search tree.
The lookup of elements intersecting the given element is done by first finding the leftmost intersecting element in the tree, and then scanning adjacent tree nodes until all the intersecting elements have been found.
This requires time $O(\log n+u)$ where $u$ is the number of overlapping pairs.

Combining the time for sorting, tree additions, deletions and lookups, the total complexity is $O(n\log n + k)$.
\end{proof}

We are now ready to prove the main result of this section.

\begin{theo}\label{theo:split3dtime}3D rectilinear domain defined by obstacles with a total of $n$ vertices can be decomposed into $O(n^2)$ cuboids with $O(n^2)$ links between them in time $O(n^2\log n).$\end{theo}
\begin{proof}
The cuboids can be constructed in time $O(n^2\log n)$ according to Lemma~\ref{lem:split3dtime}.
The total number of links between the nodes is $k=O(n^2)$ according to Lemma~\ref{lem:split3dcount}.
Computing the links between all the layers can then be done in time $O(n^2\log n+k)=O(n^2\log n)$ by Lemma~\ref{lem:overlap2dtime}.
Thus the total time complexity is $O(n^2\log n)$, and the total number of cuboids and links is $O(n^2)$.
\end{proof}



\subsection{Higher dimensional decomposition}

The ideas of the 3D decomposition can be generalized to allow decomposing 4D and higher dimensional rectilinear domains into hyperrectangles.
The construction is done recursively, so that $D$-dimensional decomposition is created by solving a sequence of $(D-1)$-dimensional sub-problems.
The idea is identical to how the 3D decomposition is constructed based on a sequence of 2D decompositions in Algorithm~\ref{alg:split3d}.

\begin{alg}\label{alg:splitdd}
Decompose the free space defined by a set $E$ of $(D-1)$-dimensional obstacle faces into $D$-dimensional hyperrectangles.
\begin{algorithmic}
\If{$D=2$}
	\State Compute the decomposition using Algorithm~\ref{alg:split2d} and return.
\EndIf
\State $Z\gets$ All $D$-coordinates of obstacle vertices.
\State Sort $Z$ in increasing order.
\State $R\gets$ Empty list of result cells.
\State $M\gets$ Empty binary search tree mapping $D-1$-dimensional rectangles to indices in $R$.
\ForAll{$z\in Z$}
	\State $E_z\gets\set{e \mid e\in E, e_D\ni z}$.
	\State $T\gets$ $(D-1)$-dimensional decomposition for $E_z$ recursively.
	\ForAll{$m\in M\setminus T$}
		\State $c\gets R[M[m]]$.
		\State Upper $D$-coordinate of $c\gets z$.
		\State Remove $m$ from $M$.
	\EndFor
	\ForAll{$t\in T\setminus M$}
		\State $c\gets$ New cell with the first $D-1$ coordinates defined by $t$ and starting $D$-coordinate $z$.
		\State Insert $c$ into $R$.
		\State $M[t]\gets$ index of $c$ in $R$.
	\EndFor
\EndFor
\State Return list $R$.
\end{algorithmic}
\end{alg}

The analysis is similar to the 3D case, except that we now use induction on $D$.

\begin{lem}\label{lem:splitddcells}The number of rectangles produced by Algorithm~\ref{alg:splitdd} is $O(n^{D-1})$.\end{lem}
\begin{proof}
Proof by induction on $D$.
Since the size of the horizontal decomposition of 2D space is $O(n)$, the claim is clearly true for $D=2$.
For $D>2$, we loop over the $O(n)$ unique values of the $D$-coordinate in the obstacles.
For each cross-section we compute a $(D-1)$-dimensional decomposition, whose size is $O(n^{D-2})$ by induction.
The combination of the $n$ sub-problem results has thus size $O(n^{D-2}n)=O(n^{D-1})$.
\end{proof}

\begin{lem}\label{lem:splitddtime}The running time of Algorithm~\ref{alg:splitdd} is $O(n^{D-1}\log n)$.\end{lem}
\begin{proof}
Proof by indunction on $D$.
Since we use Algorithm~\ref{alg:split2d} for case $D=2$, Lemma~\ref{lem:split2dtime} proves the base case $D=2$.

For $D>2$, we solve $O(n)$ sub-problems, each of which can be done in time $O(n^{D-2}\log n)$ by induction.
The total time of solving all the sub-problems is thus $O(n^{D-1}\log n)$.

We also maintain a mapping from $(D-1)$-dimensional hyperrectangles to result indices.
The size of the mapping is bounded by the size of the $(D-1)$-dimensional decompositions, which have size $O(n^{D-2})$ by Lemma~\ref{lem:splitddcells}.
Thus each map operation can be done in time $O(\log{n^{D-2}})=O(\log n)$.
The number of map operations for each cross-section is $O(n^{D-2})$, so the total time spent in the map operations is $O(nn^{D-2}\log n)=O(n^{D-1}\log n)$.
\end{proof}

We can similarly prove a bound for the number of links with induction that uses the proofs for 2D and 3D domains as the base case.

\begin{lem}\label{lem:decompddch}
Consider two obstacle sets $A$ and $B$ that each define a $D$-dimensional domain.
Let $n$ be the total number of $(D-1)$-dimensional obstacle faces in $A$ and $B$, and $k$ be the number of faces that are present in exactly one of the sets.
The number of overlapping $D$-dimensional hyperrectangles in the decompositions of $A$ and $B$ is $O(n^{D-1}k)$.
\end{lem}
\begin{proof}
Proof by induction on $D$.
The base case $D=2$ is proven by Lemma~\ref{lem:decomp2dch}.

For $D\ge 3$ consider how the sweeps of Algorithm~\ref{alg:split3d} advance in domains defined by $A$ and $B$.
Each of the sweeps stops at $O(n)$ points, producing a $(D-1)$-dimensional decomposition for the cross section.
For any $D$-coordinate, the cross-sections of the domains of $A$ and $B$ differ by $O(k)$ obstacles, so the number of links at a fixed $D$-coordinate is $O(n^{D-2}k)$ by induction.

The total number of links between the two decompositions is the total number of links counted in each of the $O(n)$ cross-sections.
This may count some links multiple times, but each link is counted at least once.
Each cross-section has $O(n^{D-2}k)$ links, so the total number of links has upper bound $O(n^{D-1}k)$.
\end{proof}

\begin{lem}\label{lem:splitddcount}The number of links between adjacent pairs of hyperrectangles produced by Algorithm~\ref{alg:splitdd} is $O(n^{D-1})$.\end{lem}
\begin{proof}
Consider separately the links in direction $D$ and in the other directions.
For both cases, we count the number of links using induction on $D$.
For the base case of the induction, the number of links in case $D=2$ is $O(n)$, as shown in Section~\ref{sec:decomp2d}.

The links in directions other than $Z$ can be obtained from the $(D-1)$-dimensional decompositions produced during the sweep.
By induction, the number of links in each $(D-1)$-decomposition is $O(n^{D-2})$, so the total number of links in directions other than $Z$ is $O(n^{D-1})$.

To count the number of links in direction $D$, observe how the cross-section changes as the sweep hyperplane advances through the domain.
If two adjacent cross sections differ by $u$ obstacles, the number of links between the cross-sections is $O(n^{D-2}u)$ by Lemma~\ref{lem:decompddch}.
The total number of obstacles changing during the sweep is $O(n)$, so the total count of the links between all adjacent levels is $O(n^{D-1})$.
\end{proof}

The proof of Lemma~\ref{lem:splitddcount} gives a hint for designing an algorithm to compute the links.
Similarly to the proof, we consider separately the links in direction $D$ and in the other directions.
The links in directions other than $D$ can be obtained recursively from the solutions of the sub-problems.
The links in direction $D$ are computed by performing an additional sweep between each pair of adjacent cross-sections and using a recursive method similar to the proof above.
Each sweep finds the direction $D$ links by using the following recursive algorithm.

\begin{alg}\label{alg:overlapdd}
Find all overlapping pairs of two sets of $D$-dimensional hyperrectangles $A$ and $B$.
\begin{algorithmic}
\If{$D=2$}
	\State Compute the overlapping pairs using Algorithm~\ref{alg:overlap2d} and return.
\EndIf
\State $E\gets$ List of all faces of hyperrectangles in $A$ and $B$ perpendicular to $D$-axis.
\State Sort $E$ by $D$-coordinate.
\State $G\gets$ Groups of consequtive elements of $E$ with equal $D$-coordinate.
\State $P_A\gets$ Empty set of integers.
\State $P_B\gets$ Empty set of integers.
\State $R\gets$ Empty list of pairs.
\ForAll{$g\in G$}
	\State $S_A\gets$ Starting elements of $A$ in $g$.
	\State $S_B\gets$ Starting elements of $B$ in $g$.
	\State $T_A\gets$ Ending elements of $A$ in $g$.
	\State $T_B\gets$ Ending elements of $B$ in $g$.
	\State $P_A\gets P_A\setminus T_A$.
	\State $P_B\gets P_B\setminus T_B$.
	\State Recursively compute overlap between $P_A$ and $S_B$ into $R$.
	\State Recursively compute overlap between $S_A$ and $P_A$ into $R$.
	\State Recursively compute overlap between $S_A$ and $S_A$ into $R$.
	\State $P_A\gets P_A\cup S_A$.
	\State $P_B\gets P_B\cup S_B$.
\EndFor
\State Return list $R$.
\end{algorithmic}
\end{alg}

The algorithm processes each set of events with equal $D$-coordinate as a single unit.
For each unit we recursively search for new links between the newly added hyperrectangles, as well as between old and new hyperrectangles.
We maintain the set of hyperrectangles currently intersecting the sweep hyperplane to avoid adding already included intersections to the result twice.

\begin{lem}\label{lem:overlapddok}
Algorithm~\ref{alg:overlapdd} finds each intersecting pair between the input sets $A$ and $B$ exactly once.
\end{lem}
\begin{proof}Left as an exercise.\end{proof}

The algorithm for the $D$-dimensional overlap computation is simpler than the special case for $D=2$.
However Lemma~\ref{lem:overlap2dtime} cannot be directly extended to higher dimensions, because there is no guarantee that the subproblems are significantly smaller than the original problem.
Instead we prove a less generic lemma by using the properties of the decompositions.

\begin{lem}\label{lem:overlapddtime}
Let $A$ and $B$ be two decompositions generated by Algorithm~\ref{alg:splitdd} for two different inputs that have a total of $n$ obstacles.
Then Algorithm~\ref{alg:overlapdd} runs in time $O(n^{D-1}\log n + k)$ for inputs $A$ and $B$, where $k$ is the number of overlapping pairs.
\end{lem}
\begin{proof}
Proof by induction on $D$.
The base case $D=2$ is proven by Lemma~\ref{lem:overlap2dtime}.

For $D\ge 3$, the decomposition is created by combining the $(D-1)$-dimensional decompositions at each cross section.
Thus the sweep hyperplane of Algorithm~\ref{alg:overlapdd} intersects a $(D-1)$-dimensional decomposition produced by Algorithm~\ref{alg:splitdd} at each point of the sweep.
By Lemma~\ref{lem:splitddcells} this implies that the index sets maintained during the sweep have size $O(n^{D-2})$.
Performing the set operations on the $n$ steps of the sweep then has total time complexity $O(n^{D-1}\log n)$.

The time taken by each of the 3 recursive calls on each cross section is $O(n^{D-2}\log n + u)$ by induction, where $u$ is the number of overlapping pairs returned from the subproblem.
By Lemma~\ref{lem:overlapddok} each intersection is found exactly once, so the total complexity of the recursive calls during the sweep is $O(n^{D-1}\log n + k)$.
\end{proof}

Finally, we can generalize Theorem~\ref{theo:split3dtime} to $D$ dimensions.

\begin{theo}\label{theo:splitddtime}$D$-dimensional rectilinear domain defined by obstacles with a total of $n$ vertices can be decomposed into $O(n^{D-1})$ hyperrectangles with $O(n^{D-1})$ links between them in time $O(n^{D-1}\log n).$\end{theo}
\begin{proof}
The cuboids can be constructed in time $O(n^{D-1}\log n)$ according to Lemma~\ref{lem:splitddtime}.
The total number of links between the nodes is $k=O(n^{D-1})$ according to Lemma~\ref{lem:splitddcount}.
Computing the links between all the layers can then be done in time $O(n^{D-1}\log n+k)=O(n^2\log n)$ by Lemma~\ref{lem:overlapddtime}.
Thus the total time complexity is $O(n^{D-1}\log n)$, and the total number of cuboids and links is $O(n^{D-1})$.
\end{proof}



\section{Segment tree}\label{sec:segtree}

Segment tree is a data structure that allows storing and querying of number intervals.
The structure allows performing a wide range of operations in logarithmic time.
Some example of operations that can be implemented include:
\begin{itemize}
	\item Insert and remove interval to the tree.
	\item Find all the intervals intersecting a given query interval.
	\item Cut of a given range from all the ranges in the tree.
\end{itemize}

Rather than as a single data structure that is used as a black box, the segment trees are better viewed as a framework that can be adapted to work in various situations.
Segment trees are straightforward to augment to contain additional information about the intervals, and use the information in queries.
For example we can associate a number with each interval, and efficiently query for the maximum number overlapping a given query interval.
We first present the general idea of the tree, and then show how it can be applied to the minimum link path problem.

Segment trees are typically implemented as semi-dynamic structures.
This means that the tree can be efficiently modified after it has been build, but we need to specify the set of possible endpoints \epts of intervals in advance.
This allows implementing most operations in time $O(\log\segsize)$, and the size of the tree is $O(\segsize)$, where $\segsize=\size{\epts}$.

\subsection{Structure of a segment tree}

A segment tree is a binary tree where each node $n$ corresponds to a fixed half-open interval $\inter{n}$.
Each branch node $s$ has two child nodes \leftc{s} and \rightc{s}.
The intervals of the children divide the parent interval into two parts:
$\inter{s}=\inter{\leftc{s}}\cup\inter{\rightc{s}}$, $\inter{\leftc{s}}\cap\inter{\rightc{s}}=\emptyset$.
The root node corresponds the largest supported interval \range{\epts[1]}{\epts[\segsize]}, and the leaf nodes correspond to the smallest possible intervals \range{\epts[i]}{\epts[i+1]}.

The structure of a semi-dynamic segment tree is independent of the intervals added to the tree.
The nodes are commonly arranged into an almost complete binary tree, which allows storing the tree nodes in an array similarly to binary heap:
the root node is stored in index~1, and the child nodes of node $i$ are $2i$ and $2i+1$.
This representation allows implementing segment tree operations with very low overhead, making segment tree a powerful practical tool in addition to providing asymptotical bounds.

\subsection{Canonical nodes}

When an interval $I$ is added to a segment tree, it is added to several tree nodes called the \emph{canonical nodes} of $I$, denoted by \canon{I}.
The canonical nodes of $I$ are the smallest set of nodes whose intervals cover $I$ but nothing else: $\cup_{c\in\canon{I}} \inter{c}=I$.

Let \canonpar{I} be the set of ancestors of \canon{I}.
The following two lemmas are useful for proving the running times of segment tree operations.

\begin{lem}\label{lem:canonlog}$\size{\canon{I}}=O(\log\segsize)$ for any interval $I$.\end{lem}
\begin{proof}
As the segment tree is a balanced binary tree, it has depth $\Theta(\log\segsize)$.
We show that $\canon{I}$ contains at most 2 nodes on each depth, which proves the claim.

If a set $N$ contains 3 nodes on the same depth, we can replace the middle one with its parent node without affecting the interval covered by $N$.
Thus $N$ is not a minimal cover of $I$, and can not be \canon{I}.
\end{proof}

\begin{lem}\label{lem:canonplog}$\size{\canonpar{I}})=O(\log\segsize)$ for any inverval $I$.\end{lem}
\begin{proof}
Similarly to the previous proof we show that \canonpar{I} cannot contain more than 2 nodes on the same depth.

Suppose, for a contradiction, that \canonpar{I} contains 3 nodes on the same depth: $a$, $b$ and $c$ in that order.
Then $\inter{a}\cap I\neq\emptyset$ and $\inter{c}\cap I\neq\emptyset$, so $\inter{b}\subseteq I$.
Some grandchild of $b$ belongs to \canon{I}, so \canon{I} is not a minimal cover, which is a contradiction.
\end{proof}

We can iterate over the canonical nodes and their parents by using the following recursive algorithm starting from the root node.

\begin{alg}\label{alg:segiter}
Visit all the elements of \canon{I} and \canonpar{I}.
\begin{algorithmic}
\Procedure{IterCanonical}{$n$}
\Comment{Visit the canonical nodes in the subtree rooted at node $n$}
	\If{$\inter{n}\subseteq I$}
		\State \visitc($n$)
	\ElsIf{$\inter{n}\cap I\neq\emptyset$}
		\State \visitp($n$)
		\State \textsc{IterCanonical}($\leftc{n}$)
		\State \textsc{IterCanonical}($\rightc{n}$)
	\EndIf
\EndProcedure
\end{algorithmic}
\end{alg}

Algorithm~\ref{alg:segiter} can be used to implement other tree operations such as adding intervals to segment tree by defining the called methods \visitc and \visitp appropriately.
The recursion traverses through the nodes in \canonpar{I}, and stops immediately when it arrives either to a node in \canon{I} or to a node neither in \canon{I} nor in \canonpar{I}.
Thus the running time is proportional to the sizes of \canon{I} and \canonpar{I}, which is $O(\log\segsize)$ by Lemma~\ref{lem:canonlog} and Lemma~\ref{lem:canonplog}.

\subsection{Tree operations}

We now show how the segment trees can be used for finding intersecting intervals.

\begin{lem}\label{lem:segintersect}Consider any two intervals $I$ and $J$.
At least one of the following is true if and only if $I\cap J\neq\emptyset$.
\begin{enumerate}
\item $\canon{I}\cap\canon{J}\neq\emptyset$,
\item $\canon{I}\cap\canonpar{J}\neq\emptyset$,
\item $\canonpar{I}\cap\canon{J}\neq\emptyset$.
\end{enumerate}
\end{lem}
\begin{proof}
First suppose that $I\cap J\neq\emptyset$.
Let $x$ be any leaf node of the segment tree such that $\inter{x}\in I\cap J$.
Let $A$ be the set of ancestors of $x$.
Since the canonical nodes of an interval cover the whole interval, $A$ intersects both \canon{I} and \canon{J}.
Let $i$ and $j$ be the nodes where $A$ intersects with \canon{I} and \canon{J} respectively.
Either $i$ and $j$ are the same node, or one of them is an ancestor of the other, which proves the "if" part of the claim.

For the "only if" part, we look at the three cases separately.
\begin{enumerate}
\item If there exists a node $n\in\canon{I}\cap\canon{J}$, then $\inter{n}\subseteq I\cap J$, so $I\cap J\neq\emptyset$.
\item If there is a node $n\in\canonpar{I}\cap\canon{J}$, then there exists $m\in\canon{I}$ that is a grandchild of $n$. $\inter{m}\subseteq I$ and $\inter{m}\subsetneq\inter{n}\subseteq J$, so $I\cap J\neq\emptyset$.
\item Identical to the second case.
\end{enumerate}
\end{proof}

Lemma~\ref{lem:segintersect} can be used to find intersecting pairs of intervals in a segment tree.
In each node $n$ of the segment tree, maintain two lists of intervals:
\begin{itemize}
\item \nodecs{n}: Intervals $I$ for which $n\in\canon{I}$,
\item \nodeps{n}: Intervals $I$ for which $n\in\canonpar{I}$.
\end{itemize}
When interval $I$ is added to the segment tree, it is added to \nodecs{n} for all $n\in\canon{I}$ and to \nodeps{n} for all $n\in\canonpar{I}$.
When we look for intervals intersecting a given interval $J$, we report all the intervals in \nodecs{n} for all $n\in\canonpar{J}$ and in \nodeps{n} for all $n\in\canon{J}$.
By Lemma~\ref{lem:segintersect} this finds exactly the intervals intersecting $J$ and nothing else.
Note, though, that some intervals might be counted multiple times.
The structure can be further extended to avoid reporting the duplicates, but for the minimum link paths use case we only need to be able to check whether the query interval overlaps any of the intervals in the tree, so this solution is sufficient.

We also want to support clearing an interval from the tree.
Clearing interval $I$ means that all the intervals $J$ in the tree are cut into $J\setminus I$, potentially removing $J$ completely or cutting it into two parts.

The clear operation is implemented by visiting all the canonical nodes and their parents recursively similarly to Algorithm~\ref{alg:segiter}.
When the recursion reaches a canonical node of $I$, the entire subtree is cleared.
For nodes $n\in\canonpar{I}$ we push down the intervals in \nodecs{n} to the child nodes before proceeding with the recursion.
This allows us to clear only the parts of the intervals covered by $I$ without removing the other parts.
After the child nodes are cleared, we also need to regenerate the \nodeps{n} list for the nodes $n\in\canonpar{I}$ to remove intervals that were fully removed from the subtree.
The regeneration is done by merging the lists in the child nodes of $n$.
The exact algorithm for clearing is below.

\begin{alg}\label{alg:segrm}
Clear interval $I$ from a segment tree.
\begin{algorithmic}
\Procedure{ClearInterval}{$n$}
	\Comment Clears interval $I$ from subtree rooted at $n$.
	\If{$\inter{n}\subseteq I$}
		\State ClearSubtree($n$).
	\ElsIf{$\inter{n}\cap I\neq\emptyset$}
		\State Copy \nodecs{n} to \nodecs{\leftc{n}} and to \nodecs{\rightc{n}}.
		\State \textsc{IterCanonical}($\leftc{n}$)
		\State \textsc{IterCanonical}($\rightc{n}$)
		\State $\nodeps{n}\gets \nodeps{\leftc{n}} \cup \nodeps{\rightc{n}} \cup \nodecs{\leftc{n}} \cup \nodecs{\rightc{n}}$.
	\EndIf
\EndProcedure

\Procedure{ClearSubtree}{$n$}
	\Comment Fully clears the subtree rooted at $n$.
	\State Clear \nodecs{n}.
	\If{\nodeps{n} is not empty}
		\State Clear \nodeps{n}.
		\State ClearSubtree(\leftc{n}).
		\State ClearSubtree(\rightc{n}).
	\EndIf
\EndProcedure
\end{algorithmic}
\end{alg}

The running time of Algorithm~\ref{alg:segrm} depends on the time taken for copying and merging the intervals stored in the tree nodes.
If we are only interested in querying whether a given interval overlaps any interval in the tree rather than finding the overlapping intervals, we can replace the interval lists by booleans indicating whether the list is empty.
We analyze this more simple case.

\begin{lem}Suppose that the copying and merging of interval sets in Algorithm~\ref{alg:segrm} can be done in constant time.
Then the time complexity of clearing range $I$ is $O(\log\segsize + k)$, where $k$ is the number of cleared nodes.\end{lem}
\begin{proof}
The function $\textsc{ClearInterval}$ traverses through nodes \canon{I} and \canonpar{I}, whose count is $O(\log\segsize)$ by Lemma~\ref{lem:canonlog} and Lemma~\ref{lem:canonplog}.
In each node we do a constant amount of work, not counting the calls to $\textsc{ClearSubtree}$.

The function $\textsc{ClearSubtree}$ returns immediately for empty nodes, and for cleared nodes performs constant amount of additional work to recurse further.
Thus all the work in $\textsc{ClearSubtree}$ can be accounted for the cleared nodes, so the total time complexity is $O(\log n + k)$.
\end{proof}


\subsection{Multidimensional segment tree}

The segment tree can be generalized into two or higher dimensional structure.
A two-dimensional segment tree stores rectangles, and allows efficient queries for rectangular regions.
Correspondingly a $D$-dimensional segment tree provides efficient operations for $D$-dimensional hyperrectangles.

A multidimensional segment tree is composed of of nested regular segment trees.
The shape of a $D$-dimensional segment tree is a 1-dimensional segment tree whose each node stores a $(D-1)$-dimensional segment tree.

Each tree dimension represents one of the $D$ coordinate axes.
Each node $n$ of the innermost segment tree represents a $D$-dimensional hyperrectangle \rect{n}, whose bounds are defined by the position of the node on each of the $D$ tree levels.
For example the outer tree of a 2-dimensional segment tree represents the $y$ coordinates, and each inner tree represents the $x$ coordinates.
Each node of the inner tree represents a rectangle whose $x$-bounds are determined by the position of the node in the inner tree, and the $y$-bounds are determined by the node of the outer tree that contains the inner tree.

The concept of canonical nodes can also be extended to higher dimensions.
The canonical nodes \canon{R} of a $D$-dimensional hyperrectangle $R$ are the smallest set of nodes that fully cover $R$ but nothing else.

In order to compute the canonical nodes, let us look into each axis separately.
Let interval $R_i$ be the projection of hyperrectangle $R$ into $i$-axis.
Let $\canoni{R_i}{i}$ be the canonical rectangles of $R_i$ in the 1-dimensional segment tree built for $i$-coordinates.

Consider a 2-dimensional segment tree, and two arbitrary nodes of the projected 1-dimensional trees $c_1\in\canoni{R_1}{1}$ and $c_2\in\canoni{R_2}{2}$.
Let $c_1\times c_2$ be the node of the 2-dimensional tree that is found in position of $c_1$ in the inner tree, and $c_2$ in the outer tree.
Similarly for $D$-dimensional trees we define product $c_1\times c_2\times\dots\times c_n$ to be the node of a $D$-dimensional segment tree defined by positions of 1-dimensional tree nodes.
The following lemma shows how the canonical nodes of 1-dimensional projections can be combined to get the canonical nodes of a $D$-dimensional tree.

\begin{lem}\label{lem:canond}
For any $D$-dimensional hyperrectangle $R$ applies
$$\canon{R}=\set{c_1\times c_2\dots\times c_D \mid c_1\in\canoni{R_1}{1}, \dots, c_D\in\canoni{R_D}{D}}.$$
In other words, \canon{R} is the Cartesian product of one-dimensional canonical sets
$$\canon{R}=\bigtimes_{i=1}^D \canoni{R_i}{i}.$$
\end{lem}
\begin{proof}Left as an exercise.\end{proof}

Combination of Lemma~\ref{lem:canond} and Lemma~\ref{lem:canonlog} gives bound for the size of the canonical set.

\begin{lem}$\size{\canon{R}}=O(\log^D\segsize)$ for any $D$-dimensional rectangle $R$.\end{lem}
\begin{proof}
$$
\size{\canon{R}} = \size{\bigtimes_{i=1}^D \canoni{R_i}{i}}
= \prod_{i=1}^D \size{\canoni{R_i}{i}}
= \prod_{i=1}^D O(\log\segsize)
= O(\log^D\segsize).
$$
\end{proof}

For 1-dimensional segment trees there is a clear connection between the child-parent hierarchy and interval overlap.
For any two tree nodes $a$ and $b$, $\inter{a}\subseteq\inter{b}$ if and only if $b$ is an ancestor of $a$ in the tree.
In multidimensional case it also applies that if $b$ is an ancestor of $a$, then $\rect{a}\subseteq\rect{b}$.
However the reverse is not true; $\rect{a}\subseteq\rect{b}$ does not imply that $b$ is an ancestor of $a$ because $b$ can be in a different subtree in some of the outer trees.

Instead of looking for parent-child relationships directly in the tree, we can look at them separately on each coordinate axis.
This allows us to generalize Lemma~\ref{lem:segintersect} for segment interaction to work for rectangles.

\begin{lem}\label{lem:rectintersect}Consider any two $D$-dimensional hyperrectangles $A$ and $B$.
If $A\cap B\neq\emptyset$, then the following holds for each coordinate axis $d\in\set{1,\dots,D}$.
\begin{enumerate}
\item $\canoni{A_d}{d}\cap\canoni{B_d}{d}\neq\emptyset$,
\item $\canoni{A_d}{d}\cap\canonpari{B_d}{d}\neq\emptyset$,
\item $\canonpari{A_d}{d}\cap\canoni{B_d}{d}\neq\emptyset$.
\end{enumerate}
Furthermore, if $A\cap B=\emptyset$, then there is at least one coordinate axis for which none of the conditions hold.
\end{lem}
\begin{proof}
$A$ and $B$ overlap if and only if their projections to each coordinate axis overlap.
Suppose that $A\cap B\neq\emptyset$.
Then $A_d$ and $B_d$ overlap for each $d$, and by Lemma~\ref{lem:segintersect} the condition holds for each $d$.
If $A\cap B=\emptyset$, then there exists some $d$ for which $A_d\cap B_d=\emptyset$, so again by Lemma~\ref{lem:segintersect} none of the conditions hold for $d$.
\end{proof}

To apply Lemma~\ref{lem:rectintersect} to detect intersecting rectangles, we create \emph{two} $D-1$ dimensional inner trees to every outer node of a $D$-dimensional segment tree:
\begin{description}
\item[\subtree{n}] where we store rectangles $R$ for which $n\in\canoni{R_D}{D}$,
\item[\subtreep{n}] where we store rectangles $R$ for which $n\in\canonpari{R_D}{D}$.
\end{description}

We can write rectangle insertion and query operations by using these fields.
For simplicity we only support checking whether a query rectangle intersects any rectangle in the tree rather than returning the matching rectangles.
The nodes $n$ of the innermost tree have dimension 0, and they contain only a single boolean \hasrect{n}, which indicates that at least one rectangle is inserted to this subtree.

\begin{alg}\label{alg:rectadd}
Add rectangle $R$ to $D$-dimensional tree.
\begin{algorithmic}
\Procedure{InsertToTree}{$D,n$}
\Comment{Insert to the subtree rooted at node $n$}
	\If{$D=0$}
		\State $\hasrect{n}\gets\texttt{true}$.
	\ElsIf{$\inter{n}\subseteq R_D$}
		\State $\adddt(D-1,\subtree{n})$.
	\ElsIf{$\inter{n}\cap R_D\neq\emptyset$}
		\State $\adddt(D-1,\subtreep{n})$.
		\State $\adddt(D,\leftc{n})$.
		\State $\adddt(D,\rightc{n})$.
	\EndIf
\EndProcedure
\end{algorithmic}
\end{alg}

\begin{alg}\label{alg:rectcheck}
Query whether rectangle $R$ intersects with any rectangle in the tree.
\begin{algorithmic}
\Procedure{QueryTree}{$D,n$}
\Comment{Check subtree rooted at node $n$}
	\State $R\gets\texttt{false}$.
	\If{$D=0$}
		\State $R\gets\hasrect{n}$.
	\ElsIf{$\inter{n}\subseteq R_D$}
		\State $R\gets \checkdt(D-1,\subtree{n})$.
		\State $R\gets R$ or $\checkdt(D-1,\subtreep{n})$.
	\ElsIf{$\inter{n}\cap R_D\neq\emptyset$}
		\State $R\gets \checkdt(D-1,\subtree{n})$.
		\State $R\gets R$ or $\checkdt(D,\leftc{n})$.
		\State $R\gets R$ or $\checkdt(D,\rightc{n})$.
	\EndIf
	\State Return $R$.
\EndProcedure
\end{algorithmic}
\end{alg}

\begin{lem}\adddt and \checkdt both have time complexity $O(\log^D n)$.\end{lem}
\begin{proof}
Proof by induction on $D$.
For the base case $D=0$ both algorithm finishes in constant time.
For $D\ge 1$, algorithms iterate over the canonical nodes and their ancestors in the outer tree, making $\log{n}$ calls to the inner trees.
By induction the inner tree operations are done in time $O(\log^{D-1}n)$, so the total time complexity is $O(\log^D n)$.
\end{proof}

Note that \subtree{} and \subtreep{} are used in opposite ways in the two operations.
In \adddt{} we recurse down to \subtree{} for canonical nodes, and to \subtreep{} for their ancestors, whereas in \checkdt{} we recurse to \subtree{} in the ancestor nodes, and to both of the trees in the canonical nodes.
This allows us to ensure that \adddt{} and \checkdt{} arrive in the same node exactly in the case where the conditions of Lemma~\ref{lem:rectintersect} are fulfilled.

Suppose we first add rectangle $A$ and then query for rectangle $B$ in the tree.
The \checkdt operation returns true if the two operations end up in the same dimension-0 node.
The only way the two operations end up in a common node is if in each dimension $d$ we are in a canonical node of at least one of $A_d$ and $B_d$, and in either a canonical node or an ancestor for the other rectangle.
If \adddt{} and \checkdt{} operations end up in the same level-0 node, then in each dimension we are in the canonical node of at least either

Thus we can efficiently support inserting and querying for $D$-dimensional hyperrectangles by a nested structure consisting of multiple levels of segment trees.
However clearing a rectangle in this structure is considerable more difficult to support.
For that we turn into another variant of the multidimensional segment tree, the unified segment tree.

\subsection{Unified segment tree}\label{sec:unifiedtree}

The structure of a multidimensional segment tree depends on how we order the coordinate axes.
For example a two-dimensional segment tree can have either the outer tree represent $y$-coordinates and each inner tree represent $x$-coordinates, or the other way round.
The structure and parent-child relationships are different in the two cases, but the sets of rectangles represented by the nodes of the inner trees are exactly the same.

The \emph{unified segment tree} combines the parent-child links of the different multidimensional segment trees into a single structure.
The unified segment tree is not a tree, but a directed graph.
Each node $n$ of the graph represents a $D$-dimensional hyperrectangle.
For each axis $i$ where \rect{n} is not minimal, $n$ has links to two child nodes that divide \rect{n} into two parts along hyperplane perpendicular to $i$-axis.
Thus each node has between 0 and $2D$ links to child nodes.
The children splitting the node $n$ along axis $i$ are denoted by \leftu{n}{i} and \rightu{n}{i}.

Note that in the unified tree there is no distinction between outer and inner tree.
In the regular multidimensional segment tree the nodes of nested tree represent ranges in one of the coordinate axes, and the innermost nodes represent their cartesian product.
In the unified tree, there are no outer and inner nodes, and each node represents a $D$-dimensional hyperrectangle.

The operations \adddt and \checkdt for unified tree are largely similar to the algorithms for the regular multidimensional tree.
We consider again checking whether the query rectangle intersects with any of the hyperrectangles in the tree rather than reporting all the intersecting hyperrectangles.
Each tree node stores $2^D$ bits of information about the hyperrectangles stored in the subtree.
When a hyperrectangle $R$ is added to node $n$, the bits are used to define whether $n$ represents a canonical node or a parent of a canonical node along each coordinate axis.
The $2^D$ bits allow us to detect when the conditions of Lemma~\ref{lem:rectintersect} become fulfilled for the query rectangle and a rectangle in the tree.
The following function computes the mask for a rectangle and a tree node.

\begin{alg}\label{alg:maskof}
Compute bitmask representing how hyperrectangle $R$ is stored in unified tree node $n$.
\begin{algorithmic}
\Procedure{NodeMask}{$R,n$}
	\State $m\gets 0$
	\ForAll{$d \in 1\dots D$}
		\If{$\rect{n}_d\subseteq R_D$}
			\State $m\gets m + 2^d$
		\EndIf
	\EndFor
	\State Return $m$.
\EndProcedure
\end{algorithmic}
\end{alg}

We can write procedures \adddt and \checkdt by using this function.

\begin{alg}\label{alg:uadd}
Add rectangle $R$ to $D$-dimensional unified tree.
\begin{algorithmic}
\Procedure{InsertToTree}{$d,n$}
\Comment{Insert to the subtree rooted at node $n$ by moving along axes $1\dots d$}
	\If{$d=0$}
		\State $m\gets\maskof{R,n}$.
		\ForAll{$b \in 0\dots 2^D-1$}
			\If{All bits of $b$ are set in $m$}
				\State $\hasbits{n}{b}\gets\texttt{true}.$
			\EndIf
		\EndFor
		\State $\hasrect{n}\gets\texttt{true}$.
	\ElsIf{$\rect{n}_d\subseteq R_d$}
		\State $\adddt(d-1,n)$.
	\ElsIf{$\rect{n}_d\cap R_d\neq\emptyset$}
		\State $\adddt(d-1,n)$.
		\State $\adddt(d,\leftu{n}{d})$.
		\State $\adddt(d,\rightu{n}{d})$.
	\EndIf
\EndProcedure
\end{algorithmic}
\end{alg}

For \checkdt we use function $\texttt{reverseBits}$, which reverses the bits of a $2^D$-bit input.
For example if $D=2$ then $\texttt{reverseBits}(0111_2)=1000_2$.

\begin{alg}\label{alg:ucheck}
Query whether rectangle $R$ intersects with any rectangle in the unified tree.
\begin{algorithmic}
\Procedure{QueryTree}{$D,n$}
\Comment{Check subtree rooted at node $n$}
	\State $R\gets\texttt{false}$.
	\If{$D=0$}
		\State $R\gets\hasbits{n}{\texttt{reverseBits}(\maskof{R,n})}$.
	\ElsIf{$\inter{n}\subseteq R_D$}
		\State $R\gets\checkdt(d-1,n)$.
	\ElsIf{$\inter{n}\cap I\neq\emptyset$}
		\State $R\gets\checkdt(d-1,n)$.
		\State $R\gets R$ or $\checkdt(d,\leftu{n}{d})$.
		\State $R\gets R$ or $\checkdt(d,\rightu{n}{d})$.
	\EndIf
	\State Return $R$.
\EndProcedure
\end{algorithmic}
\end{alg}

The interesting part of the query algorithm is checking if the tree node contains a rectangle by expression $\hasbits{n}{\texttt{reverseBits}(\maskof{R,n})}$ when querying for hyperrectangle $R$.
When adding a hyperrectangle $A$, we set $\hasbits{n}{b}$ for each bitmask $b$ whose bits are contained in $\maskof{A,n}$.
Thus the expression in \checkdt detects $A$ if $\maskof{A,n}|\maskof{R,n}=2^D-1$, where $x|y$ represents the bitwise OR operation of $x$ and $y$.
This is equivalent to condition that $\rect{n}_d$ is the range of a canonical node of either $R_d$ or $A_d$ in each dimension $d$.
This matches the conditions of Lemma~\ref{lem:rectintersect} for rectangle intersection, so the intersection is returned if and only if $R$ and $A$ truly intersect.

Next we consider clearing a rectangle from the unified tree.


\section{Planar minimum link paths}\label{sec:minlink2d}

In this section we study the rectilinear minimum link path in a plane.
In the rectilinear problem both the obstacle segments as well as the links of the path to be produced must be aligned to coordinate axes.
We present a simple algorithm with time complexity $O(n\log n)$ and space complexity $O(n)$.
The ideas develoepd for the the simple algorithm are later generalized to solve the more difficult 3D minimum link path problem in Section~\ref{sec:minlink3d}.

\subsection{Intersection graph}

We solve the minimum link path problem by applying the staged illumination paradigm outlined in Section~\ref{sec:overview}.
Initialize \reach{0} to contain the starting point, and iteratively expand the illuminated area by computing \reach{k+1} based on \reach{k}.
The iteration is continued until we find the desired endpoint.

It is easy to see that in any minimum link path consists of alternation between horizontal and vertical links.
We split the problem into two subproblems, based on whether the first link is horizontal or vertical.
The minimum link path can be found by solving both subproblems and choosing the shorter of the two solutions.

Consider the case with the first link horizontal.
It is easy to see that \reach{k+1} consists of points that can be reached by starting from \reach{k} and moving either horizontally or vertically, depending on the parity of $k$.
The regions that are illuminated on each step can be expressed using the horizontal and vertical decompositions defined in Section~\ref{sec:decomp2d}.
This is shown by the following lemma.

\begin{lem}\label{lem:illum2d}
For even $k>0$, the region \reach{k+1} consists of the rectangles $r\in\decomp{x}$ that intersect the region \reach{k}.
For odd $k$ the same applies for \decomp{y}.
\end{lem}
\begin{proof}
Let $k>0$ be even.
The region \reach{k} is formed by illuminating in vertical direction from \reach{k-1}.
Let $h$ be any rectangle in $decomp{x}$ that is at least partially illuminated in \reach{k}, and $p$ any point in $h\cap\reach{k}$.
Since \reach{k} is formed by illuminating vertically from \reach{k-1}, the vertical line segment passing between top and bottom edges of $h$ through $p$ must entirely belong to \reach{k}.
Illuminating horizontally from the vertical line passing through $h$ illuminated the entire rectangle, so $h\subseteq\reach{k+1}$.
Thus each rectangle of \decomp{x} intersected by \reach{k} is entirely contained in \reach{k+1}.

For odd $k$ we form \reach{k+1} by illuminating in vertical direction from \reach{k}, and the same proof applies for \decomp{y}.
\end{proof}

For a set of geometric objects (such as rectangles) $G$, the \emph{intersection graph} of $G$ is a graph whose nodes are the elements of $G$, and there is an edge between each each pair of intersecting objects.
Consider the intersection graph of $\decomp{x}\cup\decomp{y}$.
This graph has rectangles as nodes, and intersection rectangles between \decomp{x} and \decomp{y} are combined by an edge.
Let $k$ be an even number and $r\in\decomp{x}$ contained in \reach{k}.
Then for each neighbor $n$ of $r$ in the intersection graph applies $n\subseteq\reach{k+1}$ by Lemma~\ref{lem:illum2d}.
In other words, the staged illumination finds the rectangles in the same order as breadth-first search in the intersection graph.

The rectilinear minimum link path problem can thus be solved by forming the intersection graph and searching for the shortest path using breadth-first search.
The intersection graph has quadratic size, so we don't want to form the graph explicitly.
The challenging part of minimum link path finding is thus performing BFS in the intersection graph without explicitly forming the graph.

\subsection{Searching the intersection graph}

Consider again the case where the first link of the path is horizontal.
We start by constructing the horizontal decomposition with Algorithm~\ref{alg:split2d}.
The vertical decomposition is used implicitly in the analysis, but there is no need to construct it explicitly.

\reach{0} contains the start point~\spt, and \reach{1} is the horizontal line segment passing through \spt.
The path finding algorithm works by alternating between two phases:

\begin{enumerate}
\item For odd $k$, \reach{k} consists of a set of rectangles $R_k\subseteq\decomp{x}$.
	Inspect which obstacles can be reached by a vertical line starting from any point in \reach{k}, and form $\hat{R}_{k+1}=\set{r \mid r\in\decomp{x}, r\cap\reach{k+1}\neq\emptyset}$.
\item For even $k$, we simply set $R_{k+1}=\hat{R}_k$.
	Then $\reach{k+1}=\bigcup_{r\in R_{k+1}}r$ by Lemma~\ref{lem:illum2d}.
\end{enumerate}

We keep iterating these phases until the endpoint~\ept is reached in either phase.

For performance, it is important to ensure that we don't reilluminate the same parts of the domain many times.
We avoid the reillumination by marking cells of \decomp{x} as obstacles some time after they have been found.
If rectangle $r$ is discovered on step $k$, then it is fully illuminated in \reach{k+1}, and each point visible from $r$ is illuminated in \reach{k+2}.
After this there is no longer any need to illuminate through $r$, so we can treat $r$ as an obstacle after 2 steps have passed since the illumination first reached $k$.
This ensures that each rectangle is illuminated only a constant number of times.

Next we show how to implement illumination in $y$-direction starting from \reach{k}, which is represented as a set of rectangles $R\in\subseteq\decomp{x}$.
The illuminated area is computed with two line sweeps, in in direction $+y$ and the other in direction $-y$.

The sweep line stops at each rectangle to be illuminated.
During the sweep we maintain the intersection between the sweep line and the newly illuminated region \reach{k+1}.
The intersection consists of non-overlapping intervals stored in a binary search tree.

Let \nbsd{r}{d} and \obsd{r}{d} be the neighbor cell and the adjacent obstacles of rectangle $r$ in direction $d$ in \decomp{x}.
The algorithm below displays the illumination in direction $+y$.
The sweep in direction $-y$ is identical.

\begin{alg}\label{alg:light2d}
Compute illuminated rectangles from group $R$ into direction $+y$.
\begin{algorithmic}
\State $Q\gets\text{Priority queue containing the rectangles of $R$, ordered by the highest $y$-coordinate}$.
\State $T\gets\text{Empty binary search tree}$.
\While{$Q$ is not empty}
	\State $r\gets\pop{Q}$.
	\If{$r\in R$}
		\State Insert \xrange{r} into $T$.
	\EndIf
	\ForAll{$o\in\obsd{r}{+y}$}
		\ForAll{$t\in T$ touching \xrange{o}}
			\State Replace $t$ by $t\setminus\xrange{o}$, possibly removing it or splitting it into two parts.
		\EndFor
	\EndFor
	\ForAll{$n\in\nbsd{r}{+y}$}
		\If{$\xrange{n}$ touches any range in $T$ and $n\notin Q$}
			\State Insert $n$ into $Q$.
		\EndIf
	\EndFor
\EndWhile
\end{algorithmic}
\end{alg}

\begin{lem}\label{lem:light2dtime}The running time of Algorithm~\ref{alg:light2d} is $O(m\log m)$ where $m$ is the number of visited rectangles and their neighbor links.\end{lem}
\begin{proof}
The outermost loop processes a different rectangle $r$ each time, so it is executed $O(m)$ times.
For each obstacle adjacent to $r$ we cut of all the intersections with the obstacle from the binary search tree.
At most two of the intersected intervals remain in the tree, the others are removed, so the cost of the clearing operation can be accounted to the point when the nodes where added to the tree.
Thus the cost of processing an obstacle if $O(\log m)$ when the removing time is accounted to the insertions.
For each rectangle adjacent to $r$ we perform a single binary tree operation and possibly a single operation to the binary queue, which can both be done in time $O(\log m)$.
Thus the total time complexity is $O(m\log m)$.
\end{proof}

The link distance between \spt and \ept can be computed by iteratively performing the illumination sweeps in $+y$ and $-y$ directions until the endpoint is found.

\begin{alg}\label{alg:minlink2d}
Run staged illumination starting from \spt within \fspace such that the first link is horizontal.
\begin{algorithmic}
\State Form \decomp{x} for \fspace with Algorithm~\ref{alg:split2d}.
\State $R\gets\set{r\in\decomp{x} \mid \spt\in r}$
\State $k\gets 1$
\While{$R\neq\emptyset$}
	\ForAll{$r\in R$}
		\If{$\stepof{r}$ is not set}
			\State $\stepof{r}\gets k$
		\ElsIf{$\stepof{r} \le k-2$}
			\State Mark $r$ to be treated as obstacle during the sweeps.
			\State Remove $r$ from $R$.
		\EndIf
	\EndFor
	\State $H_{+y}\gets H$ illuminated in direction $+y$ by Algorithm~\ref{alg:light2d}.
	\State $H_{-y}\gets H$ illuminated in direction $-y$ by Algorithm~\ref{alg:light2d}.
	\State $H\gets H_{+y}\cup H_{-y}$.
	\State $k\gets k+1$
\EndWhile
\end{algorithmic}
\end{alg}

\begin{theo}Algorithm~\ref{alg:minlink2d} has time complexity $O(n\log n)$.\end{theo}
\begin{proof}
\decomp{x} is formed in time $O(n\log n)$ by Lemma~\ref{lem:split2dtime}.
\decomp{x} has $O(n)$ cells and links between cells.
Each cell is marked as an obstacle 2 steps after it has been found.
On each iteration of the main loop we perform two sweeps, so each cell can be visited at most 4 times by the sweeps.
The complexity of a single sweep is $O(m\log m)$ by Lemma~\ref{lem:light2dtime}, where $m$ is the number of visited rectangles.
Since each rectangle can be visited O(1) times, the total complexity of all the sweeps is $O(n\log n)$.
\end{proof}

The link distance between \spt and a target point \ept can be found by stopping the illumination process as soon as \ept becomes illuminated.
\epts can become illuminated either during a vertical sweep, or the implicit horizontal sweep that happens when we assign $H_{+y}\cup H_{-y}$ into $H$.
To construct the minimum link path between \spt and \ept, augment the algorithm such that we store into each rectangle how it was initially illuminated, and trace back the path when \ept gets illuminated.



\section{Paths in 3 and higher dimensions}\label{sec:minlink3d}

In this section we study the rectilinear minimum link path problem in 3D domain.
We present an algorithm that has time complexity $O(n^2\log^2n)$ and space complexity $O(n^2)$.
We also extend the algorithm to work in higher dimensions.
For any constant $D\ge 1$, the presented algorithm works in time $O(n^D\log^Dn)$.

Some of the basic ideas of the 2D minimum link path algorithm can also be applied to the 3D case.
The path is computed using the staged illumination paradigm, and on each step we compute \reach{k+1} from \reach{k} by using sweep plane algorithms in all the coordinate axis directions.
However in 3D case the representation of the illuminated space becomes more complicated, and also the sweep algorithms require more sophisticated logic.

We use the decomposition presented in Section~\ref{sec:split3d} to maintain the illuminated set and to guide the illumination during the sweeps.
Unlike the 2D case, the algorithm does not use any specific properties of the decomposition, but can be used with any space decomposition.
The running time of the algorithm is heavily dependend on the number of cells and links between them, and the decomposition we use has the advantage of having only a small number of links compared to other decompositions.

The decomposition is used to implement plane sweep algorithm for computing \reach{k+1} from \reach{k}.
On each step we run 6 sweeps, one in each of the directions $\pm x$, $\pm y$ and $\pm z$.
By combining the results of sweeping in each direction we form the whole region \reach{k+1}.
Next we discuss how the sweep plane algorithm is implemented, and then show how the minimum link path algorithm is built around it.

\subsection{Illumination by plane sweep}

We use a sweep plane algorithm to compute \reach{k+1} from \reach{k}.
The sweep algorithm performs two functions: it discovers which cells can be illuminated from \reach{k}, and it constructs the boundary of the illuminated region.
The boundary is used on the next step to compute \reach{k+2} from \reach{k+1}.

During the sweep we maintain the intersection of the sweep plane with the newly illuminated region, and a priority queue of events.
The events belong to one of the following types:

\begin{description}
\item[\addE] where a previously illuminated region is added to the sweep plane.
\item[\cellE] which occurs when the sweep plane reaches the end of a cell that potentially intersects with the illuminated region.
\item[\obsE] which occurs when the sweep plane encounters an obstacle face with normal opposite of the sweep direction.
\end{description}

Suppose that we are performing the sweep in direction $+z$.
In \cellE we first check whether the reached cell $c$ is truly illuminated.
If yes, we add a \cellE for each neighbor of $c$ in direction $+z$, and an \obsE for each obstacle adjacent to $c$ in direction $+z$.
In \obsE the projection of the encountered obstacle is cleared from the sweep plane.
Additionally the cleared rectangles are used to construct new \addEs on the boundary of the illuminated region to be used on the next illumination step.

During the sweep, the intersection of the illuminated region with the sweep plane is stored in the Unified 2D segment tree presented in Section~\ref{sec:unifiedtree}.
Each \addE inserts a new rectangle to the tree.
Each illuminated canonical node of the tree stores reference to the event that was used to generate it.
If multiple \addEs illuminate the same canonical rectangle, only the one inserted first is stored.
This reference is used to determine the $z$-range of the \addEs generated during \obsE, as well as for tracing back the path from \ept to \spt after the illumination is finished.

Pseudocode for the illumination plane sweep is as following.

\begin{alg}\label{alg:sweep3d}
Illuminate by plane sweep in direction $+z$ starting from a provided event set $E$.
\begin{algorithmic}
\State $Q\gets$ Priority queue containing $E$.
\State $T\gets$ Empty 2D segment tree.
\While{$Q$ is not empty}
	\State $e\gets\pop{Q}$.
	\If{$e$ is \addE}
		\State Insert \rectof{e} to $T$.
	\ElsIf{$e$ is \cellE}
		\If{\rectof{e} touches any rectangle in $T$}
			\State $c\gets\cellof{e}$.
			\ForAll{$o\in\obsd{c}{z+}$}
				\State Insert \obsE for $o$ to $Q$.
			\EndFor
			\ForAll{$n\in\nbsd{c}{z+}$}
				\State Insert \cellE for $n$ to $Q$.
			\EndFor
		\EndIf
	\ElsIf{$e$ is \obsE}
		\State Clear \rectof{e} from $T$.
		\State Generate \addEs for the cleared canonical rectangles.
	\EndIf
\EndWhile
\end{algorithmic}
\end{alg}

We can write down the basic pseudocode for the staged illumination by iteratively applying the sweep algorithm.

\begin{alg}\label{alg:minlink3d}
Run staged illumination in 3D domain \fspace starting from point \spt.
\begin{algorithmic}
\State Compute decomposition of \fspace into cells using Algorithm~\ref{alg:split3d}.
\ForAll{$d\in\set{\pm x,\pm y,\pm z}$}
	\State $E_d\gets$ Event set containing \addE at \spt and \cellE for the cell containing \spt.
\EndFor
\While{$E_d$ is not empty for some $d$}
	\ForAll{$d\in\set{\pm x,\pm y,\pm z}$}
		\State $E_d'\gets$ Empty event set.
	\EndFor
	\ForAll{$d\in\set{\pm x,\pm y,\pm z}$}
		\State Illuminate in direction $d$ using Algorithm~\ref{alg:sweep3d} with events $E_d$.
		\State Store the events generated by the sweep into $E_e'$ for $e\neq\pm d$.
	\EndFor
	\ForAll{$d\in\set{\pm x,\pm y,\pm z}$}
		\State $E_d\gets E_d'$.
	\EndFor
\EndWhile
\end{algorithmic}
\end{alg}

To make the minimum link path computation efficient, we want to avoid reilluminating the same cells multiple times.
For the 2D minimum link paths this was done by turning cells into obstacles once enough steps have passed since the cell was first discovered.
This approach works also for 3D, but since there are $O(n^2)$ cells and clearing a rectangle from the unified tree requires $O(n\log n)$ steps, having to do clear operations for all the cells would increase the time complexity significantly.

To overcome this problem, instead of limiting the reachable cells, we instead limit the creation of \addEs.
We create \addEs for the next step when a plane sweep hits an obstacle.
If the illumination first reaches an obstacle face $o$ on step $k$, then after step $k+2$ all the points touching $o$ are illuminated, so after step $k+3$ all the points visible from $o$ are illuminated.
Thus there is no longer need to add \addEs for \obsEs on $o$, as any point illuminated through such events has been illuminated already.

\subsection{Event generation}\label{sec:evtgen}

We now discuss how the \addEs for the next round are generated when the sweep processes an \obsE.
We again explain only the case for $+z$ sweep, as the other cases are identical.
The goal is to generate \addEs on the boundary of the space illuminated on step $k$, such that the sweeps on step $k+1$ correctly generate \reach{k+1}.

During the $+z$ sweep we generate \addEs in directions $\pm x$ and $\pm y$.
On a \obsE we perform a clear operation on the unified tree containing the sweep plane status.
Thus operations clears some of the tree nodes.
As a first step in even generation, we create an \addEs on each side of every cleared canonical rectangle.
This can create an unnecessarily large amount of events, because rectangles added to the tree are split to up to $(\log^2 n)$ canonical rectangles.

To reduce the number of generated events, we perform the following two steps after generating the events:
\begin{enumerate}
\item Remove all the pairs of \addEs with the same position but opposite direction.
\item Merge all sets of aligned \addEs with the same $z$-range into a single larger \addE.
\end{enumerate}

The aligned \addEs in direction $+x$ are the ones that occur on the same $x$ coordinate and have the same bounds in direction $z$, and the bounds in $y$-direction touch each other at endpoints.
The definition is similar in all the other directions.
The aligned \addEs are searched for the events in all directions separately.
Performing these operations allow us to bound the number of \addEs generated during the illumination.

\subsection{Complexity}

We now prove the complexity of the minimum link computation algorithm.

\begin{lem}\label{lem:adde3}The number of \addEs generated during the illumation after after filtering is $O(n^2)$.\end{lem}
\begin{proof}
Left as an exerice to the reader.
\end{proof}

We also need to bound the number of \obsEs and \cellEs.

\begin{lem}\label{lem:obse3}For each obstacle we generate \obsE on at most 9 steps of the illumination.\end{lem}
\begin{proof}
Left as an exerice to the reader.
\end{proof}

\begin{lem}\label{lem:celle3}For each cell we generate \cellE on at most 9 steps of the illumination.\end{lem}
\begin{proof}
Left as an exerice to the reader.
\end{proof}

We are ready to prove the main result of this section.

\begin{theo}Algorithm~\ref{alg:minlink3d} computes 3D minimum link path in time $O(n^2\log^2n)$.\end{theo}
\begin{proof}
By Lemma~\ref{lem:celle3} each cell is visited $O(1)$ times during the illumination.
On each \cellE we perform a single lookup to the unified tree in time $O(\log^2 n)$, and iterate over the neighbors of the cell.
Since the decomposition has $O(n^2)$ cells and $O(n^2)$ links between cells, the total time taken in processing \cellEs is $O(n^2\log^2 n)$.

On each \addE we insert a new rectangle to the unified tree in time $O(\log^2 n)$.
The number of \addEs is $O(n^2)$ by Lemma~\ref{lem:adde3}, so the event filtering can be done in time $O(n^2\log n)$, and the total time used in processing them is $O(n^2\log^2 n)$.

On each \obsE we clear a rectangle from the tree.
The clearing takes $O(n\log n + k)$, where $k$ is the number of cleared rectangles.
The total number of rectangles cleared is bounded by the total number of \addEs, which is $O(n^2)$.
There are $O(n)$ \obsEs by Lemma~\ref{lem:obse3}, so the total time taken in \obsEs is $O(n^2\log n)$.

As all parts of the algorithm are done in time $O(n^2\log^2 n)$ or less, the total complexity is $O(m^2\log^2 n)$.
\end{proof}

\subsection{Higher dimensional paths}

The algorithm for 3D minimum link paths can be generalized to higher dimensions.
We now assume that \fspace is a $D$-dimensional rectilinear region for arbitrary fixed $D\ge 2$.
We develop a generalization of Algorithm~\ref{alg:minlink3d} that computes the rectilinear minimum link path in $D$-dimensional space in time $O(n^{D-1}\log^{D-1}n)$.

The algorithm uses the same set of events during the sweeps in the $D$-dimensional space as were used in 3D space.
The 2D sweep plane is replaced by a $(D-1)$-dimensional hyperplane, so each event $e$ defines a $(D-1)$-dimensional hyperrectangle \hrectof{e} instead of \rectof{e}.

We use $D$-dimensional Unified segment tree to store the sweep hyperplane state during the sweeps.
The unified tree and the $D$-dimensional space decomposition allow us to use almost identical algorithm for the higher dimension case as the algorithm for the 3D domains.

\begin{alg}\label{alg:sweepdd}
Illuminate by plane sweep in direction $+D$ starting from a provided event set $E$.
\begin{algorithmic}
\State $Q\gets$ Priority queue containing $E$.
\State $T\gets$ Empty $(D-1)$-dimensional Unified segment tree.
\While{$Q$ is not empty}
	\State $e\gets\pop{Q}$.
	\If{$e$ is \addE}
		\State Insert \hrectof{e} to $T$.
	\ElsIf{$e$ is \cellE}
		\If{\hrectof{e} touches any hyperrectangle in $T$}
			\State $c\gets\cellof{e}$.
			\ForAll{$o\in\obsd{c}{D+}$}
				\State Insert \obsE for $o$ to $Q$.
			\EndFor
			\ForAll{$n\in\nbsd{c}{D+}$}
				\State Insert \cellE for $n$ to $Q$.
			\EndFor
		\EndIf
	\ElsIf{$e$ is \obsE}
		\State Clear \hrectof{e} from $T$.
		\State Generate \addEs for the cleared canonical hyperrectangles.
	\EndIf
\EndWhile
\end{algorithmic}
\end{alg}

Using the hyperplane sweep, the $D$-dimensional minimum link path computation works as the following.

\begin{alg}\label{alg:minlinkdd}
Run staged illumination in $D$-dimensional domain \fspace starting from point \spt.
\begin{algorithmic}
\State Compute decomposition of \fspace into $D$-dimensional cells using Algorithm~\ref{alg:splitdd}.
\ForAll{$d\in\set{\pm1,\dots,\pm D}$}
	\State $E_d\gets$ Event set containing \addE at \spt and \cellE for the cell containing \spt.
\EndFor
\While{$E_d$ is not empty for some $d$}
	\ForAll{$d\in\set{\pm1,\dots,\pm D}$}
		\State $E_d'\gets$ Empty event set.
	\EndFor
	\ForAll{$d\in\set{\pm1,\dots,\pm D}$}
		\State Illuminate in direction $d$ using Algorithm~\ref{alg:sweep3d} with events $E_d$.
		\State Store the events generated by the sweep into $E_e'$ for $e\neq\pm d$.
	\EndFor
	\ForAll{$d\in\set{\pm1,\dots,\pm D}$}
		\State $E_d\gets E_d'$.
	\EndFor
\EndWhile
\end{algorithmic}
\end{alg}

We use the same method for avoiding reilluminating the same areas many times as was used in the 3D algorithm.
For each obstacle $o$ we record when it was first discovered, and use that to stop generating \addEs from $o$ after a certain number of steps has passed.
If $o$ is reached first on step $k$, then at the end of step $k+D$ all the points visible from $o$ are illuminated, so we can stop creating \addEs from $o$ starting from step $k+D+1$.

We also need to perform the filtering described in Section~\ref{sec:evtgen} to avoid generating a large number of \addEs because of the unified tree structure.
The filtering rules are exactly the same as the ones used in the 3D algorithm, except that we are working with $(D-1)$-dimensional hyperplanes.
The operations below are performed to \addEs produced by sweep in direction $+D$.
\begin{enumerate}
\item Remove all the pairs of \addEs with the same position but opposite direction.
\item Merge all sets of aligned \addEs with the same $D$-range into a single larger \addE.
\end{enumerate}

The definition of aligned \addEs is a bit more complicated in high-dimensional case.
A pair of \addEs can be aligned along multiple axes.
For two \addEs to be aligned, they need to in the event set for the same direction, and share the same coordinate where the events occur.
Let $a$ be any axis other than $D$.
The events are aligned in direction $a$ if the bounds of their hyperrectangles are identical in all the directions except $a$, and the bounds in direction $a$ touch each other at endpoints.

The filtering step allows us to again bound the numberor of \addEs processed during the illumination.

\begin{lem}\label{lem:added}The number of \addEs generated during the illumation after after filtering is $O(n^{D-1})$.\end{lem}
\begin{proof}
Left as an exerice to the reader.
\end{proof}

We also need to bound the number of \obsEs and \cellEs.

\begin{lem}\label{lem:obsed}For each obstacle we generate \obsE on at most 9 steps of the illumination.\end{lem}
\begin{proof}
Left as an exerice to the reader.
\end{proof}

\begin{lem}\label{lem:celled}For each cell we generate \cellE on at most 9 steps of the illumination.\end{lem}
\begin{proof}
Left as an exerice to the reader.
\end{proof}

These lemmas allow us to prove the final result.

\begin{theo}Algorithm~\ref{alg:minlinkdd} computes $D$-dimensional minimum link path in time $O(n^{D-1}\log^{D-1}n)$.\end{theo}
\begin{proof}
Left as an exerice to the reader.
\end{proof}



\section{Conclusions}\label{sec:conclusions}

We have shown algorithms for the rectilinear minimum link path problem for many different dimensions.
The 2D case is solved in time $O(n\log n)$, which was shown initially by~TODO.
A new result is that a similar algorithm can be created for 3 dimensions, which works in time $O(n^2\log^2 n)$.
We also showed how this result can be further generalized to work for any dimension $D$ in time $O(n^{D-1}\log^{D-1}n)$.

The previous best known result for the 3D minimum link paths was $O(n^{2.5}\log n)$, and we improved it down to $O(n^2\log^2 n)$.
A natural follow up question is, whether the result could be improved further.
The 2D case was shown to be equivalently difficult as sorting the input, so the result is asymptotically optimal.
For the higher dimensional results no other upper bound is known than the same $O(n\log n)$ bound.

The main bottleneck in the higher dimensional algorithms are operations on segment tree.
Segment trees and their applications are a broad research topic.
For example we can create a segment tree that supports adding intervals, and finding the maximal number of overlapping any point in a query interval in time $O(\log n)$.
It is an open question whether this can be generalized to two or more dimensions: can we create a structure that supports adding and querying for maximally overlapping rectangles in polylogarithmic time?


\nocite{*}
\bibliographystyle{tktl}
\bibliography{ref}

\lastpage

\appendices

\pagestyle{empty}

\internalappendix{1}{Source code location}

An implementation of the high-dimensional rectilinear minimum link path algorithm presented in the thesis is available in the following URL: \\
\url{https://github.com/sisu/gradu/tree/master/code}

The code is written in standard C++ using the C++14 standard.
The implementation does not depend on any libraries besides the C++ standard library, but the associated unit tests are written using the Google Test framework.

\end{document}


