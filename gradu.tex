\documentclass[english,gradu]{tktltiki2018}
\usepackage{epsfig}
%\usepackage[pdftex]{graphicx}
\usepackage{url}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{amsfonts,amsmath,amssymb,amsthm,booktabs,color,enumitem,graphicx,mathabx}
\usepackage{subfigure,xspace}
\usepackage{algpseudocode}
\begin{document}
\onehalfspacing

\newtheorem{theo}{Theorem}
\newtheorem{lem}{Lemma}
\newtheorem{cor}[lem]{Corollary}

\theoremstyle{definition}
%\newtheorem{def}[theo]{Definition}
\newtheorem{prob}{Problem}
\newtheorem{alg}{Algorithm}
\newtheorem{ex}{Example}

\theoremstyle{remark}
\newtheorem*{note}{Remark}

\newcommand\range[2]{\ensuremath{\left [ #1 , #2 \right )}\xspace}
\newcommand\orange[2]{\ensuremath{\left ( #1 , #2 \right )}\xspace}
\newcommand\crange[2]{\ensuremath{\left [ #1 , #2 \right ]}\xspace}
\newcommand\set[1]{\ensuremath{\left\{#1\right\}}\xspace}
\newcommand\size[1]{\ensuremath{\left |#1\right |}\xspace}
\newcommand\ceil[1]{\ensuremath{\left\lceil #1\right\rceil}\xspace}
\newcommand\reals{\ensuremath{\mathbb{R}}\xspace}

\newcommand\spt{\ensuremath{\dot{s}}\xspace}
\newcommand\ept{\ensuremath{\dot{t}}\xspace}
\newcommand\fspace{\ensuremath{\mathcal{A}}\xspace}
\newcommand\dirs{\ensuremath{\mathcal{C}}\xspace}

\newcommand\epts{\ensuremath{P}\xspace}
\newcommand\segsize{\ensuremath{m}\xspace}
\newcommand\inter[1]{\ensuremath{\textsc{intr}(#1)}\xspace}
\newcommand\leftc[1]{\ensuremath{\textsc{left}(#1)}\xspace}
\newcommand\rightc[1]{\ensuremath{\textsc{right}(#1)}\xspace}
\newcommand\leftu[2]{\ensuremath{\textsc{fst}_{#2}(#1)}\xspace}
\newcommand\rightu[2]{\ensuremath{\textsc{snd}_{#2}(#1)}\xspace}
\newcommand\reach[1]{\ensuremath{\textsc{light}(#1)}\xspace}
\newcommand\reachd[2]{\ensuremath{\textsc{light}_{#2}(#1)}\xspace}
\newcommand\canon[1]{\ensuremath{\textsc{c}(#1)}\xspace}
%\newcommand\canonp[1]{\ensuremath{\dot{\textsc{c}}(#1)}\xspace}
%\newcommand\canont[2]{\ensuremath{\textsc{c}(#1,#2)}\xspace}
\newcommand\canoni[2]{\ensuremath{\textsc{c}_{#2}(#1)}\xspace}
\newcommand\canonpar[1]{\ensuremath{\textsc{p}_{\textsc{c}}(#1)}\xspace}
\newcommand\canonpari[2]{\ensuremath{\textsc{p}_{\textsc{c},#2}(#1)}\xspace}
\newcommand\epar[1]{\ensuremath{\textsc{p}(#1)}\xspace}
\newcommand\findol{\ensuremath{\textsc{FindOverlapping}}\xspace}
\newcommand\visitp{\ensuremath{\textsc{VisitParent}}\xspace}
\newcommand\visitc{\ensuremath{\textsc{VisitCanonical}}\xspace}
\newcommand\adddt{\ensuremath{\textsc{InsertToTree}}\xspace}
\newcommand\checkdt{\ensuremath{\textsc{QueryTree}}\xspace}
\newcommand\cleariv{\ensuremath{\textsc{ClearInterval}}\xspace}
\newcommand\maskof[1]{\ensuremath{\textsc{NodeMask}(#1)}\xspace}
\newcommand\cleardt{\ensuremath{\textsc{ClearFromTree}}\xspace}
\newcommand\clearst{\ensuremath{\textsc{ClearSubtree}}\xspace}
\newcommand\pdst{\ensuremath{\textsc{PushDownSubtree}}\xspace}
\newcommand\recomp{\ensuremath{\textsc{RecomputeSubtreeData}}\xspace}

\newcommand\nodecs[1]{\ensuremath{\textsc{ivc}(#1)}\xspace}
\newcommand\nodeps[1]{\ensuremath{\textsc{ivp}(#1)}\xspace}
\newcommand\subtree[1]{\ensuremath{\texttt{subtree}(#1)}\xspace}
\newcommand\subtreep[1]{\ensuremath{\texttt{subtreeP}(#1)}\xspace}
\newcommand\hasrect[1]{\ensuremath{\texttt{hasrect}(#1)}\xspace}
\newcommand\hasbits[2]{\ensuremath{\texttt{hasbits}(#1)[#2]}\xspace}
\newcommand\hasbita[1]{\ensuremath{\texttt{hasbits}(#1)}\xspace}

\newcommand\rect[1]{\ensuremath{\textsc{rect}(#1)}\xspace}

\newcommand\pop[1]{\ensuremath{\textsc{pop}(#1)}\xspace}

\newcommand\y[1]{\ensuremath{{#1}_y}\xspace}
\newcommand\x[1]{\ensuremath{{#1}_x}\xspace}
\newcommand\xrange[1]{\ensuremath{x(#1)}\xspace}
\newcommand\yrange[1]{\ensuremath{y(#1)}\xspace}
\newcommand\zrange[1]{\ensuremath{z(#1)}\xspace}
\newcommand\xranget[2]{\ensuremath{x(#1)_{#2}}\xspace}
\newcommand\yranget[2]{\ensuremath{y(#1)_{#2}}\xspace}
\newcommand\nbs[1]{\ensuremath{\textsc{nbs}{(#1)}}\xspace}
\newcommand\nbsd[2]{\ensuremath{\textsc{nbs}_{#2}{(#1)}}\xspace}
\newcommand\obsd[2]{\ensuremath{\textsc{obs}_{#2}{(#1)}}\xspace}

\newcommand\decomp[1]{\ensuremath{\textsc{dec}_{#1}}\xspace}
%\newcommand\decompc[1]{\ensuremath{\textsc{dec}({#1})}\xspace}
\newcommand\sweep[2]{\ensuremath{\textsc{sweep}_{#2}{(#1)}}\xspace}
\newcommand\stepof[1]{\ensuremath{\textsc{step}{(#1)}}\xspace}
\newcommand\proj[2]{\ensuremath{\text{proj}_{#1}(#2)}\xspace}

\newcommand\rotr[1]{\ensuremath{\top #1}\xspace}
\newcommand\vecof[1]{\ensuremath{\left [#1\right ]}\xspace}
\newcommand\sline[1]{\ensuremath{S_{#1}}\xspace}
\newcommand\intert[2]{\ensuremath{\textsc{interval}_{#1}(#2)}\xspace}
\newcommand\point[1]{\ensuremath{\left ({#1}\right )}\xspace}

\newcommand\cellE{\ensuremath{\mathsf{CellEvent}}\xspace}
\newcommand\cellEs{\ensuremath{\mathsf{CellEvent}}s\xspace}
\newcommand\obsE{\ensuremath{\mathsf{ObstacleEvent}}\xspace}
\newcommand\obsEs{\ensuremath{\mathsf{ObstacleEvent}}s\xspace}
\newcommand\addE{\ensuremath{\mathsf{AddRangeEvent}}\xspace}
\newcommand\addEs{\ensuremath{\mathsf{AddRangeEvent}}s\xspace}
\newcommand\cellof[1]{\ensuremath{\text{cell}(#1)}\xspace}
\newcommand\rectof[1]{\ensuremath{\text{rect}(#1)}\xspace}
\newcommand\hrectof[1]{\ensuremath{\text{hyperrect}(#1)}\xspace}


\title{Rectilinear minimum link paths in high dimensions}
\author{Mikko Sysikaski}
\date{\today}
\level{Master's thesis}

% For new study programmes (2017->) to appear on title page
%\department{Master's Programme in Computer Science}
%\department{Master's Programme in Data Science}
%\department{Bachelor's Programme in Computer Science}

\maketitle

\numberofpagesinformation{\numberofpages\ pages + \numberofappendixpages\ appendices}

\classification{\protect{\ \\
%\  General and reference $\rightarrow$ Document types  $\rightarrow$ Surveys and overviews\  \\
%\  Applied computing  $\rightarrow$ Document management and text processing  $\rightarrow$ Document management $\rightarrow$ Text editing\\
F.2.2 [Nonnumerical Algorithms and Problems]}}

\keywords{algorithms, computational geometry}

\supervisors{Antti Laaksonen and Jyrki Kivinen}

%default (40 cr thesis)
%\program{Computer Science}

%Computer Science Master's Programme thesis, 30 cr
%\program{Study Programme in Computer Science} 

%Data Science thesis, 30 cr
%\program{Master's Programme in Data Science}

%Bachelor's thesis 
%\level{Bachelor's thesis}
%Computer Science Bachelor's Programme (2017->) thesis
%\program{Bachelor's Programme in Computer Science}

% For CS Master's Programme thesis 2017->
%\additionalinformation{Thesis for the Algorithms study track }
%\additionalinformation{Thesis for the Networking and Services study track}
%\additionalinformation{Thesis for the Software Systems study track}

% For CS Master's thesis if you follow CS degree requirements prior 2017
%\additionalinformation{Thesis for the Algorithmic Bioinformatics subprogramme}
\additionalinformation{Thesis for the Algorithms, Data Analytics and Machine Learning subprogramme}
%\additionalinformation{Thesis for the Networking and Services subprogramme}
%\additionalinformation{Thesis for the Software Systems subprogramme}

%\level{Seminar essay}
%\additionalinformation{Essay for Seminar on ...}

\begin{abstract}
The thesis subject are algorithms for minimum link path computation.
Minimum link path is a geometric path that consists of straight line segments and does a minimal number of turns.
We present new algorithms to several variations of the minimum link path problem.
\end{abstract}

\mytableofcontents


\setcounter{section}{-1}
\section{Preface}

"If it was hard to write, it should be hard to read." -- Anonymous

\section{Introduction}

Path finding problems are a widely studied subject in algorithmics.\cite{survey}
A typical task is finding the shortest path between two nodes in a graph.
Geometric version of the problem asks for the shortest path in a continuous space, such as plane with polygonal obstacles.
The typical task is to minimize the Euclidean length of the path, but there are other relevant metrics as well.
For example a robot might move forward fast, but be slow at corners, so a long simple route is sometimes preferable to a shorter but more complex route.

The topic of this thesis is finding geometric path the do minimum amount of turns.
Consider a path consisting of a finite number of straight line segments.
The \emph{link distance} of the path is the number of segments.
A \emph{minimum link path} between two points is a path that minimizes the link distance.
Figure~\ref{fig:paths} displays an example of two kinds of minimum link paths as well as the regular shortest path.

\begin{figure}\centering
	\includegraphics{fig/paths}
	\caption{There are many variants of the path finding problem in the plane, resulting in different kinds of paths.}\label{fig:paths}
\end{figure}

Finding minimum link paths is a well studied algorithmic problem.
The basic idea employed by most known algorithms is a simple extension of bredth-first search:
First find points that have link distance~1 to the starting point, then points with link distance~2, and similarly iterate until the desired endpoint is encountered.
Since the search happens in continuous space, the hard part of the algorithms is defining the appropriate data structures to store and update the discovered area.

In this thesis we focus on the \emph{rectilinear} variant of the problem.
In the rectilinear minimum link path problem we require the obstacles as well as the paths to be constructed to follow the coordinate axes.
We also study 3D version of the rectilinear minimum link path problem.
For this version we present a new algorithm that works in time $O(n^2\log^2n)$, which is a significant improvement over the earlier best known result $O(n^{2.5}\log n)$.\cite{restricted}
Finally, we extend the solution to the 3D rectilinear problem to work in $D$-dimensional domains, giving an algorithm with running time $O(n^D\log^Dn)$.

\subsection{Background and new results}

Computing rectilinear minimum link paths is and old and well studied problem.
For 2D domains an algorithm with running time $O(n\log n)$ and linear space complexity was developed independently by Das and Narasimhan~\cite{dasnar} and by Sato, Sakanaka and Ohtsuki~\cite{sato}.
This result is asymptotically optimal, as the problem can be shown to be as hard as sorting~\cite{dasnar}, and thus having lower bound $O(n\log n)$.

Several algorithms have been developed to compute higher dimensional rectilinear minimum link paths.
De Berg et al.~\cite{de1992} gave an $O(n^D\log n)$ algorithm for the $D$-dimensional minimum link path problem.
For the 3D case, a $O(n^3)$ algorithm was developed by Mikami and Tabuchi~\cite{mikami}.
Fitch, Butler and Rus~\cite{fitch} gave an algorithm with improved performance in many cases, but still $O(n^3)$ worst case running time.
This was further improved by Wagner, Drysdale and Stein~\cite{wagner}, who gave an algorithm with worst case time complexity $O(n^{2.5}\log n)$.

In this thesis we focus on new results to the rectilinear minimum link path problem, which are original research of the author.
The following results have been published in peer-reviewed journals and conferences, and were made in collaboration with the respective co-authors.
\begin{itemize}
\item A simplified $O(n\log n)$ algorithm for the 2-dimensional case.
\item A new algorithm for the 3D minimum link path problem, improving the running time from the previous best result of $O(n^{2.5}\log n)$ to $O(n^2\log^2 n)$.
\end{itemize}

The following items are new original contributions in this thesis.

\begin{itemize}
\item An algorithm for minimum link paths in higher dimensions. We show that the rectilinear minimum link path problem in $D$ dimensions can be solved in time $O(n^{D-1}\log^{D-1} n)$ by a generalization of the 3D algorithm.
\item Detailed description of the algorithm for 3D minimum link path computation and the data structures used in the algorithm.
\item Extension of the decomposition used in the 3D algorithm to higher dimensions.
\item Simplification of the 3D minimum link algorithm by using the unified segment tree by Wagner~\cite{unified}.
\item Extending the unified tree to higher than 2 dimensions and showing how clearing a hyperrectangle can be implemented. The original paper by Wagner~\cite{unified} mentions the possibility of extending the structure to higher dimensions, but does not provide any details.
\end{itemize}

\subsection{Overview of algorithms}\label{sec:overview}

All the known algorithms for the minimum link path problem use the same basic idea:
The tasks is to find a minimum link path from point \spt to point \ept.
Let \reach{k} be the set of points reachable by at most $k$ links from \spt.
Start by defining $\reach{0}=\set{\spt}$, and iteratively compute \reach{k+1} from \reach{k}.
The iteration continues until we find $k$ such that $\ept\in\reach{k}$.
This iteration is often called \emph{staged illumination}, because the computation of \reach{k+1} can be illustrated by setting a light source in all points of \reach{k}, and selecting all the lit points.
Figure~\ref{fig:staged} displays an example of the staged illumination process.

\begin{figure}\centering
	\includegraphics[scale=0.5,page=1]{fig/staged}
	\hfil
	\includegraphics[scale=0.5,page=2]{fig/staged}
	\hfil
	\includegraphics[scale=0.5,page=3]{fig/staged}
	\hfil
	\includegraphics[scale=0.5,page=4]{fig/staged}
	\caption{Four steps of staged illumination from a single starting point. The new areas are illuminated through the red windows on each step.}\label{fig:staged}
\end{figure}

This process closely resembles the bredth-first search, but a key difference is that the search is done in continuous space rather than in a graph.
A nontrivial part in any minimum link path algorithm is maintaining the illuminated area in a data structure that allows efficient computation of \reach{k+1} from \reach{k}.

Representing the illuminated area can be simplified by first splitting the free space into simple primitives.
A common approach in computational geometry is to start by triangulating the input, which allows working with simple forms.
In case of minimum link paths with restricted orientations, rectangles or trapezoids are the most comfortable representations.
In Section~\ref{sec:decomposition} we present algorithms for construction decompositions suitable for minimum link path computation.

With restricted orientations that the paths can take, we can use \emph{sweep line algorithms} to efficiently compute \reach{k+1} from \reach{k}.
The idea is to "sweep" over the search space by a line, and use the sweep to calculate how the path can advance into the direction of the sweep line.
This generic technique allows us to transform the 2-dimensional illumination problem into a series of easier 1-dimensional problems on the sweep line.
The sweep line technique is discussed in Section~\ref{sec:sweep}.

During the sweeps we need to maintain the relationship between the sweep line and the obstacles as well as the region \reach{k}.
Maintaining this kind of information requires efficient handling of 1-dimensional intervals.
\emph{Segment tree} is a generic data structure for working with intervals.
It can be used to efficiently implement all the operations required by the staged illumination.
Segment trees are described in Section~\ref{sec:segtree}.

We combine the aforementioned concepts into an algorithm for finding minimum link paths in Section~\ref{sec:minlink2d}.
The ideas of the two-dimensional solution can also be generalized to work in higher dimensions.
Many details need to be taken care of, but the basic ideas are relatively straightforward to transfer to more than two dimensions.
The space is decomposed into cuboids instead of rectangles, and the sweep line is replaced by a sweep plane.
The segment tree can also be generalized into a higher dimensional structure.
These elements are combined into an algorithm for finding minimum link paths in higher dimensional domains in Section~\ref{sec:minlink3d}.



\section{Space decomposition}\label{sec:decomposition}

The domain of the minimum link path problem is a polygon with smaller polygons as obstacles.
The input is given as a list of polygons, and each polygon is described by a list of vertices.
This form is inconvenient for path planning algorithms, as many simple operations, such as checking whether we can move from a given point to given direction, require scanning through all the polygons.

In the rectilinear minimum link path problem the obstacle edges are oriented according to the coordinate axis.
This allows us to decomposition the free space into rectangles, which is a convenient form for rectilinear path computation.
For each cell of the decomposition we also construct links to neighboring cells and obstacles.
In other words, the decomposition is a graph with rectangles as vertices and an edge between each pair of adjacent rectangles.
If the total number of edges in all the obstacles is $n$, we can decompose the space into $O(n)$ cells such the total number of links between cells is also $O(n)$.

A similar structure can also be used for computing minimum link paths in 3-dimensional domains.
In 3D rectilinear case each obstacle face is a polygon with axis-aligned edges in 3D space.
In this case the free space can be decomposed into a graph with $O(n^2)$ cuboid as vertices and $O(n^2)$ edges.


\subsection{Sweep line algorithms}\label{sec:sweep}

Sweep line algorithms are a generic technique used for a wide range of computational geometry problems.
The idea is to image a line that crosses over the domain.
As the sweep line progresses, we gradually update the solution to take into account the parts of the domain that the line has crossed.
Conceptually the sweep line moves continuously in space, but in practice we only process a discrete set of \emph{events} where some structural change to the solution happens.


\subsection{Planar decomposition}\label{sec:decomp2d}

A rectilinear domain can be decomposed into rectangles by extending each horizontal obstacle edge in both directions until the sides hit a vertical obstacle edge.
This defines the \emph{horizontal decomposition} of the domain, denoted \decomp{x}.
The vertical decomposition \decomp{y} is defined correspondingly by extending all the vertical edges until they hit a horizontal obstacle.
Figure~\ref{fig:decomp}

\begin{figure}\centering
	\includegraphics[scale=0.6,page=2]{fig/decomp}
	\hfil
	\includegraphics[scale=0.6,page=3]{fig/decomp}
	\caption{Horizontal and vertical decomposition of the same domain. Each cell touches at least one obstacle corner and each obstacle corner touches at most two cells, so both decompositions have size $O(n)$.}\label{fig:decomp}
\end{figure}

It is easy to see that each cell of \decomp{x} touches at least one obstacle vertex.
Since each vertex can be touched by at most two rectangles, the size of the decomposition is $O(n)$.
Each pair of touching rectangles also shares a common obstacle corner, so the number of links is also $O(n)$.

\decomp{x} can be constructed with a line sweep algorithm.
We sweep over the domain by a horizontal line moving from $y$ coordinate $-\infty$ (down) to $\infty$ (up).
During the sweep we maintain the intersection of the free space \fspace and the sweep line.
The intersection consists of non-overlapping intervals, which we store in a binary search tree.

Each element added to the binary tree is a partially constructed rectangle $a$ with the following fields.
\begin{itemize}
\item Interval $\xrange{a}=\range{\xranget{a}{1}}{\xranget{a}{2}}$.
\item Interval $\yrange{a}=\range{\yranget{a}{1}}{\yranget{a}{2}}$.
\item List of neighbor links $\nbs{a}$.
\end{itemize}

The sweep stops at each horizontal obstacle edge.
When moving from down to up, each edge starts either starts or ends an obstacle.
If the edge starts an obstacle, the $x$-range of the edge is fully contained in one of the intervals in the search tree.
If the edge ends an obstacle, the $x$-range does not intersect any intervals in the tree, but the left and right endpoints may touch some intervals.
In both cases the intervals touching the encountered edge are removed from the search tree, and $O(1)$ new intervals are inserted to maintain the sweep line state.
A more exact description of the algorithm follows below.

\begin{alg}\label{alg:split2d}
Decomposition of \fspace into a group of rectangular cells \decomp{x}.
\begin{algorithmic}
\State $T\gets \text{Empty binary search tree}$.
\State $E\gets\text{All horizontal obstacle edges}$.
\State Sort $E$ by the $y$ coordinates of the edges.
\ForAll{$e\in E$}
	\If{$e$ starts an obstacle}
		\Comment Exactly one interval in $T$ intersects \xrange{e}.
		\State $v\gets\text{Lookup $T$ for interval touching \xrange{e}}$.
		\State Remove $v$ from $T$.
		\State $\yranget{v}{2}\gets\y{e}$.
		\ForAll{$u\gets v\setminus s$}
			\State $\yranget{u}{1}\gets\y{e}$.
			\State Insert $v$ to list $\nbs{u}$.
			\State $a\gets\text{New rectangle}$.
			\State $\xrange{a}\gets u$.
			\State $\yranget{a}{1}\gets\y{e}$.
			\State Insert $a$ to tree $T$.
		\EndFor
	\Else\Comment $e$ starts free space.
		\State $a\gets\text{New rectangle}$
		\State $\xrange{a}\gets\xrange{e}$.
		\State $\yranget{a}{1}\gets\y{e}$.
		\ForAll{$v\in$ lookup $T$ for intervals touching \xrange{e}}
			\State Remove $v$ from $T$.
			\State Insert $v$ to list \nbs{a}.
			\State $\xrange{a}\gets\xrange{a}\cup\xrange{v}$.
		\EndFor
		\State Insert $a$ to $T$.
	\EndIf
\EndFor
\end{algorithmic}
\end{alg}

The complexity of the algorithm can be easily bounded.

\begin{lem}\label{lem:split2dtime}Algorithm~\ref{alg:split2d} works in time $O(n\log n)$ and space $O(n)$.\end{lem}
\begin{proof}
The algorithm sorts all the horizontal edges in time $O(n\log n)$, and iterates over them in $O(n)$ steps.
On each step we emit $O(1)$ cells and neighbor links, and perform $O(1)$ operations to the binary search tree.
The search tree is a balanced binary tree, so each operation to it is carried out in time $O(\log n)$.
Thus the total complexity of the algorithm is $O(n\log n)$, and we only need $O(n)$ storage for the edge list and the binary search tree.
\end{proof}

\subsection{3D cuboid decomposition}\label{sec:split3d}

Similarly as a 2D domain can be decomposed into rectangles, a 3D rectilinear domain can be decomposed into cuboids.
Decomposition into cuboids is used in the algorithm for 3D minimum link paths in Section~\ref{sec:minlink3d}.
The running time of the path finding algorithm is heavily depent on the size of the decomposition, so it is desirable to find as small decomposition as possible.

The input is given as a list of 2-dimensional obstacle faces in 3-dimensional space.
Each obstacle face is a polygon defined by a list of vertices.
Denote the total number of vertices by $n$.

We present a simple algorithm that uses the Algorithm~\ref{alg:split2d} as a subroutine.
This algorithm produces a decomposition with $O(n^2)$ cells and $O(n^2)$ links.
There also exists algorithms for finding decompositions with even small number of cells, but the worst case for number of links is superquadratic for all the known solutions.

The solution is a sweep plane algorithm, whichi sweeps through the domain with a plane perpendicular to $z$-axis.
During the sweep we maintain the intersection of the sweep plane and the domain~\fspace.
The intersection of the domain and a plane is called a \emph{cross section} of the domain.

In each cross section we form a 2D decomposition of the domain with Algorithm~\ref{alg:split2d}, and extend the $xy$-rectangles in $z$-direction so that they fill the whole free space.
Any common rectangles shared by consecutive cross sections are merged into a single larger cuboid.
The merging is done by by maintaining a binary search tree of the cells of the previous decomposition.

The description below only calculates the cells, but not the links between them.
We discuss the computation of links below.

\begin{alg}\label{alg:split3d}
Decompose the free space defined by a set $E$ of obstacle faces into cuboids.
\begin{algorithmic}
\State $Z\gets$ All $z$-coordinates of obstacle vertices.
\State Sort $Z$ in increasing order.
\State $R\gets$ Empty list of result cells.
\State $M\gets$ Empty binary search tree mapping 2D rectangles to indices in $R$.
\ForAll{$z\in Z$}
	\State $E_z\gets\set{e \mid e\in E, \zrange{e}\ni z}$.
	\State $T\gets$ 2D decomposition for $E_z$ using Algorithm~\ref{alg:split2d}.
	\ForAll{$m\in M\setminus T$}
		\State $c\gets R[M[m]]$.
		\State Upper $z$-coordinate of $c\gets z$.
		\State Remove $m$ from $M$.
	\EndFor
	\ForAll{$t\in T\setminus M$}
		\State $c\gets$ New cell with $xy$-bounds $t$ and starting $z$-coordinate $z$.
		\State Insert $c$ into $R$.
		\State $M[t]\gets$ index of $c$ in $R$.
	\EndFor
\EndFor
\State Return list $R$.
\end{algorithmic}
\end{alg}

The running time of the algorithm is easy to determine using Lemma~\ref{lem:split2dtime}.

\begin{lem}\label{lem:split3dtime}Algorithm~\ref{alg:split3d} has running time $O(n^2\log n)$.\end{lem}
\begin{proof}
We loop through $O(n)$ unique $z$-coordinates.
For each $z$ we construct a set of obstacles in time $O(n)$ and a 2D decomposition in time $O(n\log n)$.
The map $M$ is implemented as a binary search tree, so each update and lookup can be performed in time $O(\log n)$.
For each $z$ we perform $O(n)$ such updates, so the total time bound is $O(n^2\log n)$.
\end{proof}

Algorithm~\ref{alg:split3d} divides the space into cuboids, but does not generate any links between them.
First we bound the number of links.
The following lemma helps in the analysis.

\begin{lem}\label{lem:decomp2dch}
Consider two obstacle sets $A$ and $B$ on 2D plane.
Let $n$ be the total number of obstacle edges in $A$ and $B$, and $k$ be the number of edges that are present in exactly one of the sets.
The number of overlapping rectangles in \decomp{x}(A) and \decomp{x}(B) is $O(nk)$.
\end{lem}
\begin{proof}
Consider how the sweep line of Algorithm~\ref{alg:split2d} advances in domains $A$ and $B$.
Recall that the sweep line is a horizontal line moving in $y$-direction.

The intersection of the sweep line and the free space is a sequence of disjoint intervals for both $A$ and $B$.
Since there are $O(k)$ changes to the set of obstacles, the edit distance between the interval sets is $O(k)$.
Thus each $y$ coordinate contributes $O(k)$ pairs to the overlap.
Since the number of $y$ coordinates where the domain changes is $O(n)$, the total number of overlapping pairs is $O(nk)$.
\end{proof}

\begin{lem}\label{lem:split3dcount}The number of pairs of adjacent cells in the decomposition produced by Algorithm~\ref{alg:split3d} is $O(n^2)$.\end{lem}
\begin{proof}
Since the number of links produced by Algorithm~\ref{alg:split2d} is $O(n)$, any cross section has $O(n)$ links in $x$ and $y$ directions.
Thus the total number of $x$ and $y$ links is $O(n^2)$.

Let $k_z$ be the number of different obstacles on the cross sections on planes $z=z_k-\varepsilon$ and $z=z_k+\varepsilon$.
Since the total number of obstacles is $n$, the sum of different $k_z$ values is $n$.
The number of links between two adjacent layers is $O(nk_z)$ by Lemma~\ref{lem:decomp2dch}.
Summing up all the changes gives the desired bound $\sum_z O(nk_z) = O(n^2)$.
\end{proof}

Since we know how to compute links for 2D decomposition, the links in $x$ and $y$ directions can easily be obtained from the cross sections.
What remains is computing the links in $z$ direction.
We compute the links between each pair of adjacent cross sections separately.

Let $A$ and $B$ be the sets of rectangles that are different on the horizontal decompositions of two adjacent cross sections.
Finding the $z$-links in the 3D decomposition is equivalent to finding the set of overlapping pairs between $A$ and $B$.
The pairs are found by running \emph{another} line sweep algorithm after both $A$ and $B$ have been created by Algorithm~\ref{alg:split2d}.

We sweep through the domain again by a horizontal line.
During the sweep we maintain two binary search tree $T_A$ and $T_B$, containing the rectangles of $A$ and $B$ touching the sweep line respectively.
The binary search tree is ordered by the $x$-coordinate of the rectangle.
Note that the rectangles in each of the sets $A$ and $B$ are disjoint, so the $x$-ranges are disjoint as well.

Each time the sweep line arrives into a new rectangle $a\in A$, the tree $T_B$ is queries to find all the rectangles touched by the bottom line of $a$.
Similarly for each new rectangle $b\in B$, we query the tree $T_A$ for rectangles touching the bottom line of $b$.
A more exact description of the algorithm is below.

\begin{alg}\label{alg:overlap2d}
Find all overlapping pairs of two sets of rectangles $A$ and $B$.
\begin{algorithmic}
\State $E\gets$ All bottom and top edges of rectangles in $A$ and $B$.
\State Sort $E$ by $y$-coordinate.
\State $T_A\gets$ Empty binary search tree.
\State $T_B\gets$ Empty binary search tree.
\ForAll{$e\in E$}
	\State $s\in\set{A,B}\gets$ Group to which $e$ belongs to.
	\State $t\in\set{A,B}\gets$ Group to which $e$ does not belong to.
	\If{$e$ starts a rectangle}
		\State Find all elements from $T_t$ with $x$-range intersection the $x$-range of $e$.
		\State Add the rectangle to $T_x$.
	\Else
		\State Remove the rectangle from $T_x$.
	\EndIf
\EndFor
\end{algorithmic}
\end{alg}

\begin{lem}\label{lem:overlap2dtime}Algorithm~\ref{alg:overlap2d} runs in time $O(n\log n + k)$, where $n$ is the total size of $A$ and $B$, and $k$ is the number of overlapping pairs.\end{lem}
\begin{proof}
First we sort all the top and bottom edges in the input in time $O(n\log n)$.
We then iterate over all the edges, performing 3 kinds of tree operations: add, remove and lookup.

Each add and lookup operation takes $O(\log n)$ time in a balanced binary search tree.
The lookup of elements intersecting the given element is done by first finding the leftmost intersecting element in the tree, and then scanning adjacent tree nodes until all the intersecting elements have been found.
This requires time $O(\log n+u)$ where $u$ is the number of overlapping pairs.

Combining the time for sorting, tree additions, deletions and lookups, the total complexity is $O(n\log n + k)$.
\end{proof}

We are now ready to prove the main result of this section.

\begin{theo}\label{theo:split3dtime}3D rectilinear domain defined by obstacles with a total of $n$ vertices can be decomposed into $O(n^2)$ cuboids with $O(n^2)$ links between them in time $O(n^2\log n).$\end{theo}
\begin{proof}
The cuboids can be constructed in time $O(n^2\log n)$ according to Lemma~\ref{lem:split3dtime}.
The total number of links between the nodes is $k=O(n^2)$ according to Lemma~\ref{lem:split3dcount}.
Computing the links between all the layers can then be done in time $O(n^2\log n+k)=O(n^2\log n)$ by Lemma~\ref{lem:overlap2dtime}.
Thus the total time complexity is $O(n^2\log n)$, and the total number of cuboids and links is $O(n^2)$.
\end{proof}



\subsection{Higher dimensional decomposition}

The ideas of the 3D decomposition can be generalized to allow decomposing 4D and higher dimensional rectilinear domains into hyperrectangles.
The construction is done recursively, so that $D$-dimensional decomposition is created by solving a sequence of $(D-1)$-dimensional sub-problems.
The idea is identical to how the 3D decomposition is constructed based on a sequence of 2D decompositions in Algorithm~\ref{alg:split3d}.

\begin{alg}\label{alg:splitdd}
Decompose the free space defined by a set $E$ of $(D-1)$-dimensional obstacle faces into $D$-dimensional hyperrectangles.
\begin{algorithmic}
\If{$D=2$}
	\State Compute the decomposition using Algorithm~\ref{alg:split2d} and return.
\EndIf
\State $Z\gets$ All $D$-coordinates of obstacle vertices.
\State Sort $Z$ in increasing order.
\State $R\gets$ Empty list of result cells.
\State $M\gets$ Empty binary search tree mapping $D-1$-dimensional rectangles to indices in $R$.
\ForAll{$z\in Z$}
	\State $E_z\gets\set{e \mid e\in E, e_D\ni z}$.
	\State $T\gets$ $(D-1)$-dimensional decomposition for $E_z$ recursively.
	\ForAll{$m\in M\setminus T$}
		\State $c\gets R[M[m]]$.
		\State Upper $D$-coordinate of $c\gets z$.
		\State Remove $m$ from $M$.
	\EndFor
	\ForAll{$t\in T\setminus M$}
		\State $c\gets$ New cell with the first $D-1$ coordinates defined by $t$ and starting $D$-coordinate $z$.
		\State Insert $c$ into $R$.
		\State $M[t]\gets$ index of $c$ in $R$.
	\EndFor
\EndFor
\State Return list $R$.
\end{algorithmic}
\end{alg}

The analysis is similar to the 3D case, except that we now use induction on $D$.

\begin{lem}\label{lem:splitddcells}The number of rectangles produced by Algorithm~\ref{alg:splitdd} is $O(n^{D-1})$.\end{lem}
\begin{proof}
Proof by induction on $D$.
Since the size of the horizontal decomposition of 2D space is $O(n)$, the claim is clearly true for $D=2$.
For $D>2$, we loop over the $O(n)$ unique values of the $D$-coordinate in the obstacles.
For each cross-section we compute a $(D-1)$-dimensional decomposition, whose size is $O(n^{D-2})$ by induction.
The combination of the $n$ sub-problem results has thus size $O(n^{D-2}n)=O(n^{D-1})$.
\end{proof}

\begin{lem}\label{lem:splitddtime}The running time of Algorithm~\ref{alg:splitdd} is $O(n^{D-1}\log n)$.\end{lem}
\begin{proof}
Proof by indunction on $D$.
Since we use Algorithm~\ref{alg:split2d} for case $D=2$, Lemma~\ref{lem:split2dtime} proves the base case $D=2$.

For $D>2$, we solve $O(n)$ sub-problems, each of which can be done in time $O(n^{D-2}\log n)$ by induction.
The total time of solving all the sub-problems is thus $O(n^{D-1}\log n)$.

We also maintain a mapping from $(D-1)$-dimensional hyperrectangles to result indices.
The size of the mapping is bounded by the size of the $(D-1)$-dimensional decompositions, which have size $O(n^{D-2})$ by Lemma~\ref{lem:splitddcells}.
Thus each map operation can be done in time $O(\log{n^{D-2}})=O(\log n)$.
The number of map operations for each cross-section is $O(n^{D-2})$, so the total time spent in the map operations is $O(nn^{D-2}\log n)=O(n^{D-1}\log n)$.
\end{proof}

We can similarly prove a bound for the number of links with induction that uses the proofs for 2D and 3D domains as the base case.

\begin{lem}\label{lem:decompddch}
Consider two obstacle sets $A$ and $B$ that each define a $D$-dimensional domain.
Let $n$ be the total number of $(D-1)$-dimensional obstacle faces in $A$ and $B$, and $k$ be the number of faces that are present in exactly one of the sets.
The number of overlapping $D$-dimensional hyperrectangles in the decompositions of $A$ and $B$ is $O(n^{D-1}k)$.
\end{lem}
\begin{proof}
Proof by induction on $D$.
The base case $D=2$ is proven by Lemma~\ref{lem:decomp2dch}.

For $D\ge 3$ consider how the sweeps of Algorithm~\ref{alg:split3d} advance in domains defined by $A$ and $B$.
Each of the sweeps stops at $O(n)$ points, producing a $(D-1)$-dimensional decomposition for the cross section.
For any $D$-coordinate, the cross-sections of the domains of $A$ and $B$ differ by $O(k)$ obstacles, so the number of links at a fixed $D$-coordinate is $O(n^{D-2}k)$ by induction.

The total number of links between the two decompositions is the total number of links counted in each of the $O(n)$ cross-sections.
This may count some links multiple times, but each link is counted at least once.
Each cross-section has $O(n^{D-2}k)$ links, so the total number of links has upper bound $O(n^{D-1}k)$.
\end{proof}

\begin{lem}\label{lem:splitddcount}The number of links between adjacent pairs of hyperrectangles produced by Algorithm~\ref{alg:splitdd} is $O(n^{D-1})$.\end{lem}
\begin{proof}
Consider separately the links in direction $D$ and in the other directions.
For both cases, we count the number of links using induction on $D$.
For the base case of the induction, the number of links in case $D=2$ is $O(n)$, as shown in Section~\ref{sec:decomp2d}.

The links in directions other than $Z$ can be obtained from the $(D-1)$-dimensional decompositions produced during the sweep.
By induction, the number of links in each $(D-1)$-decomposition is $O(n^{D-2})$, so the total number of links in directions other than $Z$ is $O(n^{D-1})$.

To count the number of links in direction $D$, observe how the cross-section changes as the sweep hyperplane advances through the domain.
If two adjacent cross sections differ by $u$ obstacles, the number of links between the cross-sections is $O(n^{D-2}u)$ by Lemma~\ref{lem:decompddch}.
The total number of obstacles changing during the sweep is $O(n)$, so the total count of the links between all adjacent levels is $O(n^{D-1})$.
\end{proof}

The proof of Lemma~\ref{lem:splitddcount} gives a hint for designing an algorithm to compute the links.
Similarly to the proof, we consider separately the links in direction $D$ and in the other directions.
The links in directions other than $D$ can be obtained recursively from the solutions of the sub-problems.
The links in direction $D$ are computed by performing an additional sweep between each pair of adjacent cross-sections and using a recursive method similar to the proof above.
Each sweep finds the direction $D$ links by using the following recursive algorithm.

\begin{alg}\label{alg:overlapdd}
Find all overlapping pairs of two sets of $D$-dimensional hyperrectangles $A$ and $B$.
\begin{algorithmic}
\Procedure{FindOverlapping}{$D,A,B$}
	\If{$D=2$}
		\State Return overlapping pairs computed with Algorithm~\ref{alg:overlap2d}.
	\EndIf
	\State $E\gets$ List of all faces of hyperrectangles in $A$ and $B$ perpendicular to $D$-axis.
	\State Sort $E$ by $D$-coordinate.
	\State $G\gets$ Groups of consequtive elements of $E$ with equal $D$-coordinate.
	\State $P_A\gets$ Empty set of references to $A$.
	\State $P_B\gets$ Empty set of references to $B$.
	\State $R\gets$ Empty list of pairs.
	\ForAll{$g\in G$}
		\State $S_A\gets$ Starting elements of $A$ in $g$.
		\State $S_B\gets$ Starting elements of $B$ in $g$.
		\State $T_A\gets$ Ending elements of $A$ in $g$.
		\State $T_B\gets$ Ending elements of $B$ in $g$.
		\State $P_A\gets P_A\setminus T_A$.
		\State $P_B\gets P_B\setminus T_B$.
		\State $R\gets R + \findol(D-1,P_A,B_B)$.
		\State $R\gets R + \findol(D-1,S_A,P_B)$.
		\State $R\gets R + \findol(D-1,S_A,S_B)$.
		\State $P_A\gets P_A\cup S_A$.
		\State $P_B\gets P_B\cup S_B$.
	\EndFor
	\State Return list $R$.
\EndProcedure
\end{algorithmic}
\end{alg}

The algorithm processes each set of events with equal $D$-coordinate as a single unit.
For each unit we recursively search for new links between the newly added hyperrectangles, as well as between old and new hyperrectangles.
We maintain the set of hyperrectangles currently intersecting the sweep hyperplane to avoid adding already included intersections to the result twice.

\begin{lem}\label{lem:overlapddok}
Algorithm~\ref{alg:overlapdd} finds each intersecting pair between the input sets $A$ and $B$ exactly once.
\end{lem}
\begin{proof}
Proof by induction on $D$.
If $D=2$, we use Algorithm~\ref{alg:overlap2d}, which was shown to work correctly in Section~\ref{sec:split3d}.

Suppose $D\ge 3$.
The algorithm iterates over the $D$-coordinates where at least one of $A$ or $B$ changes.
By induction we know that the 3 recursive calls inside the iteration each report the intersections of the provded inputs exactly once.
On each iteration we create sets $S_A$ and $S_B$, which are the newly introduced hyperrectangles at this coordinate.
Since $S_A$ and $S_B$ contain only new rectangles, none of the 3 recursive calls may find any pairs that were previously added.
Thus the algorithm finds each intersecting pair at most once.

At the point of making the recursive calls, the sets $P_A$ and $P_B$ contain all the rectangles whose $D$-ranges strictly contain the current $D$-coordinate.
Two ranges can only itersect is they either share the starting point or the starting point of one of the ranges is inside the other range.
The recursive call $\findol(D-1,S_A,S_B)$ handles the ranges with the common starting point, and the other two recursive calls handle the case of the starting point being inside the other range.
Thus the algorithm finds all the intersectin pairs at least once.
Since we have proven that each pair is found at most once, this completes the proof.
\end{proof}

The algorithm for the $D$-dimensional overlap computation is simpler than the special case for $D=2$.
However Lemma~\ref{lem:overlap2dtime} cannot be directly extended to higher dimensions, because there is no guarantee that the subproblems are significantly smaller than the original problem.
Instead we prove a less generic lemma by using the properties of the decompositions.

\begin{lem}\label{lem:overlapddtime}
Let $A$ and $B$ be two decompositions generated by Algorithm~\ref{alg:splitdd} for two different inputs that have a total of $n$ obstacles.
Then Algorithm~\ref{alg:overlapdd} runs in time $O(n^{D-1}\log n + k)$ for inputs $A$ and $B$, where $k$ is the number of overlapping pairs.
\end{lem}
\begin{proof}
Proof by induction on $D$.
The base case $D=2$ is proven by Lemma~\ref{lem:overlap2dtime}.

For $D\ge 3$, the decomposition is created by combining the $(D-1)$-dimensional decompositions at each cross section.
Thus the sweep hyperplane of Algorithm~\ref{alg:overlapdd} intersects a $(D-1)$-dimensional decomposition produced by Algorithm~\ref{alg:splitdd} at each point of the sweep.
By Lemma~\ref{lem:splitddcells} this implies that the index sets maintained during the sweep have size $O(n^{D-2})$.
Performing the set operations on the $n$ steps of the sweep then has total time complexity $O(n^{D-1}\log n)$.

The time taken by each of the 3 recursive calls on each cross section is $O(n^{D-2}\log n + u)$ by induction, where $u$ is the number of overlapping pairs returned from the subproblem.
By Lemma~\ref{lem:overlapddok} each intersection is found exactly once, so the total complexity of the recursive calls during the sweep is $O(n^{D-1}\log n + k)$.
\end{proof}

Finally, we can generalize Theorem~\ref{theo:split3dtime} to $D$ dimensions.

\begin{theo}\label{theo:splitddtime}$D$-dimensional rectilinear domain defined by obstacles with a total of $n$ vertices can be decomposed into $O(n^{D-1})$ hyperrectangles with $O(n^{D-1})$ links between them in time $O(n^{D-1}\log n).$\end{theo}
\begin{proof}
The cuboids can be constructed in time $O(n^{D-1}\log n)$ according to Lemma~\ref{lem:splitddtime}.
The total number of links between the nodes is $k=O(n^{D-1})$ according to Lemma~\ref{lem:splitddcount}.
Computing the links between all the layers can then be done in time $O(n^{D-1}\log n+k)=O(n^2\log n)$ by Lemma~\ref{lem:overlapddtime}.
Thus the total time complexity is $O(n^{D-1}\log n)$, and the total number of cuboids and links is $O(n^{D-1})$.
\end{proof}



\section{Segment tree}\label{sec:segtree}

Segment tree is a data structure that allows storing and querying of number intervals.
The structure allows performing a wide range of operations in logarithmic time.
Some example of operations that can be implemented include:
\begin{itemize}
	\item Insert and remove interval to the tree.
	\item Find all the intervals intersecting a given query interval.
	\item Cut of a given range from all the ranges in the tree.
\end{itemize}

Rather than as a single data structure that is used as a black box, the segment trees are better viewed as a framework that can be adapted to work in various situations.
Segment trees are straightforward to augment to contain additional information about the intervals, and use the information in queries.
For example we can associate a number with each interval, and efficiently query for the maximum number overlapping a given query interval.
We first present the general idea of the tree, and then show how it can be applied to the minimum link path problem.

Segment trees are typically implemented as semi-dynamic structures.
This means that the tree can be efficiently modified after it has been build, but we need to specify the set of possible endpoints \epts of intervals in advance.
This allows implementing most operations in time $O(\log\segsize)$, and the size of the tree is $O(\segsize)$, where $\segsize=\size{\epts}$.

\subsection{Structure of a segment tree}

A segment tree is a binary tree where each node $n$ corresponds to a fixed half-open interval $\inter{n}$.
Each branch node $s$ has two child nodes \leftc{s} and \rightc{s}.
The intervals of the children divide the parent interval into two parts:
$\inter{s}=\inter{\leftc{s}}\cup\inter{\rightc{s}}$, $\inter{\leftc{s}}\cap\inter{\rightc{s}}=\emptyset$.
The root node corresponds the largest supported interval \range{\epts[1]}{\epts[\segsize]}, and the leaf nodes correspond to the smallest possible intervals \range{\epts[i]}{\epts[i+1]}.
Figure~\ref{fig:segtree} displays an example of a segment tree.

\begin{figure}\centering
	\includegraphics[scale=0.7,page=1]{fig/segtree}
	\caption{Structure of a segment tree. The numbers display how the nodes are indexed when the tree is stored in an array.}\label{fig:segtree}
\end{figure}

The structure of a semi-dynamic segment tree is independent of the intervals added to the tree.
The nodes are commonly arranged into an almost complete binary tree, which allows storing the tree nodes in an array similarly to binary heap:
the root node is stored in index~1, and the child nodes of node $i$ are $2i$ and $2i+1$.
This representation allows implementing segment tree operations with very low overhead, making segment tree a powerful practical tool in addition to providing asymptotical bounds.

\subsection{Canonical nodes}

When an interval $I$ is added to a segment tree, it is added to several tree nodes called the \emph{canonical nodes} of $I$, denoted by \canon{I}.
The canonical nodes of $I$ are the smallest set of nodes whose intervals cover $I$ but nothing else: $\cup_{c\in\canon{I}} \inter{c}=I$.
Figure~\ref{fig:canon} displays examples of canonical nodes.

\begin{figure}\centering
	\includegraphics[scale=0.7,page=1]{fig/canon}
	\caption{Two intervals, red and blue, and their canonical nodes in the segment tree.}\label{fig:canon}
\end{figure}

Let \canonpar{I} be the set of ancestors of \canon{I}.
The following two lemmas are useful for proving the running times of segment tree operations.

\begin{lem}\label{lem:canonlog}$\size{\canon{I}}=O(\log\segsize)$ for any interval $I$.\end{lem}
\begin{proof}
As the segment tree is a balanced binary tree, it has depth $\Theta(\log\segsize)$.
We show that $\canon{I}$ contains at most 2 nodes on each depth, which proves the claim.

If a set $N$ contains 3 nodes on the same depth, we can replace the middle one with its parent node without affecting the interval covered by $N$.
Thus $N$ is not a minimal cover of $I$, and can not be \canon{I}.
\end{proof}

\begin{lem}\label{lem:canonplog}$\size{\canonpar{I}})=O(\log\segsize)$ for any inverval $I$.\end{lem}
\begin{proof}
Similarly to the previous proof we show that \canonpar{I} cannot contain more than 2 nodes on the same depth.

Suppose, for a contradiction, that \canonpar{I} contains 3 nodes on the same depth: $a$, $b$ and $c$ in that order.
Then $\inter{a}\cap I\neq\emptyset$ and $\inter{c}\cap I\neq\emptyset$, so $\inter{b}\subseteq I$.
Some grandchild of $b$ belongs to \canon{I}, so \canon{I} is not a minimal cover, which is a contradiction.
\end{proof}

We can iterate over the canonical nodes and their ancestors by using the following recursive algorithm starting from the root node.

\begin{alg}\label{alg:segiter}
Visit all the elements of \canon{I} and \canonpar{I}.
\begin{algorithmic}
\Procedure{IterCanonical}{$n$}
\Comment{Visit the canonical nodes in the subtree rooted at node $n$}
	\If{$\inter{n}\subseteq I$}
		\State \visitc($n$)
	\ElsIf{$\inter{n}\cap I\neq\emptyset$}
		\State \visitp($n$)
		\State \textsc{IterCanonical}($\leftc{n}$)
		\State \textsc{IterCanonical}($\rightc{n}$)
	\EndIf
\EndProcedure
\end{algorithmic}
\end{alg}

Algorithm~\ref{alg:segiter} can be used to implement other tree operations such as adding intervals to segment tree by defining the called methods \visitc and \visitp appropriately.
The recursion traverses through the nodes in \canonpar{I}, and stops immediately when it arrives either to a node in \canon{I} or to a node neither in \canon{I} nor in \canonpar{I}.
Thus the running time is proportional to the sizes of \canon{I} and \canonpar{I}, which is $O(\log\segsize)$ by Lemma~\ref{lem:canonlog} and Lemma~\ref{lem:canonplog}.

\subsection{Tree operations}\label{sec:treeops}

We now show how the segment trees can be used for finding intersecting intervals.

\begin{lem}\label{lem:segintersect}Consider any two intervals $I$ and $J$.
At least one of the following is true if and only if $I\cap J\neq\emptyset$.
\begin{enumerate}
\item $\canon{I}\cap\canon{J}\neq\emptyset$,
\item $\canon{I}\cap\canonpar{J}\neq\emptyset$,
\item $\canonpar{I}\cap\canon{J}\neq\emptyset$.
\end{enumerate}
\end{lem}
\begin{proof}
First suppose that $I\cap J\neq\emptyset$.
Let $x$ be any leaf node of the segment tree such that $\inter{x}\in I\cap J$.
Let $A$ be the set of ancestors of $x$.
Since the canonical nodes of an interval cover the whole interval, $A$ intersects both \canon{I} and \canon{J}.
Let $i$ and $j$ be the nodes where $A$ intersects with \canon{I} and \canon{J} respectively.
Either $i$ and $j$ are the same node, or one of them is an ancestor of the other, which proves the "if" part of the claim.

For the "only if" part, we look at the three cases separately.
\begin{enumerate}
\item If there exists a node $n\in\canon{I}\cap\canon{J}$, then $\inter{n}\subseteq I\cap J$, so $I\cap J\neq\emptyset$.
\item If there is a node $n\in\canonpar{I}\cap\canon{J}$, then there exists $m\in\canon{I}$ that is a grandchild of $n$. $\inter{m}\subseteq I$ and $\inter{m}\subsetneq\inter{n}\subseteq J$, so $I\cap J\neq\emptyset$.
\item Identical to the second case.
\end{enumerate}
\end{proof}

Lemma~\ref{lem:segintersect} can be used to find intersecting pairs of intervals in a segment tree.
In each node $n$ of the segment tree, maintain two lists of intervals:
\begin{itemize}
\item \nodecs{n}: Intervals $I$ for which $n\in\canon{I}$,
\item \nodeps{n}: Intervals $I$ for which $n\in\canonpar{I}$.
\end{itemize}
When interval $I$ is added to the segment tree, it is added to \nodecs{n} for all $n\in\canon{I}$ and to \nodeps{n} for all $n\in\canonpar{I}$.
When we look for intervals intersecting a given interval $J$, we report all the intervals in \nodecs{n} for all $n\in\canonpar{J}$ and in \nodeps{n} for all $n\in\canon{J}$.
By Lemma~\ref{lem:segintersect} this finds exactly the intervals intersecting $J$ and nothing else.
Note, though, that some intervals might be counted multiple times.
The structure can be further extended to avoid reporting the duplicates, but for the minimum link paths use case we only need to be able to check whether the query interval overlaps any of the intervals in the tree, so this solution is sufficient.

We also want to support clearing an interval from the tree.
Clearing interval $I$ means that all the intervals $J$ in the tree are cut into $J\setminus I$, potentially removing $J$ completely or cutting it into two parts.
The clear operation is performed in the following three steps:
\begin{enumerate}
\item Split rectangles that touch $I$ but are not contained by $I$ into smaller parts.
\item Completely clear each each subtree rooted in any node $n\in\canon{I}$.
\item Recompute \nodeps{n} to match the remaining nodes for all nodes $n\in\canonpar{I}$.
\end{enumerate}

All the tree operations can be done in parallel during a single recursive traversal of the tree.
For nodes $n\in\canonpar{I}$ we push down the intervals in \nodecs{n} to the child nodes before proceeding with the recursion.
When we arrive in a node $n\in\canon{I}$, the entire subtree rooted at $n$ is cleared.
After the child nodes are cleared, we also need to regenerate the \nodeps{n} list for the nodes $n\in\canonpar{I}$ to account for the intervals that are no longer present in the subtree.
The regeneration is done by merging the lists in the child nodes of $n$.
The exact algorithm for clearing is shown below.

\begin{alg}\label{alg:segrm}
Clear interval $I$ from a segment tree.
\begin{algorithmic}
\Procedure{ClearInterval}{$n$}
	\Comment Clears interval $I$ from subtree rooted at $n$.
	\If{$\inter{n}\cap I=\emptyset$ or $\nodeps{n}$ is empty}
		Return.
	\EndIf
	\If{$\inter{n}\nsubseteq I$}
		\State Copy \nodecs{n} to \nodecs{\leftc{n}} and to \nodecs{\rightc{n}}.
	\EndIf
	\State Clear \nodecs{n}.
	\State Clear \nodeps{n}.
	\If{\leftc{n} and \rightc{n} defined}
		\State $\cleariv(\leftc{n})$.
		\State $\cleariv(\rightc{n})$.
	\EndIf
	\If{$\inter{n}\cap I\neq\emptyset$}
		\State $\nodeps{n}\gets \nodeps{\leftc{n}} \cup \nodeps{\rightc{n}} \cup \nodecs{\leftc{n}} \cup \nodecs{\rightc{n}}$.
	\EndIf
\EndProcedure
\end{algorithmic}
\end{alg}

The running time of Algorithm~\ref{alg:segrm} depends on the time taken for copying and merging the intervals stored in the tree nodes.
If we are only interested in querying whether a given interval overlaps any interval in the tree rather than finding the overlapping intervals, we can replace the interval lists by booleans indicating whether the list is empty.
We analyze this more simple case.

\begin{lem}\label{lem:segrmtime}Suppose that the copying and merging of interval sets in Algorithm~\ref{alg:segrm} can be done in constant time.
Then the time complexity of clearing range $I$ is $O(\log\segsize + k)$, where $k$ is the number of cleared nodes.\end{lem}
\begin{proof}
The function $\textsc{ClearInterval}$ traverses through nodes \canon{I}, \canonpar{I}, and the descendants of the canonical nodes, stopping immediately if it ends up in a non-empty subtree.
In each descendant node we either clear the node or return immediately, so the cost of visiting the descendants can be accounted to the cleared nodes.
The number of canonical nodes and their ancestors is $O(\log\segsize)$, so the total complexity is $O(\log\segsize + k)$.
\end{proof}


\subsection{Multidimensional segment tree}

The segment tree can be generalized into two or higher dimensional structure.
A two-dimensional segment tree stores rectangles, and allows efficient queries for rectangular regions.
Correspondingly a $D$-dimensional segment tree provides efficient operations for $D$-dimensional hyperrectangles.

A multidimensional segment tree is composed of of nested regular segment trees.
The shape of a $D$-dimensional segment tree is a 1-dimensional segment tree whose each node stores a $(D-1)$-dimensional segment tree.

Each tree dimension represents one of the $D$ coordinate axes.
Each node $n$ of the innermost segment tree represents a $D$-dimensional hyperrectangle \rect{n}, whose bounds are defined by the position of the node on each of the $D$ tree levels.
For example the outer tree of a 2-dimensional segment tree represents the $y$ coordinates, and each inner tree represents the $x$ coordinates.
Each node of the inner tree represents a rectangle whose $x$-bounds are determined by the position of the node in the inner tree, and the $y$-bounds are determined by the node of the outer tree that contains the inner tree.

The concept of canonical nodes can also be extended to higher dimensions.
The canonical nodes \canon{R} of a $D$-dimensional hyperrectangle $R$ are the smallest set of nodes that fully cover $R$ but nothing else.
Figure~\ref{fig:canon2d} displays an example of canonical nodes of a 2-dimensional segment tree.

\begin{figure}\centering
	\includegraphics[scale=0.7,page=1]{fig/canon2d}
	\caption{Rectangle in a two-dimensional segment tree. The original rectangle is drawn with solid line, and its canonical nodes with dotted lines.}\label{fig:canon2d}
\end{figure}

In order to compute the canonical nodes we look into each axis separately.
Let interval $R_i$ be the projection of hyperrectangle $R$ into $i$-axis.
Let $\canoni{R_i}{i}$ be the canonical rectangles of $R_i$ in the 1-dimensional segment tree built for $i$-coordinates.

Consider a 2-dimensional segment tree, and two arbitrary nodes of the projected 1-dimensional trees $c_1\in\canoni{R_1}{1}$ and $c_2\in\canoni{R_2}{2}$.
Let $c_1\times c_2$ be the node of the 2-dimensional tree that is found in position of $c_1$ in the inner tree, and $c_2$ in the outer tree.
Similarly for $D$-dimensional trees we define product $c_1\times c_2\times\dots\times c_n$ to be the node of a $D$-dimensional segment tree defined by positions of 1-dimensional tree nodes.
The following lemma shows how the canonical nodes of 1-dimensional projections can be combined to get the canonical nodes of a $D$-dimensional tree.

\begin{lem}\label{lem:canond}
For any $D$-dimensional hyperrectangle $R$ applies
$$\canon{R}=\set{c_1\times c_2\dots\times c_D \mid c_1\in\canoni{R_1}{1}, \dots, c_D\in\canoni{R_D}{D}}.$$
In other words, \canon{R} is the Cartesian product of one-dimensional canonical sets
$$\canon{R}=\bigtimes_{i=1}^D \canoni{R_i}{i}.$$
\end{lem}
\begin{proof}
Proof by induction on $D$.
The base case $D=1$ follows directly from the definition of \canon{R}.

For $D\ge 2$ note that all of the inner $(D-1)$-dimensional segment trees are identical.
Thus to cover a rectangular region minimally, we should select the same set of nodes in each inner tree.
By induction we should select the nodes $bigtimes_{i=1}^{D-1} \canoni{R_i}{i}$ in the inner trees to cover axes $1\dots D-1$ optimally.
To cover also axis $D$, it is optimal to select the nodes $\canoni{R_D}{D}$, and thus $\canon{R}=\bigtimes_{i=1}^D\canoni{R_i}{i}$.
\end{proof}

Combination of Lemma~\ref{lem:canond} and Lemma~\ref{lem:canonlog} gives bound for the size of the canonical set.

\begin{lem}$\size{\canon{R}}=O(\log^D\segsize)$ for any $D$-dimensional rectangle $R$.\end{lem}
\begin{proof}
$$
\size{\canon{R}} = \size{\bigtimes_{i=1}^D \canoni{R_i}{i}}
= \prod_{i=1}^D \size{\canoni{R_i}{i}}
= \prod_{i=1}^D O(\log\segsize)
= O(\log^D\segsize).
$$
\end{proof}

For 1-dimensional segment trees there is a clear connection between the parent-child hierarchy and interval overlap.
For any two tree nodes $a$ and $b$, $\inter{a}\subseteq\inter{b}$ if and only if $b$ is an ancestor of $a$ in the tree.
In multidimensional case it also applies that if $b$ is an ancestor of $a$, then $\rect{a}\subseteq\rect{b}$.
However the reverse is not true; $\rect{a}\subseteq\rect{b}$ does not imply that $b$ is an ancestor of $a$ because $b$ can be in a different subtree in some of the outer trees.

Instead of looking for parent-child relationships directly in the tree, we can look at them separately on each coordinate axis.
This allows us to generalize Lemma~\ref{lem:segintersect} for segment interaction to work for rectangles.

\begin{lem}\label{lem:rectintersect}Consider any two $D$-dimensional hyperrectangles $A$ and $B$.
If $A\cap B\neq\emptyset$, then the following holds for each coordinate axis $d\in\set{1,\dots,D}$.
\begin{enumerate}
\item $\canoni{A_d}{d}\cap\canoni{B_d}{d}\neq\emptyset$,
\item $\canoni{A_d}{d}\cap\canonpari{B_d}{d}\neq\emptyset$,
\item $\canonpari{A_d}{d}\cap\canoni{B_d}{d}\neq\emptyset$.
\end{enumerate}
Furthermore, if $A\cap B=\emptyset$, then there is at least one coordinate axis for which none of the conditions hold.
\end{lem}
\begin{proof}
$A$ and $B$ overlap if and only if their projections to each coordinate axis overlap.
Suppose that $A\cap B\neq\emptyset$.
Then $A_d$ and $B_d$ overlap for each $d$, and by Lemma~\ref{lem:segintersect} the condition holds for each $d$.
If $A\cap B=\emptyset$, then there exists some $d$ for which $A_d\cap B_d=\emptyset$, so again by Lemma~\ref{lem:segintersect} none of the conditions hold for $d$.
\end{proof}

To apply Lemma~\ref{lem:rectintersect} to detect intersecting rectangles, we create \emph{two} $D-1$ dimensional inner trees to every outer node of a $D$-dimensional segment tree:
\begin{description}
\item[\subtree{n}] where we store rectangles $R$ for which $n\in\canoni{R_D}{D}$,
\item[\subtreep{n}] where we store rectangles $R$ for which $n\in\canonpari{R_D}{D}$.
\end{description}

We can write rectangle insertion and query operations by using these fields.
For simplicity we only support checking whether a query rectangle intersects any rectangle in the tree rather than returning the matching rectangles.
The nodes $n$ of the innermost tree have dimension 0, and they contain only a single boolean \hasrect{n}, which indicates that at least one rectangle is inserted to this subtree.

\begin{alg}\label{alg:rectadd}
Add rectangle $R$ to $D$-dimensional tree.
\begin{algorithmic}
\Procedure{InsertToTree}{$D,n$}
\Comment{Insert to the subtree rooted at node $n$}
	\If{$D=0$}
		\State $\hasrect{n}\gets\texttt{true}$.
	\ElsIf{$\inter{n}\subseteq R_D$}
		\State $\adddt(D-1,\subtree{n})$.
	\ElsIf{$\inter{n}\cap R_D\neq\emptyset$}
		\State $\adddt(D-1,\subtreep{n})$.
		\State $\adddt(D,\leftc{n})$.
		\State $\adddt(D,\rightc{n})$.
	\EndIf
\EndProcedure
\end{algorithmic}
\end{alg}

\begin{alg}\label{alg:rectcheck}
Query whether rectangle $R$ intersects with any rectangle in the tree.
\begin{algorithmic}
\Procedure{QueryTree}{$D,n$}
\Comment{Check subtree rooted at node $n$}
	\State $R\gets\texttt{false}$.
	\If{$D=0$}
		\State $R\gets\hasrect{n}$.
	\ElsIf{$\inter{n}\subseteq R_D$}
		\State $R\gets \checkdt(D-1,\subtree{n})$.
		\State $R\gets R$ or $\checkdt(D-1,\subtreep{n})$.
	\ElsIf{$\inter{n}\cap R_D\neq\emptyset$}
		\State $R\gets \checkdt(D-1,\subtree{n})$.
		\State $R\gets R$ or $\checkdt(D,\leftc{n})$.
		\State $R\gets R$ or $\checkdt(D,\rightc{n})$.
	\EndIf
	\State Return $R$.
\EndProcedure
\end{algorithmic}
\end{alg}

\begin{lem}\adddt and \checkdt both have time complexity $O(\log^D n)$.\end{lem}
\begin{proof}
Proof by induction on $D$.
For the base case $D=0$ both algorithm finishes in constant time.
For $D\ge 1$, algorithms iterate over the canonical nodes and their ancestors in the outer tree, making $\log{n}$ calls to the inner trees.
By induction the inner tree operations are done in time $O(\log^{D-1}n)$, so the total time complexity is $O(\log^D n)$.
\end{proof}

Note that \subtree{} and \subtreep{} are used in opposite ways in the two operations.
In \adddt{} we recurse down to \subtree{} for canonical nodes, and to \subtreep{} for their ancestors, whereas in \checkdt{} we recurse to \subtree{} in the ancestor nodes, and to both of the trees in the canonical nodes.
This allows us to ensure that \adddt{} and \checkdt{} arrive in the same node exactly in the case where the conditions of Lemma~\ref{lem:rectintersect} are fulfilled.

Suppose we first add rectangle $A$ and then query for rectangle $B$ in the tree.
The \checkdt operation returns true if the two operations end up in the same dimension-0 node.
The only way the two operations end up in a common node is if in each dimension $d$ we are in a canonical node of at least one of $A_d$ and $B_d$, and in either a canonical node or an ancestor for the other rectangle.
If \adddt{} and \checkdt{} operations end up in the same level-0 node, then in each dimension we are in the canonical node of at least either

Thus we can efficiently support inserting and querying for $D$-dimensional hyperrectangles by a nested structure consisting of multiple levels of segment trees.
However clearing a rectangle in this structure is considerable more difficult to support.
For that we turn into another variant of the multidimensional segment tree, the unified segment tree.

\subsection{Unified segment tree}\label{sec:unifiedtree}

The structure of a multidimensional segment tree depends on how we order the coordinate axes.
For example a two-dimensional segment tree can have either the outer tree represent $y$-coordinates and each inner tree represent $x$-coordinates, or the other way round.
The structure and parent-child relationships are different in the two cases, but the sets of rectangles represented by the nodes of the inner trees are exactly the same.

The \emph{unified segment tree} combines the parent-child links of the different multidimensional segment trees into a single structure.
The unified segment tree is not a tree, but a directed graph.
Each node $n$ of the graph represents a $D$-dimensional hyperrectangle.
For each axis $i$ where \rect{n} is not minimal, $n$ has links to two child nodes that divide \rect{n} into two parts along hyperplane perpendicular to $i$-axis.
Thus each node has between 0 and $2D$ links to child nodes.
The children splitting the node $n$ along axis $i$ are denoted by \leftu{n}{i} and \rightu{n}{i}.

Note that in the unified tree there is no distinction between outer and inner tree.
In the regular multidimensional segment tree the nodes of nested tree represent ranges in one of the coordinate axes, and the innermost nodes represent their cartesian product.
In the unified tree, there are no outer and inner nodes, and each node represents a $D$-dimensional hyperrectangle.

The operations \adddt and \checkdt for unified tree are largely similar to the algorithms for the regular multidimensional tree.
We consider again checking whether the query rectangle intersects with any of the hyperrectangles in the tree rather than reporting all the intersecting hyperrectangles.
Each tree node stores $2^D$ bits of information about the hyperrectangles stored in the subtree.
When a hyperrectangle $R$ is added to node $n$, the bits are used to define whether $n$ represents a canonical node or an ancestor of a canonical node along each coordinate axis.
The $2^D$ bits allow us to detect when the conditions of Lemma~\ref{lem:rectintersect} become fulfilled for the query rectangle and a rectangle in the tree.
The following function computes the mask for a rectangle and a tree node.

\begin{alg}\label{alg:maskof}
Compute bitmask representing how hyperrectangle $R$ is stored in unified tree node $n$.
\begin{algorithmic}
\Procedure{NodeMask}{$R,n$}
	\State $m\gets 0$
	\ForAll{$d \in 1\dots D$}
		\If{$\rect{n}_d\subseteq R_D$}
			\State $m\gets m + 2^d$
		\EndIf
	\EndFor
	\State Return $m$.
\EndProcedure
\end{algorithmic}
\end{alg}

We can write procedures \adddt and \checkdt by using this function.

\begin{alg}\label{alg:uadd}
Add rectangle $R$ to $D$-dimensional unified tree.
\begin{algorithmic}
\Procedure{InsertToTree}{$d,n$}
\Comment{Insert to the subtree rooted at node $n$ by moving along axes $1\dots d$}
	\If{$d=0$}
		\State $m\gets\maskof{R,n}$.
		\ForAll{$b \in 0\dots 2^D-1$}
			\If{All bits of $b$ are set in $m$}
				\State $\hasbits{n}{b}\gets\texttt{true}.$
			\EndIf
		\EndFor
		\State $\hasrect{n}\gets\texttt{true}$.
	\ElsIf{$\rect{n}_d\subseteq R_d$}
		\State $\adddt(d-1,n)$.
	\ElsIf{$\rect{n}_d\cap R_d\neq\emptyset$}
		\State $\adddt(d-1,n)$.
		\State $\adddt(d,\leftu{n}{d})$.
		\State $\adddt(d,\rightu{n}{d})$.
	\EndIf
\EndProcedure
\end{algorithmic}
\end{alg}

For \checkdt we use function $\texttt{reverseBits}$, which reverses the bits of a $2^D$-bit input.
For example if $D=2$ then $\texttt{reverseBits}(0111_2)=1000_2$.

\begin{alg}\label{alg:ucheck}
Query whether rectangle $R$ intersects with any rectangle in the unified tree.
\begin{algorithmic}
\Procedure{QueryTree}{$d,n$}
\Comment{Check subtree rooted at node $n$}
	\State $R\gets\texttt{false}$.
	\If{$d=0$}
		\State $R\gets\hasbits{n}{\texttt{reverseBits}(\maskof{R,n})}$.
	\ElsIf{$\inter{n}\subseteq R_d$}
		\State $R\gets\checkdt(d-1,n)$.
	\ElsIf{$\inter{n}\cap I\neq\emptyset$}
		\State $R\gets\checkdt(d-1,n)$.
		\State $R\gets R$ or $\checkdt(d,\leftu{n}{d})$.
		\State $R\gets R$ or $\checkdt(d,\rightu{n}{d})$.
	\EndIf
	\State Return $R$.
\EndProcedure
\end{algorithmic}
\end{alg}

The interesting part of the query algorithm is checking if the tree node contains a rectangle by expression $\hasbits{n}{\texttt{reverseBits}(\maskof{R,n})}$ when querying for hyperrectangle $R$.
When adding a hyperrectangle $A$, we set $\hasbits{n}{b}$ for each bitmask $b$ whose bits are contained in $\maskof{A,n}$.
Thus the expression in \checkdt detects $A$ if $\maskof{A,n}|\maskof{R,n}=2^D-1$, where $x|y$ represents the bitwise OR operation of $x$ and $y$.
This is equivalent to condition that $\rect{n}_d$ is the range of a canonical node of either $R_d$ or $A_d$ in each dimension $d$.
This matches the conditions of Lemma~\ref{lem:rectintersect} for rectangle intersection, so the intersection is returned if and only if $R$ and $A$ truly intersect.

Next we consider clearing a rectangle from the unified tree.
Clearing a rectangle $R$ means that all the rectangles in the tree are cut such that the region of $R$ becomes empty.
The clear operation is implemented using the same three operations as we used for the 1-dimensional tree in Section~\ref{sec:treeops}:
split touching intervals, clear subtrees of the canonical nodes, and finally recompute the information about hyperrectangles stored in the descendants.

The three operations are performed by a recursive function \cleardt that traverses through the tree.
The function guides the tree traversal with two arguments: the current subtree root $n$, and the axis where we are moving $d$.
In each canonical parent $n\in\canonpari{R_d}{d}$ we split the contents of the subtree along axis $d$ before proceeding, and recompute the descendant information after finishing clearing the subtree.
The full algorithm is described below.

\begin{alg}\label{alg:segurm}
Clear rectangle $R$ from $D$-dimensional unified segment tree.
\begin{algorithmic}
\Procedure{ClearFromTree}{$d,n$}
	\If{$\inter{n}\cap R_d=\emptyset$ or $\neg\hasbits{n}{0}$}
		\State Return.
	\EndIf
	\If{$d=0$}
		\State $\hasbita{n}\gets\texttt{false}$.
		\State Return.
	\EndIf
	\If{$\rect{n}_d\nsubseteq R_d$}
		\State $\pdst(d-1,n,d)$.
	\EndIf
	\State $\cleardt(d-1,n)$.
	\If{\leftu{n}{d} and \rightu{n}{d} defined}
		\State $\cleardt(d,\leftu{n}{d})$.
		\State $\cleardt(d,\rightu{n}{d})$.
	\EndIf
	\If{$\rect{n}_d\nsubseteq R_d$}
		\State $\recomp(d,n)$.
	\EndIf
\EndProcedure

\Procedure{PushDownSubtree}{$d,n,a$}
	\Comment Pushes down values in subtree $n$ along axis $a$.
	\If{$d=0$}
		\State $\hasbita{\leftu{n}{a}}\gets \hasbita{\leftu{n}{a}} | \hasbita{n}$.
		\State $\hasbita{\rightu{n}{a}}\gets \hasbita{\rightu{n}{a}} | \hasbita{n}$.
		\State Return.
	\ElsIf{$\rect{n}_d\cap R_d=\emptyset$}
		\State Return.
	\EndIf
	\State $\pdst(d-1,n,a)$.
	\If{\leftu{n}{d} and \rightu{n}{d} defined}
		\State $\pdst(d,\leftu{n}{d},a)$.
		\State $\pdst(d,\rightu{n}{d},a)$.
	\EndIf
\EndProcedure

\Procedure{RecomputeSubtreeData}{$d,n$}
	\If{$d=0$}
		\State $\hasbita{n}\gets\texttt{false}$.
		\State $m\gets\maskof{R,n}$.
		\ForAll{$a \in 1\dots D$}
			\If{$\rect{n}_a \subseteq R_a$}
				Continue.
			\EndIf
			\State $c_1\gets\leftu{n}{a}$.
			\State $c_1\gets\rightu{n}{a}$.
			\ForAll{$b \in 0 \dots 2^D-1$}
				\If{$b$ does not have bit $a$ set}
					\State $\hasbits{n}{b}\gets \hasbits{n}{b}$ or $\hasbits{c_1}{b}$ or $\hasbits{c_2}{b}$.
				\EndIf
			\EndFor
		\EndFor
		\State Return.
	\ElsIf{$\inter{n}\cap R_d=\emptyset$}
		\State Return.
	\EndIf
	\State $\recomp(d-1,n)$.
	\If{\leftu{n}{d} and \rightu{n}{d} defined}
		\State $\recomp(d,\leftu{n}{d})$.
		\State $\recomp(d,\rightu{n}{d})$.
	\EndIf
\EndProcedure
\end{algorithmic}
\end{alg}

\begin{lem}\label{lem:segurmtime}Algorithm~\ref{alg:segurm} has running time $O(\segsize^{D-1}\log\segsize + k)$, where $k$ is the number of cleared canonical nodes.\end{lem}
\begin{proof}
We start by proving that \pdst and \recomp have running time $O(\segsize^d)$ by induction on the argument $d$.
Clearly the functions perform $O(1)$ work in case $d=0$, which proves the base case.
If $d\ge 1$, then both functions recursively iterate over the child nodes in direction $d$, making $O(\segsize)$ recursive calls with argument $d-1$.
By induction the recursive calls are done in time $O(\segsize^{d-1})$, so the time complexity of both \pdst and \recomp is $O(\segsize^d)$.

Next we prove the running time of \cleardt by induction on argument $d$.
If $d=1$ the calls to \pdst and \recomp perform $O(1)$ work, and the algorithm is equivalent to Algorithm~\ref{alg:segrm} for 1-dimensional segment tree removal.
Thus the base case $d=1$ is proven by Lemma~\ref{lem:segrmtime}.

In case $d\ge 2$ we iterate over the child nodes in direction $d$.
We call \pdst and \recomp with argument $d-1$ for every node in \canonpari{R_d}{d}.
We also make $O(\segsize)$ calls to \cleardt with argument $d-1$.
The size of \canonpari{R_d}{d} is $O(\log\segsize)$, so by induction the total time complexity is $O((\log\segsize)\segsize^{d-1} + \segsize(\segsize^{d-2}\log\segsize))=O(\segsize^{d-1}\log\segsize)$.

\end{proof}



\section{Planar minimum link paths}\label{sec:minlink2d}

In this section we study the rectilinear minimum link path in a plane.
In the rectilinear problem both the obstacle segments as well as the links of the path to be produced must be aligned to coordinate axes.
We present a simple algorithm with time complexity $O(n\log n)$ and space complexity $O(n)$.
The ideas develoepd for the the simple algorithm are later generalized to solve the more difficult 3D minimum link path problem in Section~\ref{sec:minlink3d}.

\subsection{Intersection graph}

We solve the minimum link path problem by applying the staged illumination paradigm outlined in Section~\ref{sec:overview}.
Initialize \reach{0} to contain the starting point, and iteratively expand the illuminated area by computing \reach{k+1} based on \reach{k}.
The iteration is continued until we find the desired endpoint.

It is easy to see that in any minimum link path consists of alternation between horizontal and vertical links.
We split the problem into two subproblems, based on whether the first link is horizontal or vertical.
The minimum link path can be found by solving both subproblems and choosing the shorter of the two solutions.

Consider the case with the first link horizontal.
It is easy to see that \reach{k+1} consists of points that can be reached by starting from \reach{k} and moving either horizontally or vertically, depending on the parity of $k$.
The regions that are illuminated on each step can be expressed using the horizontal and vertical decompositions defined in Section~\ref{sec:decomp2d}.
This is shown by the following lemma.

\begin{lem}\label{lem:illum2d}
For even $k>0$, the region \reach{k+1} consists of the rectangles $r\in\decomp{x}$ that intersect the region \reach{k}.
For odd $k$ the same applies for \decomp{y}.
\end{lem}
\begin{proof}
Let $k>0$ be even.
The region \reach{k} is formed by illuminating in vertical direction from \reach{k-1}.
Let $h$ be any rectangle in $decomp{x}$ that is at least partially illuminated in \reach{k}, and $p$ any point in $h\cap\reach{k}$.
Since \reach{k} is formed by illuminating vertically from \reach{k-1}, the vertical line segment passing between top and bottom edges of $h$ through $p$ must entirely belong to \reach{k}.
Illuminating horizontally from the vertical line passing through $h$ illuminated the entire rectangle, so $h\subseteq\reach{k+1}$.
Thus each rectangle of \decomp{x} intersected by \reach{k} is entirely contained in \reach{k+1}.

For odd $k$ we form \reach{k+1} by illuminating in vertical direction from \reach{k}, and the same proof applies for \decomp{y}.
\end{proof}

\begin{figure}\centering
	\includegraphics[scale=0.7,page=1]{fig/inter}
	\hfil
	\includegraphics[scale=0.7,page=2]{fig/inter}
	\caption{Group of four rectangles and their intersection graph. Each pair of overlapping objects has an edge between them in the intersection graph.}\label{fig:inter}
\end{figure}

For a set of geometric objects (such as rectangles) $G$, the \emph{intersection graph} of $G$ is a graph whose nodes are the elements of $G$, and there is an edge between each each pair of intersecting objects.
Figure~\ref{fig:inter} displays an example of a intersection graph.
Consider the intersection graph of $\decomp{x}\cup\decomp{y}$.
This graph has rectangles as nodes, and intersection rectangles between \decomp{x} and \decomp{y} are combined by an edge.
Let $k$ be an even number and $r\in\decomp{x}$ contained in \reach{k}.
Then for each neighbor $n$ of $r$ in the intersection graph applies $n\subseteq\reach{k+1}$ by Lemma~\ref{lem:illum2d}.
In other words, the staged illumination finds the rectangles in the same order as breadth-first search in the intersection graph.

The rectilinear minimum link path problem can thus be solved by forming the intersection graph and searching for the shortest path using breadth-first search.
The intersection graph has quadratic size, so we don't want to form the graph explicitly.
The challenging part of minimum link path finding is thus performing BFS in the intersection graph without explicitly forming the graph.

\subsection{Searching the intersection graph}

Consider again the case where the first link of the path is horizontal.
We start by constructing the horizontal decomposition with Algorithm~\ref{alg:split2d}.
The vertical decomposition is used implicitly in the analysis, but there is no need to construct it explicitly.

\reach{0} contains the start point~\spt, and \reach{1} is the horizontal line segment passing through \spt.
The path finding algorithm works by alternating between two phases:

\begin{enumerate}
\item For odd $k$, \reach{k} consists of a set of rectangles $R_k\subseteq\decomp{x}$.
	Inspect which obstacles can be reached by a vertical line starting from any point in \reach{k}, and form $\hat{R}_{k+1}=\set{r \mid r\in\decomp{x}, r\cap\reach{k+1}\neq\emptyset}$.
\item For even $k$, we simply set $R_{k+1}=\hat{R}_k$.
	Then $\reach{k+1}=\bigcup_{r\in R_{k+1}}r$ by Lemma~\ref{lem:illum2d}.
\end{enumerate}

We keep iterating these phases until the endpoint~\ept is reached in either phase.

For performance, it is important to ensure that we don't reilluminate the same parts of the domain many times.
We avoid the reillumination by marking cells of \decomp{x} as obstacles some time after they have been found.
If rectangle $r$ is discovered on step $k$, then it is fully illuminated in \reach{k+1}, and each point visible from $r$ is illuminated in \reach{k+2}.
After this there is no longer any need to illuminate through $r$, so we can treat $r$ as an obstacle after 2 steps have passed since the illumination first reached $k$.
This ensures that each rectangle is illuminated only a constant number of times.

Next we show how to implement illumination in $y$-direction starting from \reach{k}, which is represented as a set of rectangles $R\in\subseteq\decomp{x}$.
The illuminated area is computed with two line sweeps, in in direction $+y$ and the other in direction $-y$.

The sweep line stops at each rectangle to be illuminated.
During the sweep we maintain the intersection between the sweep line and the newly illuminated region \reach{k+1}.
The intersection consists of non-overlapping intervals stored in a binary search tree.

Let \nbsd{r}{d} and \obsd{r}{d} be the neighbor cell and the adjacent obstacles of rectangle $r$ in direction $d$ in \decomp{x}.
The algorithm below displays the illumination in direction $+y$.
The sweep in direction $-y$ is identical.

\begin{alg}\label{alg:light2d}
Compute illuminated rectangles from group $R$ into direction $+y$.
\begin{algorithmic}
\State $Q\gets\text{Priority queue containing the rectangles of $R$, ordered by the highest $y$-coordinate}$.
\State $T\gets\text{Empty binary search tree}$.
\While{$Q$ is not empty}
	\State $r\gets\pop{Q}$.
	\If{$r\in R$}
		\State Insert \xrange{r} into $T$.
	\EndIf
	\ForAll{$o\in\obsd{r}{+y}$}
		\ForAll{$t\in T$ touching \xrange{o}}
			\State Replace $t$ by $t\setminus\xrange{o}$, possibly removing it or splitting it into two parts.
		\EndFor
	\EndFor
	\ForAll{$n\in\nbsd{r}{+y}$}
		\If{$\xrange{n}$ touches any range in $T$ and $n\notin Q$}
			\State Insert $n$ into $Q$.
		\EndIf
	\EndFor
\EndWhile
\end{algorithmic}
\end{alg}

\begin{lem}\label{lem:light2dtime}The running time of Algorithm~\ref{alg:light2d} is $O(m\log m)$ where $m$ is the number of visited rectangles and their neighbor links.\end{lem}
\begin{proof}
The outermost loop processes a different rectangle $r$ each time, so it is executed $O(m)$ times.
For each obstacle adjacent to $r$ we cut of all the intersections with the obstacle from the binary search tree.
At most two of the intersected intervals remain in the tree, the others are removed, so the cost of the clearing operation can be accounted to the point when the nodes where added to the tree.
Thus the cost of processing an obstacle if $O(\log m)$ when the removing time is accounted to the insertions.
For each rectangle adjacent to $r$ we perform a single binary tree operation and possibly a single operation to the binary queue, which can both be done in time $O(\log m)$.
Thus the total time complexity is $O(m\log m)$.
\end{proof}

The link distance between \spt and \ept can be computed by iteratively performing the illumination sweeps in $+y$ and $-y$ directions until the endpoint is found.

\begin{alg}\label{alg:minlink2d}
Run staged illumination starting from \spt within \fspace such that the first link is horizontal.
\begin{algorithmic}
\State Form \decomp{x} for \fspace with Algorithm~\ref{alg:split2d}.
\State $R\gets\set{r\in\decomp{x} \mid \spt\in r}$
\State $k\gets 1$
\While{$R\neq\emptyset$}
	\ForAll{$r\in R$}
		\If{$\stepof{r}$ is not set}
			\State $\stepof{r}\gets k$
		\ElsIf{$\stepof{r} \le k-2$}
			\State Mark $r$ to be treated as obstacle during the sweeps.
			\State Remove $r$ from $R$.
		\EndIf
	\EndFor
	\State $H_{+y}\gets H$ illuminated in direction $+y$ by Algorithm~\ref{alg:light2d}.
	\State $H_{-y}\gets H$ illuminated in direction $-y$ by Algorithm~\ref{alg:light2d}.
	\State $H\gets H_{+y}\cup H_{-y}$.
	\State $k\gets k+1$
\EndWhile
\end{algorithmic}
\end{alg}

\begin{theo}Algorithm~\ref{alg:minlink2d} has time complexity $O(n\log n)$.\end{theo}
\begin{proof}
\decomp{x} is formed in time $O(n\log n)$ by Lemma~\ref{lem:split2dtime}.
\decomp{x} has $O(n)$ cells and links between cells.
Each cell is marked as an obstacle 2 steps after it has been found.
On each iteration of the main loop we perform two sweeps, so each cell can be visited at most 4 times by the sweeps.
The complexity of a single sweep is $O(m\log m)$ by Lemma~\ref{lem:light2dtime}, where $m$ is the number of visited rectangles.
Since each rectangle can be visited O(1) times, the total complexity of all the sweeps is $O(n\log n)$.
\end{proof}

The link distance between \spt and a target point \ept can be found by stopping the illumination process as soon as \ept becomes illuminated.
\epts can become illuminated either during a vertical sweep, or the implicit horizontal sweep that happens when we assign $H_{+y}\cup H_{-y}$ into $H$.
To construct the minimum link path between \spt and \ept, augment the algorithm such that we store into each rectangle how it was initially illuminated, and trace back the path when \ept gets illuminated.



\section{Paths in 3 and higher dimensions}\label{sec:minlink3d}

In this section we study the rectilinear minimum link path problem in 3D domain.
We present an algorithm that has time complexity $O(n^2\log^2n)$ and space complexity $O(n^2)$.
We also extend the algorithm to work in higher dimensions.
For any constant $D\ge 1$, the presented algorithm works in time $O(n^D\log^Dn)$.

Some of the basic ideas of the 2D minimum link path algorithm can also be applied to the 3D case.
The path is computed using the staged illumination paradigm, and on each step we compute \reach{k+1} from \reach{k} by using sweep plane algorithms in all the coordinate axis directions.
However in 3D case the representation of the illuminated space becomes more complicated, and also the sweep algorithms require more sophisticated logic.

We use the decomposition presented in Section~\ref{sec:split3d} to maintain the illuminated set and to guide the illumination during the sweeps.
Unlike the 2D case, the algorithm does not use any specific properties of the decomposition, but can be used with any space decomposition.
The running time of the algorithm is heavily dependend on the number of cells and links between them, and the decomposition we use has the advantage of having only a small number of links compared to other decompositions.

The decomposition is used to implement plane sweep algorithm for computing \reach{k+1} from \reach{k}.
On each step we run 6 sweeps, one in each of the directions $\pm x$, $\pm y$ and $\pm z$.
By combining the results of sweeping in each direction we form the whole region \reach{k+1}.
Next we discuss how the sweep plane algorithm is implemented, and then show how the minimum link path algorithm is built around it.

\subsection{Illumination by plane sweep}

We use a sweep plane algorithm to compute \reach{k+1} from \reach{k}.
The sweep algorithm performs two functions: it discovers which cells can be illuminated from \reach{k}, and it constructs the boundary of the illuminated region.
The boundary is used on the next step to compute \reach{k+2} from \reach{k+1}.

During the sweep we maintain the intersection of the sweep plane with the newly illuminated region, and a priority queue of events.
The events belong to one of the following types:

\begin{description}
\item[\addE] where a previously illuminated region is added to the sweep plane.
\item[\cellE] which occurs when the sweep plane reaches the end of a cell that potentially intersects with the illuminated region.
\item[\obsE] which occurs when the sweep plane encounters an obstacle face with normal opposite of the sweep direction.
\end{description}

Suppose that we are performing the sweep in direction $+z$.
In \cellE we first check whether the reached cell $c$ is truly illuminated.
If yes, we add a \cellE for each neighbor of $c$ in direction $+z$, and an \obsE for each obstacle adjacent to $c$ in direction $+z$.
In \obsE the projection of the encountered obstacle is cleared from the sweep plane.
Additionally the cleared rectangles are used to construct new \addEs on the boundary of the illuminated region to be used on the next illumination step.

During the sweep, the intersection of the illuminated region with the sweep plane is stored in the Unified 2D segment tree presented in Section~\ref{sec:unifiedtree}.
Each \addE inserts a new rectangle to the tree.
Each illuminated canonical node of the tree stores reference to the event that was used to generate it.
If multiple \addEs illuminate the same canonical rectangle, only the one inserted first is stored.
This reference is used to determine the $z$-range of the \addEs generated during \obsE, as well as for tracing back the path from \ept to \spt after the illumination is finished.

Pseudocode for the illumination plane sweep is as following.

\begin{alg}\label{alg:sweep3d}
Illuminate by plane sweep in direction $+z$ starting from a provided event set $E$.
\begin{algorithmic}
\State $Q\gets$ Priority queue containing $E$.
\State $T\gets$ Empty 2D segment tree.
\While{$Q$ is not empty}
	\State $e\gets\pop{Q}$.
	\If{$e$ is \addE}
		\State Insert \rectof{e} to $T$.
	\ElsIf{$e$ is \cellE}
		\If{\rectof{e} touches any rectangle in $T$}
			\State $c\gets\cellof{e}$.
			\ForAll{$o\in\obsd{c}{z+}$}
				\State Insert \obsE for $o$ to $Q$.
			\EndFor
			\ForAll{$n\in\nbsd{c}{z+}$}
				\State Insert \cellE for $n$ to $Q$.
			\EndFor
		\EndIf
	\ElsIf{$e$ is \obsE}
		\State Clear \rectof{e} from $T$.
		\State Generate \addEs for the cleared canonical rectangles.
	\EndIf
\EndWhile
\end{algorithmic}
\end{alg}

We can write down the basic pseudocode for the staged illumination by iteratively applying the sweep algorithm.

\begin{alg}\label{alg:minlink3d}
Run staged illumination in 3D domain \fspace starting from point \spt.
\begin{algorithmic}
\State Compute decomposition of \fspace into cells using Algorithm~\ref{alg:split3d}.
\ForAll{$d\in\set{\pm x,\pm y,\pm z}$}
	\State $E_d\gets$ Event set containing \addE at \spt and \cellE for the cell containing \spt.
\EndFor
\While{$E_d$ is not empty for some $d$}
	\ForAll{$d\in\set{\pm x,\pm y,\pm z}$}
		\State $E_d'\gets$ Empty event set.
	\EndFor
	\ForAll{$d\in\set{\pm x,\pm y,\pm z}$}
		\State Illuminate in direction $d$ using Algorithm~\ref{alg:sweep3d} with events $E_d$.
		\State Store the events generated by the sweep into $E_e'$ for $e\neq\pm d$.
	\EndFor
	\ForAll{$d\in\set{\pm x,\pm y,\pm z}$}
		\State $E_d\gets E_d'$.
	\EndFor
\EndWhile
\end{algorithmic}
\end{alg}

\subsection{Event generation}\label{sec:evtgen}

We now discuss how the \addEs for the next round are generated when the sweep processes an \obsE.
We again explain only the case for $+z$ sweep, as the other cases are identical.
The goal is to generate \addEs on the boundary of the space illuminated on step $k$, such that the sweeps on step $k+1$ correctly generate \reach{k+1}.

During the $+z$ sweep we generate \addEs in directions $\pm x$ and $\pm y$.
On a \obsE we perform a clear operation on the unified tree containing the sweep plane status.
Thus operations clears some of the tree nodes.
As a first step in even generation, we create an \addEs on each side of every cleared canonical rectangle.
This can create an unnecessarily large amount of events, because rectangles added to the tree are split to up to $(\log^2 n)$ canonical rectangles.

To reduce the number of generated events, we perform the following two steps after generating the events:
\begin{enumerate}
\item Remove all the pairs of \addEs with the same position but opposite direction.
\item Merge all sets of aligned \addEs with the same $z$-range into a single larger \addE.
\end{enumerate}

The aligned \addEs in direction $+x$ are the ones that occur on the same $x$ coordinate and have the same bounds in direction $z$, and the bounds in $y$-direction touch each other at endpoints.
The definition is similar in all the other directions.
The aligned \addEs are searched for the events in all directions separately.
Performing these operations allow us to bound the number of \addEs generated during the illumination.

To make the minimum link path computation efficient, we want to avoid reilluminating the same cells multiple times.
For the 2D minimum link paths this was done by turning cells into obstacles once enough steps have passed since the cell was first discovered.
This approach works also for 3D, but since there are $O(n^2)$ cells and clearing a rectangle from the unified tree requires $O(n\log n)$ steps, having to do clear operations for all the cells would increase the time complexity significantly.

To overcome this problem, instead of limiting the reachable cells, we instead limit the creation of \addEs.
We create \addEs for the next step when a plane sweep hits an obstacle.
If the illumination first reaches an obstacle face $o$ on step $k$, then after step $k+2$ all the points touching $o$ are illuminated, so after step $k+3$ all the points visible from $o$ are illuminated.
Thus we don't create any \addEs for an obstacle $o$ that was first found more than 3 steps ago, as any point illuminated through such events has been illuminated already.

\subsection{Complexity}

We now prove the complexity of the minimum link computation algorithm.

\begin{lem}\label{lem:obse3}For each obstacle we generate \obsE on at most 9 steps of the illumination.\end{lem}
\begin{proof}
Recall that we stop generating \addEs from obstacles after 3 steps have passed since that obstacle was discovered.
Suppose we first generate \obsE for obstacle $o$ on step $k$.
After step $k+3$ all the points visible from $o$ are illuminated.
After step $k+4$ we have discovered each obstacle $h$ such that the illumination reaching $h$ could generate an \addE that illuminates $o$.
We won't generate any \addEs for such obstacle $h$ after step $k+7$, so the last time a sweep can reach $o$ is on step $k+8$.
\end{proof}

\begin{lem}\label{lem:celle3}For each cell we generate \cellE on at most 9 steps of the illumination.\end{lem}
\begin{proof}
The proof is very similar to Lemma~\ref{lem:obse3}.
If we discover a cell $c$ on step $k$ then all the points visible from $c$ are illuminated after step $k+3$, so no more sweeps can reach $c$ after step $k+8$.
\end{proof}

\begin{lem}\label{lem:adde3}The number of \addEs generated during the illumation after after filtering is $O(n^2)$.\end{lem}
\begin{proof}
We only count the \addEs in direction $+z$.
The other directions are identical.
Each \addE lies on the same plane with some obstacle face whose normal points to direction $-z$.
For the purpose of deriving an upper bound, we assume that each obstacle face has unique $z$-coordinate.
We may overcount the number of \addEs this way by counting the same events multiple times, but not undercount.

Consider the events on the plane $P$ of obstacle $o$ at $z$-coordinate $\hat{z}$.
Events in direction $+z$ can be generated during the sweeps to direction $\pm x$ and $\pm y$.
We only consider the sweep in direction $+y$.
We generate an event on plane $P$ if an \obsE removes a rectangle $R$ from the unified tree such that the upper $z$-coordinate of $R$ is $\hat{z}$.

Some \addEs might be generated on $P$ because of how the rectangles are stored in the unified segment tree.
When we add a rectangle to the tree it is split to canonical nodes, and some of them might have boundary on $P$.
In such cases we generate \addEs both from canonical nodes on both sides of $P$, so the events are removed during the filtering, where we remove pairs of events at identical positions that have opposite directions.

Because of the canonical nodes aligned with sides on $P$, we may also generate \addEs in direction $\pm x$ whose $z$-range is bounded by $\hat{z}$.
In the second part of the filtering we merge aligned events into larger events.
Because we generate the events on both sides of $P$, we will merge them so that the $z$-range of the combined event contains $\hat{z}$ but does not have endpoint on it.

Because of the filtering, we can only have events on plane $P$ after the sweep has reached obstacle $o$.
There are three cases for how an event might be generated on plane $P$ that is not removed by the filtering.
\begin{enumerate}
\item During a sweep in direction $+z$ we hit the obstacle $o$.
	We generate \addEs in directions $\pm x$ and $\pm y$ that are bounded by $\hat{z}$.
	From these \addEs we create events on plane $P$ on the following illumination step.
\item During a sweep in direction $\pm x$ or $\pm y$ the obstacle face $o$ cuts a rectangle in the tree such that the remaining part has boundary on $P$.
\item If on the previous step we created $\addE$ on plane $P$, then we also created events in directions $\pm x$ or $\pm y$ that have plane $P$ as one of the sides.
	From those events we create more $+z$ events on plane $P$ on the following step.
\end{enumerate}

First let us consider the first two types of events.
They only occur through sweeps touching the surface of obstacle $o$.
By Lemma~\ref{lem:obse3} and Lemma~\ref{lem:celle3} such sweeps occur only on $O(1)$ steps.
On a single sweep, the number of events created on $P$ is bounded by the number of canonical rectangles whose $z$-range is bounded by $\hat{z}$.
There are $O(n)$ such rectangles, so the number of events is $O(n)$.

Now consider the third type of events.
A crucial observation is the following:
After the illumination has reached obstacle $o$, the illumination on $P$ proceeds exactly like the 2D staged illumination in the cross section of $P$.
The 2D illumination illuminates maximal rectangles of \decomp{x} and \decomp{y}, producing a total of $O(n)$ illuminated rectangles.
There is some overhead because of reilluminating the same parts multiple times, but by Lemma~\ref{lem:celle3} each part of the domain can be illuminated only $O(1)$ times.

The number of events on the plane of a single obstacle $o$ is $O(n)$, so the total number of events is $O(n^2)$.
\end{proof}

We are ready to prove the main result of this section.

\begin{theo}Algorithm~\ref{alg:minlink3d} computes 3D minimum link path in time $O(n^2\log^2n)$.\end{theo}
\begin{proof}
By Lemma~\ref{lem:celle3} each cell is visited $O(1)$ times during the illumination.
On each \cellE we perform a single lookup to the unified tree in time $O(\log^2 n)$, and iterate over the neighbors of the cell.
Since the decomposition has $O(n^2)$ cells and $O(n^2)$ links between cells, the total time taken in processing \cellEs is $O(n^2\log^2 n)$.

On each \addE we insert a new rectangle to the unified tree in time $O(\log^2 n)$.
The filtering of \addEs can be done in linear time, and the total number of unfiltered events is at most the number of \addEs multiplied by the $O(\log^2 n)$ canonical nodes used to store a rectangle in the unified tree.
Thus the time complexity of the filtering is $O(n^2\log^2 n)$.

On each \obsE we clear a rectangle from the tree.
The clearing takes $O(n\log n + k)$, where $k$ is the number of cleared canonical rectangles.
Each \addE adds $O(\log^2 n)$ canonical rectangles to the tree, so the total number of rectangles to be cleared is $O(n^2\log^2 n)$.
There are $O(n)$ \obsEs by Lemma~\ref{lem:obse3}, so the total time taken in \obsEs is $O(n^2\log^2 n)$.

As all parts of the algorithm are done in time $O(n^2\log^2 n)$, the total complexity is $O(n^2\log^2 n)$.
\end{proof}

\subsection{Higher dimensional paths}

The algorithm for 3D minimum link paths can be generalized to higher dimensions.
We now assume that \fspace is a $D$-dimensional rectilinear region for arbitrary fixed $D\ge 2$.
We develop a generalization of Algorithm~\ref{alg:minlink3d} that computes the rectilinear minimum link path in $D$-dimensional space in time $O(n^{D-1}\log^{D-1}n)$.

The algorithm uses the same set of events during the sweeps in the $D$-dimensional space as were used in 3D space.
The 2D sweep plane is replaced by a $(D-1)$-dimensional hyperplane, so each event $e$ defines a $(D-1)$-dimensional hyperrectangle \hrectof{e} instead of \rectof{e}.

We use $D$-dimensional Unified segment tree to store the sweep hyperplane state during the sweeps.
The unified tree and the $D$-dimensional space decomposition allow us to use almost identical algorithm for the higher dimension case as the algorithm for the 3D domains.

\begin{alg}\label{alg:sweepdd}
Illuminate by plane sweep in direction $+D$ starting from a provided event set $E$.
\begin{algorithmic}
\State $Q\gets$ Priority queue containing $E$.
\State $T\gets$ Empty $(D-1)$-dimensional Unified segment tree.
\While{$Q$ is not empty}
	\State $e\gets\pop{Q}$.
	\If{$e$ is \addE}
		\State Insert \hrectof{e} to $T$.
	\ElsIf{$e$ is \cellE}
		\If{\hrectof{e} touches any hyperrectangle in $T$}
			\State $c\gets\cellof{e}$.
			\ForAll{$o\in\obsd{c}{D+}$}
				\State Insert \obsE for $o$ to $Q$.
			\EndFor
			\ForAll{$n\in\nbsd{c}{D+}$}
				\State Insert \cellE for $n$ to $Q$.
			\EndFor
		\EndIf
	\ElsIf{$e$ is \obsE}
		\State Clear \hrectof{e} from $T$.
		\State Generate \addEs for the cleared canonical hyperrectangles.
	\EndIf
\EndWhile
\end{algorithmic}
\end{alg}

Using the hyperplane sweep, the $D$-dimensional minimum link path computation works as the following.

\begin{alg}\label{alg:minlinkdd}
Run staged illumination in $D$-dimensional domain \fspace starting from point \spt.
\begin{algorithmic}
\State Compute decomposition of \fspace into $D$-dimensional cells using Algorithm~\ref{alg:splitdd}.
\ForAll{$d\in\set{\pm1,\dots,\pm D}$}
	\State $E_d\gets$ Event set containing \addE at \spt and \cellE for the cell containing \spt.
\EndFor
\While{$E_d$ is not empty for some $d$}
	\ForAll{$d\in\set{\pm1,\dots,\pm D}$}
		\State $E_d'\gets$ Empty event set.
	\EndFor
	\ForAll{$d\in\set{\pm1,\dots,\pm D}$}
		\State Illuminate in direction $d$ using Algorithm~\ref{alg:sweep3d} with events $E_d$.
		\State Store the events generated by the sweep into $E_e'$ for $e\neq\pm d$.
	\EndFor
	\ForAll{$d\in\set{\pm1,\dots,\pm D}$}
		\State $E_d\gets E_d'$.
	\EndFor
\EndWhile
\end{algorithmic}
\end{alg}

We use the same method for avoiding reilluminating the same areas many times as was used in the 3D algorithm.
For each obstacle $o$ we record when it was first discovered, and use that to stop generating \addEs from $o$ after a certain number of steps has passed.
If $o$ is reached first on step $k$, then at the end of step $k+D$ all the points visible from $o$ are illuminated, so we can stop creating \addEs from $o$ starting from step $k+D+1$.

We also need to perform the filtering described in Section~\ref{sec:evtgen} to avoid generating a large number of \addEs because of the unified tree structure.
The filtering rules are exactly the same as the ones used in the 3D algorithm, except that we are working with $(D-1)$-dimensional hyperplanes.
The operations below are performed to \addEs produced by sweep in direction $+D$.
\begin{enumerate}
\item Remove all the pairs of \addEs with the same position but opposite direction.
\item Merge all sets of aligned \addEs with the same $D$-range into a single larger \addE.
\end{enumerate}

The definition of aligned \addEs is a bit more complicated in high-dimensional case.
A pair of \addEs can be aligned along multiple axes.
For two \addEs to be aligned, they need to in the event set for the same direction, and share the same coordinate where the events occur.
Let $a$ be any axis other than $D$.
The events are aligned in direction $a$ if the bounds of their hyperrectangles are identical in all the directions except $a$, and the bounds in direction $a$ touch each other at endpoints.

The filtering step allows us to again bound the numberor of \addEs processed during the illumination.

\begin{lem}\label{lem:obsed}For each obstacle we generate \obsE on at most $2D+3$ steps of the illumination.\end{lem}
\begin{proof}
The proof is similar to Lemma~\ref{lem:obse3} for the 3D case.
We stop generating \addEs from obstacles after $D$ steps have passed since that obstacle was discovered.
Suppose we first generate \obsE for obstacle $o$ on step $k$.
After step $k+D$ all the points visible from $o$ are illuminated.
After step $k+D+1$ we have discovered each obstacle $h$ such that the illumination reaching $h$ could generate an \addE that illuminates $o$.
We won't generate any \addEs for such obstacle $h$ after step $k+2D+1$, so the last time a sweep can reach $o$ is on step $k+2D+2$.
\end{proof}

\begin{lem}\label{lem:celled}For each cell we generate \cellE on at most $2D+3$ steps of the illumination.\end{lem}
\begin{proof}
The proof is very similar to Lemma~\ref{lem:obsed}.
If we discover a cell $c$ on step $k$ then all the points visible from $c$ are illuminated after step $k+D$, so no more sweeps can reach $c$ after step $k+2D+2$.
\end{proof}

\begin{lem}\label{lem:added}The number of \addEs generated during the illumation after after filtering is $O(n^{D-1})$.\end{lem}
\begin{proof}
The proof is similar to Lemma~\ref{lem:adde3}.
We only count the \addEs in direction $+D$ occurring on a hyperplane $P$ defined by a $(D-1)$-dimensional obstacle face $o$ that has $D$-coordinate $\hat{d}$.
To simplify the counting we assume that the obstacle $D$-coordinates are unique so $o$ is the only obstacle face on $P$.

We classify the events remaining after filtering similarly to the 3D case:
\begin{enumerate}
\item During a sweep in direction $+D$ we hit the obstacle $o$.
	We generate \addEs in directions other than $\pm D$ that are bounded by $\hat{d}$.
	From these \addEs we create events on plane $P$ on the following illumination step.
\item During a sweep in direction other than $\pm D$ the obstacle face $o$ cuts a hyperrectangle in the tree such that the remaining part has boundary on $P$.
\item If on the previous step we created $\addE$ on plane $P$, then we also created events in directions other than $\pm D$ that have plane $P$ as one of the sides.
	From those events we create more $+D$ events on plane $P$ on the following step.
\end{enumerate}

Similar to the 3D case, a single sweep can only produce as many events on $P$ as the number of canonical hyperrectangles bounded by $P$, which in the $(D-1)$-dimensional unified tree is $O(n^{D-2})$.
By Lemma~\ref{lem:obsed} and Lemma~\ref{lem:celled} the illumination can only touch $o$ on $O(1)$ steps, so the number of type 1 and 2 events on $P$ is $O(n^{D-2})$.

We use induction on $D$ to prove the number of type 3 events.
The base case $D=2$ is proven by Lemma~\ref{lem:adde3}.

For $D\ge 3$ notice that again the illumination on the boundary of $P$ advances exactly like the $(D-1)$-dimensional illumination in the cross section of $P$.
By induction the $(D-1)$-dimensional illumination creates $O(n^{D-2})$ events.
Multiplying this by the number of times any cell can be visited gives an upper bound for the $D$-dimensional illumination on $P$.
Since there is only constant factor overhead compared to the $(D-1)$-dimensional illumination, the number of type~3 events is $O(n^{D-2})$.

The number of events on the hyperplane of a single obstacle $o$ is $O(n^{D-2})$, so the total number of events is $O(n^{D-1})$.
\end{proof}

These lemmas allow us to prove the final result.

\begin{theo}Algorithm~\ref{alg:minlinkdd} computes $D$-dimensional minimum link path in time $O(n^{D-1}\log^{D-1}n)$.\end{theo}
\begin{proof}
By Lemma~\ref{lem:celled} each cell is visited $O(1)$ times during the illumination.
On each \cellE we perform a single lookup to the unified tree in time $O(\log^{D-1} n)$, and iterate over the neighbors of the cell.
Since the decomposition has $O(n^{D-1})$ cells and $O(n^{D-1})$ links between cells, the total time taken in processing \cellEs is $O(n^{D-1}\log^{D-1} n)$.

On each \addE we insert a new rectangle to the unified tree in time $O(\log^{D-1} n)$.
The filtering of \addEs can be done in linear time, and the total number of unfiltered events is at most the number of \addEs multiplied by the $O(\log^{D-1} n)$ canonical nodes used to store a hyperrectangle in the unified tree.

On each \obsE we clear a hyperrectangle from the tree.
By Lemma~\ref{lem:segurmtime}, each clear operation takes time $O(n^{D-2}\log n + k)$ where $k$ is the nubmer of cleared canonical nodes.
Each \addE adds $O(\log^{D-1} n)$ canonical rectangles to the tree, so the total number of rectangles to be cleared is $O(n^{D-1}\log^{D-1} n)$.
There are $O(n)$ \obsEs by Lemma~\ref{lem:obsed}, so the total time taken in \obsEs is $O(n^{D-1}\log^{D-1} n)$.

As all parts of the algorithm are done in time $O(n^{D-1}\log^{D-1} n)$, the total complexity is $O(n^{D-1}\log^{D-1} n)$.
\end{proof}



\section{Conclusions}\label{sec:conclusions}

We have shown algorithms for the rectilinear minimum link path problem for many different dimensions.
The 2D case is solved in time $O(n\log n)$, which was shown initially by~TODO.
A new result is that a similar algorithm can be created for 3 dimensions, which works in time $O(n^2\log^2 n)$.
We also showed how this result can be further generalized to work for any dimension $D$ in time $O(n^{D-1}\log^{D-1}n)$.

The previous best known result for the 3D minimum link paths was $O(n^{2.5}\log n)$, and we improved it down to $O(n^2\log^2 n)$.
A natural follow up question is, whether the result could be improved further.
The 2D case was shown to be equivalently difficult as sorting the input, so the result is asymptotically optimal.
For the higher dimensional results no other upper bound is known than the same $O(n\log n)$ bound.

The main bottleneck in the higher dimensional algorithms are operations on segment tree.
Segment trees and their applications are a broad research topic.
For example we can create a segment tree that supports adding intervals, and finding the maximal number of overlapping any point in a query interval in time $O(\log n)$.
It is an open question whether this can be generalized to two or more dimensions: can we create a structure that supports adding and querying for maximally overlapping rectangles in polylogarithmic time?


\nocite{*}
\bibliographystyle{tktl}
\bibliography{ref}

\lastpage

\appendices

\pagestyle{empty}

\internalappendix{1}{Source code location}

An implementation of the high-dimensional rectilinear minimum link path algorithm presented in the thesis is available in the following URL: \\
\url{https://github.com/sisu/gradu/tree/master/code}

The code is written in standard C++ using the C++14 standard.
The implementation does not depend on any libraries besides the C++ standard library, but the associated unit tests are written using the Google Test framework.

\end{document}


